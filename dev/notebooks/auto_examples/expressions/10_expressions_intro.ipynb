{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Building complex tabular pipelines\n\nIn this example, we show a simple pipeline handling a dataset with 2 tables,\nwhich would be difficult to implement, validate, and deploy correctly without\nskrub.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The credit fraud dataset\n\nThis dataset comes from an e-commerce website. We have a set of \"baskets\" (\norders that have been placed with the website). The task is to detect which\norders were fraudulent (the customer never made the payment).\n\nThe ``baskets`` table contains a basket ID and a flag indicating if the order\nwas fraudulent or not.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import skrub\nimport skrub.datasets\n\ndataset = skrub.datasets.fetch_credit_fraud()\nskrub.TableReport(dataset.baskets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each basket contains one or more products. Each row in the ``products`` table\ncorresponds to a type of product present in a basket. Products can\nbe associated with the corresponding basket through the ``\"basket_ID\"``\ncolumn.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "skrub.TableReport(dataset.products)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A data-processing challenge\n\nWe want to fit a ``HistGradientBoostingClassifier`` to predict the fraud\nflag (or ``y``). We build a design matrix with one row per basket (and thus per\nfraud flag). Our ``baskets`` (or ``X``) table only contains IDs. We enrich it by\nadding features from the ``products`` table.\n\nThe general structure of the pipeline looks like this:\n\n<img src=\"file://../../_static/credit_fraud_diagram.svg\" width=\"300\">\n\n\nFirst, as the ``products`` table contains strings and categories (such as\n``\"SAMSUNG\"``), we vectorize those entries to extract numeric\nfeatures. This is easily done with skrub's ``TableVectorizer``. Then, as each\nbasket can contain several products, all the product lines corresponding to a\nbasket are aggregated into a single feature vector that can be\nattached to the basket.\n\nThe difficulty is that the vectorized ``products`` should be aggregated before joining\nto ``baskets``, and, in order to compute a meaningful aggregation, must\nbe vectorized *before* the aggregation. Thus, we have a ``TableVectorizer`` to\nfit on a table which does not (yet) have the same number of rows as the\ntarget ``y`` \u2014 something that the scikit-learn ``Pipeline``, with its\nsingle-input, linear structure, does not allow.\n\nWe can fit it ourselves, outside of any pipeline with something like::\n\n    vectorizer = skrub.TableVectorizer()\n    vectorized_products = vectorizer.fit_transform(dataset.products)\n\nHowever, because it is dissociated from the main estimator which handles\n``X`` (the baskets), we have to manage this transformer ourselves. We lose\nthe scikit-learn machinery for grouping all transformation steps,\nstoring fitted estimators, splitting the input data and cross-validation, and\nhyper-parameter tuning.\n\nMoreover, we might need some Pandas code to perform the aggregation and join.\nAgain, as this transformation is not in a scikit-learn estimator, it is error-prone.\nThe difficulty is that we have to keep track of it ourselves to apply it later\nto unseen data, and we cannot tune any choices (like the choice of the\naggregation function).\n\nFortunately, skrub provides an alternative way to build\nmore flexible pipelines.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A solution with skrub\n\nIn a skrub pipeline, we do not provide an explicit list of\ntransformation steps. Rather, we manipulate skrub objects representing\nintermediate results. The pipeline is built implicitly as we perform\noperations (such as applying operators or calling functions) on those\nobjects.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We start by creating skrub variables, which are the inputs to our pipeline.\nIn our example, we create three variables: \"products\", \"baskets\", and \"fraud flags\":\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "products = skrub.var(\"products\", dataset.products)\nfull_baskets = skrub.var(\"baskets\", dataset.baskets)\n\nbaskets = full_baskets[[\"ID\"]].skb.mark_as_X()\nfraud_flags = full_baskets[\"fraud_flag\"].skb.mark_as_y()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "They are given a name and an (optional) initial\nvalue, used to show previews of the pipeline's output, detect errors\nearly, and provide data for cross-validation and hyperparameter search.\n\nWe then build the pipeline by applying transformations to those inputs.\n\nAbove, ``mark_as_X()`` and ``mark_as_y()`` indicate that the baskets and\nflags are respectively our design matrix and target variables, that\nshould be split into training and testing sets for cross-validation. Here,\nthey are direct inputs to the pipeline but any\nintermediate result could be marked as X or y.\n\nBecause our pipeline expects dataframes for products, baskets and fraud\nflags, we manipulate those objects as we would manipulate dataframes.\nAll attribute accesses are transparently forwarded to the actual input\ndataframes when we run the pipeline.\n\nFor instance, we filter products to keep only those that match one of the\nbaskets in the ``baskets`` table, and then add a column containing the total\namount for each kind of product in a basket:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kept_products = products[products[\"basket_ID\"].isin(baskets[\"ID\"])]\nproducts_with_total = kept_products.assign(\n    total_price=kept_products[\"Nbr_of_prod_purchas\"] * kept_products[\"cash_price\"]\n)\nproducts_with_total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see previews of the output of intermediate results. For\nexample, the added ``\"total_price\"`` column is in the output above.\nThe \"Show graph\" dropdown at the top allows us to check the\nstructure of the pipeline and all the steps it contains.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>We recommend to assign each new skrub expression to a new variable name,\n   as is done above. For example ``kept_products = products[...]`` instead of\n   reusing the name ``products = products[...]``. This makes it easy to\n   backtrack to any step of the pipeline and change the subsequent steps, and\n   can avoid ending up in a confusing state in jupyter notebooks when the\n   same cell might be re-executed several times.</p></div>\n\nWith skrub, we do not need to specify a grid of hyperparameters separately\nfrom the pipeline. Instead, we replace a parameter's value with a skrub\n\"choice\" which indicates the range of values we consider during\nhyperparameter selection.\n\nSkrub choices can be nested arbitrarily. They are not restricted to\nparameters of a scikit-learn estimator, but can be anything: choosing\nbetween different estimators, arguments to function calls, whole sections of\nthe pipeline etc.\n\nIn-depth information about choices and hyperparameter/model selection is\nprovided in the `Tuning Pipelines example <example_tuning_pipelines>`.\n\nWe build a skrub ``TableVectorizer`` with different choices of:\nthe type of encoder for high-cardinality categorical or string columns, and\nthe number of components it uses.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n = skrub.choose_int(5, 15, name=\"n_components\")\nencoder = skrub.choose_from(\n    {\n        \"MinHash\": skrub.MinHashEncoder(n_components=n),\n        \"LSA\": skrub.StringEncoder(n_components=n),\n    },\n    name=\"encoder\",\n)\nvectorizer = skrub.TableVectorizer(high_cardinality=encoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A transformer does not have to apply to the full dataframe; we can\nrestrict it to some columns, using the ``cols`` or ``exclude_cols``\nparameters. In our example, we vectorize all columns except the ``\"basket_ID\"``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vectorized_products = products_with_total.skb.apply(\n    vectorizer, exclude_cols=\"basket_ID\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Having access to the underlying dataframe's API, we can perform the\ndata-wrangling we need. Those transformations are being implicitly added\nas steps in our machine-learning pipeline.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "aggregated_products = vectorized_products.groupby(\"basket_ID\").agg(\"mean\").reset_index()\naugmented_baskets = baskets.merge(\n    aggregated_products, left_on=\"ID\", right_on=\"basket_ID\"\n).drop(columns=[\"ID\", \"basket_ID\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can actually ask for a full report of the pipeline and inspect the\nresults at every step::\n\n    predictions.skb.full_report()\n\nThis produces a folder on disk rather than displaying inline in a notebook so\nwe do not run it here. But you can\n[see the output here](../../_static/credit_fraud_report/index.html).\n\nFinally, we add a supervised estimator:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import HistGradientBoostingClassifier\n\nhgb = HistGradientBoostingClassifier(\n    learning_rate=skrub.choose_float(0.01, 0.9, log=True, name=\"learning_rate\")\n)\npredictions = augmented_baskets.skb.apply(hgb, y=fraud_flags)\npredictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And our pipeline is complete!\n\nFrom the choices we inserted at different locations in our pipeline, skrub\ncan build a grid of hyperparameters and run the hyperparameter search for us,\nbacked by scikit-learn's ``GridSearchCV`` or ``RandomizedSearchCV``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(predictions.skb.describe_param_grid())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "search = predictions.skb.get_randomized_search(\n    scoring=\"roc_auc\", n_iter=8, n_jobs=4, random_state=0, fitted=True\n)\nsearch.results_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also run a cross validation, using the first choices defined in the ``choose``\nobjects:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "predictions.skb.cross_validate(scoring=\"roc_auc\", verbose=1, n_jobs=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also display a parallel coordinates plot of the results.\n\nIn a parallel coordinates plot, each line corresponds to a combination\nof hyperparameter (choices) values, followed by the corresponding test\nscores, and training and scoring computation durations.\nDifferent columns show the hyperparameter values.\n\nBy **clicking and dragging the mouse** on any column, we can restrict the\nset of lines we see. This allows quickly inspecting which hyperparameters are\nimportant, which values perform best, and potential trade-offs between the quality\nof predictions and computation time.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "search.plot_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It seems here that using the LSA as an encoder brings better test scores,\nbut at the expense of training and scoring time.\n\n## Serializing\nWe would usually save this model in a binary file, but to avoid accessing the\nfilesystem with this example notebook, we serialize the model in memory instead.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pickle\n\nsaved_model = pickle.dumps(search.best_pipeline_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's say we got some new data, and we want to use the model we just saved\nto make predictions on them:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "new_data = skrub.datasets.fetch_credit_fraud(split=\"test\")\nnew_baskets = new_data.baskets[[\"ID\"]]\nnew_products = new_data.products"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our pipeline expects the same variable names as the training pipeline, which is why\nwe pass a dictionary that contains new dataframes and the same variable:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "loaded_model = pickle.loads(saved_model)\nloaded_model.predict({\"baskets\": new_baskets, \"products\": new_products})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n\nIf you are curious to know more on how to build your own complex, multi-table\npipelines with easy hyperparameter tuning, please see the next examples for an\nin-depth tutorial.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}