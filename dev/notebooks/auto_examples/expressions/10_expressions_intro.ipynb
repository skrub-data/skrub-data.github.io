{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n.. currentmodule:: skrub\n\n\n# Building a predictive model by combining multiple tables with the skrub DataOps\n\nThis example introduces the skrub DataOps, that builds complex data processing pipelines\nhandling multiple tables, with hyperparameter tuning and model selection.\n\nDataOps form implicitly a \"plan\", which records all the operations performed on\nthe data; the DataOps plan can be exported as a ``Learner``, a standalone object\nthat can be saved on disk, loaded in a new environment, and used to make predictions\non new data.\n\nHere we show the basics of the skrub DataOps in a two-table scenario: how to create\nDataOps, how to use them to leverage dataframe operations, how to combine them in\na full DataOps plan, how to do simple hyperparameter tuning, and finally how to\nexport the plan as a ``Learner``.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The credit fraud dataset\n\nThis dataset originates from an e-commerce website and is structured into two tables:\n\n- The \"baskets\" table contains order IDs, each representing a list of purchased\n  products.\n  For a subset of these orders (the training set), a flag indicates whether\n  the order was fraudulent.\n  This fraud flag is the target variable we aim to predict during inference.\n- The \"products\" table provides the detailed contents of all baskets, including\n  those without a known fraud label.\n\nThe ``baskets`` table contains a basket ID and a flag indicating if the order\nwas fraudulent or not.\nWe start by loading the ``baskets`` table, and exploring it with the ``TableReport``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import skrub.datasets\nfrom skrub import TableReport\n\ndataset = skrub.datasets.fetch_credit_fraud()  # load labeled data\nTableReport(dataset.baskets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then load the ``products`` table, which contains one row per purchased product.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "TableReport(dataset.products)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each basket contains at least one product, and products can\nbe associated with the corresponding basket through the ``\"basket_ID\"``\ncolumn.\n\n## A design problem: how to combine tables while avoiding leakage?\n\nWe want to fit a ``HistGradientBoostingClassifier`` to predict the fraud\nflag (or ``y``). To do so, we build a design matrix where each row corresponds\nto a basket, and we want to add features from the ``products`` table to\neach basket.\n\nThe general structure of the pipeline looks like this:\n\n<img src=\"file://../../_static/credit_fraud_diagram.svg\" width=\"300\">\n\n\nFirst, as the ``products`` table contains strings and categories (such as\n``\"SAMSUNG\"``), we vectorize those entries to extract numeric\nfeatures. This is easily done with skrub's ``TableVectorizer``. Then, since each\nbasket can contain several products, we want to aggregate all the lines in\n``products`` that correspond to a single basket into a single vector that can\nthen be attached to the basket.\n\nThe difficulty is that the vectorized ``products`` should be aggregated before joining\nto ``baskets``, and, in order to compute a meaningful aggregation, must\nbe vectorized *before* the aggregation. Thus, we have a ``TableVectorizer`` to\nfit on a table which does not (yet) have the same number of rows as the\ntarget ``y`` \u2014 something that the scikit-learn ``Pipeline``, with its\nsingle-input, linear structure, does not allow.\n\nWe can fit it ourselves, outside of any pipeline with something like::\n\n    vectorizer = skrub.TableVectorizer()\n    vectorized_products = vectorizer.fit_transform(dataset.products)\n\nHowever, because it is dissociated from the main estimator which handles\n``X`` (the baskets), we have to manage this transformer ourselves. We lose\nthe scikit-learn machinery for grouping all transformation steps,\nstoring fitted estimators, cross-validating the data, and tuning hyper-parameters.\n\nMoreover, we might need some Pandas code to perform the aggregation and join.\nAgain, as this transformation is not in a scikit-learn estimator, it is error-prone.\nThe difficulty is that we have to keep track of it ourselves to apply it later\nto unseen data, and we cannot tune any choices (like the choice of the\naggregation function).\n\nFortunately, skrub provides an alternative way to build\nmore flexible pipelines.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DataOps make DataOps plans\nIn a skrub DataOps plan, we do not have an explicit, sequential list of\ntransformation steps. Instead, we perform \"Data Operations\" (or \"DataOps\"):\noperations that act on variables and wrap user operations to keep track\nof their parameters.\n\nUser operations could be dataframe operations (selection, merge, group by, etc.),\nscikit-learn estimators (such as a RandomForest with its hyperparameters),\nor arbitrary code (for loading data, converting values, etc.).\n\nAs we perform operations on skrub variables, the plan records each DataOp\nand its parameters. This record can later be synthesized into a standalone object\ncalled a \"learner\", which can replay these operations on unseen data, ensuring\nthat the same operations and parameters are used.\n\nIn a DataOps plan, we manipulate skrub objects representing\nintermediate results. The plan is built implicitly as we perform\noperations (such as applying operators or calling functions) on those\nobjects.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We start by creating skrub variables, which are the inputs to our plan.\nIn our example, we create three variables: \"products\", \"baskets\", and \"fraud flags\":\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "products = skrub.var(\"products\", dataset.products)\nfull_baskets = skrub.var(\"baskets\", dataset.baskets)\n\nbaskets = full_baskets[[\"ID\"]].skb.mark_as_X()\nfraud_flags = full_baskets[\"fraud_flag\"].skb.mark_as_y()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Variables are given a name and an (optional) initial\nvalue, which is used to show previews of the result of each DataOp, detect errors\nearly, and provide data for cross-validation and hyperparameter search.\n\nThen, the plan is built by applying DataOps to those variables, that\nis, by performing user operations that have been wrapped in a DataOp.\n\nAbove, ``mark_as_X()`` and ``mark_as_y()`` indicate that the baskets and\nflags are respectively our design matrix and target variables, that\nshould be split into training and testing sets for cross-validation. Here,\nthey are direct inputs to the plan, but any\nintermediate result could be marked as X or y.\n\nBy setting products, baskets and fraud_flags as skrub variables, we can manipulate\nthose objects as if they were dataframes, while keeping track of all the operations\nthat are performed on them. Additionally, skrub variables and DataOps provide\ntheir own\nset of methods, which are\naccessible through the ``skb`` attribute of any skrub variable and DataOp.\n\nFor instance, we can filter products to keep only those that match one of the\nbaskets in the ``baskets`` table, and then add a column containing the total\namount for each kind of product in a basket:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kept_products = products[products[\"basket_ID\"].isin(baskets[\"ID\"])]\nproducts_with_total = kept_products.assign(\n    total_price=kept_products[\"Nbr_of_prod_purchas\"] * kept_products[\"cash_price\"]\n)\nproducts_with_total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see previews of the output of intermediate results. For\nexample, the added ``\"total_price\"`` column is in the output above.\nThe \"Show graph\" dropdown at the top allows us to check the\nstructure of the DataOps plan and all the DataOps it contains.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>We recommend to assign each new skrub DataOp to a new variable name,\n   as is done above. For example ``kept_products = products[...]`` instead of\n   reusing the name ``products = products[...]``. This makes it easy to\n   backtrack to any step of the plan and change the subsequent steps, and\n   can avoid ending up in a confusing state in jupyter notebooks when the\n   same cell might be re-executed several times.</p></div>\n\nA major advantage of the skrub DataOps plan is that it allows to specify a\ngrid of hyperparameter choices where the parameter is defined, improving code\nreadability and maintainability.\nWe do so by replacing a parameter's value with a skrub\n\"choice\", which indicates the range of values we consider during\nhyperparameter selection.\n\nSkrub choices can be nested arbitrarily. They are not restricted to\nparameters of a scikit-learn estimator, but can be anything: choosing\nbetween different estimators, arguments to function calls, whole sections of\nthe plan etc.\n\nIn-depth information about choices and hyperparameter/model selection is\nprovided in the `Tuning Data Plans example <example_tuning_pipelines>`.\n\nHere, we build a skrub ``TableVectorizer`` with choices for the high-cardinality\nencoder, and the number of components it uses.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n = skrub.choose_int(5, 15, name=\"n_components\")\nencoder = skrub.choose_from(\n    {\n        \"MinHash\": skrub.MinHashEncoder(n_components=n),\n        \"LSA\": skrub.StringEncoder(n_components=n),\n    },\n    name=\"encoder\",\n)\nvectorizer = skrub.TableVectorizer(high_cardinality=encoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A transformer does not have to apply to the full dataframe; we can\nrestrict it to some columns, using the ``cols`` or ``exclude_cols``\nparameters. In our example, we vectorize all columns except the ``\"basket_ID\"``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vectorized_products = products_with_total.skb.apply(\n    vectorizer, exclude_cols=\"basket_ID\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Having access to the underlying dataframe's API, we can perform the\ndata-wrangling we need. Those transformations are being implicitly recorded\nas DataOps in our plan.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "aggregated_products = vectorized_products.groupby(\"basket_ID\").agg(\"mean\").reset_index()\naugmented_baskets = baskets.merge(\n    aggregated_products, left_on=\"ID\", right_on=\"basket_ID\"\n).drop(columns=[\"ID\", \"basket_ID\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can actually ask for a full report of the plan and inspect the\nresults of each DataOp::\n\n    predictions.skb.full_report()\n\nThis produces a folder on disk rather than displaying inline in a notebook so\nwe do not run it here. But you can\n[see the output here](../../_static/credit_fraud_report/index.html).\n\nFinally, we add a supervised estimator:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import HistGradientBoostingClassifier\n\nhgb = HistGradientBoostingClassifier(\n    learning_rate=skrub.choose_float(0.01, 0.9, log=True, name=\"learning_rate\")\n)\npredictions = augmented_baskets.skb.apply(hgb, y=fraud_flags)\npredictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And our DataOps plan is complete!\n\nFrom the choices we inserted at different locations in our plan, skrub\ncan build a grid of hyperparameters and run the hyperparameter search for us,\nbacked by scikit-learn's ``GridSearchCV`` or ``RandomizedSearchCV``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(predictions.skb.describe_param_grid())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "search = predictions.skb.get_randomized_search(\n    scoring=\"roc_auc\", n_iter=8, n_jobs=4, random_state=0, fitted=True\n)\nsearch.results_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also run a cross validation, using the first choices defined in the ``choose``\nobjects:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "predictions.skb.cross_validate(scoring=\"roc_auc\", verbose=1, n_jobs=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also display a parallel coordinates plot of the results.\n\nIn a parallel coordinates plot, each line corresponds to a combination\nof hyperparameter (choices) values, followed by the corresponding test\nscores, and training and scoring computation durations.\nDifferent columns show the hyperparameter values.\n\nBy **clicking and dragging the mouse** on any column, we can restrict the\nset of lines we see. This allows quickly inspecting which hyperparameters are\nimportant, which values perform best, and potential trade-offs between the quality\nof predictions and computation time.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "search.plot_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It seems here that using the LSA as an encoder brings better test scores,\nbut at the expense of training and scoring time.\n\n## From the DataOps plan to the learner\nThe learner is a standalone object that can replay all the DataOps recorded in\nthe plan, and can be used to make predictions on new, unseen data. The\nlearner can be saved and loaded, allowing us to use it later without having to\nrebuild the plan.\nWe would usually save the learner in a binary file, but to avoid accessing the\nfilesystem with this example notebook, we serialize the learner in memory instead.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pickle\n\nsaved_model = pickle.dumps(search.best_pipeline_)  # This gives us our learner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's say we got some new data, and we want to use the learner we just saved\nto make predictions on them:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "new_data = skrub.datasets.fetch_credit_fraud(split=\"test\")\nnew_baskets = new_data.baskets[[\"ID\"]]\nnew_products = new_data.products"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our learner expects the same variable names as the training plan, which is why\nwe pass a dictionary that contains new dataframes and the same variable:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "loaded_model = pickle.loads(saved_model)\nloaded_model.predict({\"baskets\": new_baskets, \"products\": new_products})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n\nIf you are curious to know more on how to build your own complex, multi-table\nplans with easy hyperparameter tuning and transforming them into reusable\nlearners, please see the next examples for an in-depth tutorial.\n\nIndeed, the following examples will explain how to tune hyperparameters in detail (see\n`example_tuning_pipelines`), and how to speed up development by subsampling\npreview data (see `example_subsampling`).\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}