{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n.. currentmodule:: skrub\n\n# Tuning DataOps with Optuna\n\nThis example shows how to use [Optuna](https://optuna.readthedocs.io/en/stable/) to tune the hyperparameters of a\nskrub :class:`DataOp`. As seen in the previous example, skrub DataOps can contain\n\"choices\", objects created with :func:`choose_from`, :func:`choose_int`,\n:func:`choose_float`, etc. and we can use hyperparameter search techniques to\npick the best outcome for each choice. Performing this search with Optuna\nallows us to benefit from its many features, such as state-of-the-art search\nstrategies, monitoring and visualization, stopping and resuming searches, and\nparallel or distributed computation.\n\nIn order to use Optuna with skrub, the package must be installed first.\nThis can be done with pip:\n\n```bash\npip install optuna\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A simple regressor and example data.\n\nWe will fit a regressor containing a few choices on a toy dataset. We\ntry 2 regressors: extra trees and ridge. They both have  hyperparameters that\nwe want to tune.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.linear_model import Ridge\n\nimport skrub\n\nextra_tree = ExtraTreesRegressor(\n    min_samples_leaf=skrub.choose_int(1, 32, log=True, name=\"min_samples_leaf\"),\n)\nridge = Ridge(alpha=skrub.choose_float(0.01, 10.0, log=True, name=\"\u03b1\"))\n\nregressor = skrub.choose_from(\n    {\"extra_tree\": extra_tree, \"ridge\": ridge}, name=\"regressor\"\n)\ndata = skrub.var(\"data\")\nX = data.drop(columns=\"MedHouseVal\", errors=\"ignore\").skb.mark_as_X()\ny = data[\"MedHouseVal\"].skb.mark_as_y()\npred = X.skb.apply(regressor, y=y)\nprint(pred.skb.describe_param_grid())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load data for the example\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n\n# (We subsample the dataset by half to make the example run faster)\ndf = skrub.datasets.fetch_california_housing().california_housing.sample(\n    10_000, random_state=0\n)\n\n# The environment we will use to fit the learners created by our DataOp.\nenv = {\"data\": df}\ncv = KFold(n_splits=4, shuffle=True, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Selecting the best hyperparameters with Optuna.\n\nThe simplest way to use Optuna is to pass ``backend='optuna'`` to\n:meth:`DataOp.skb.make_randomized_search()`. It is used very similarly as\nwith the default backend\n(:class:`sklearn.model_selection.RandomizedSearchCV`). Additional\nparameters are available to control the Optuna sampler, storage and study\nname, and timeout.\nNote that in order to persist the study and resume it later, the ``storage``\nparameter must be set to a valid database URL (e.g., a SQLite file). Refer to\nthe User Guide for an example.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "search = pred.skb.make_randomized_search(\n    backend=\"optuna\", cv=cv, n_iter=10, random_state=10\n)\nsearch.fit(env)\nsearch.results_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The usual ``results_``, ``detailed_results_`` and ``plot_results()`` are\nstill available.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "search.plot_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Optuna :class:`Study <optuna.study.Study>` that was used to run the\nhyperparameter search is available in the attribute ``study_``:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "search.study_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "search.study_.best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This allows us to use Optuna's reporting capabilities provided in\n[optuna.visualization](https://optuna.readthedocs.io/en/stable/reference/visualization/) or\n[optuna-dashboard](https://optuna-dashboard.readthedocs.io/en/latest/getting-started.html).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import optuna\n\noptuna.visualization.plot_slice(search.study_, params=[\"0:min_samples_leaf\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using Optuna directly for more advanced use cases\n\nOften we may want more control over the use of Optuna, or to access\nfunctionality not available through :meth:`DataOp.skb.make_randomized_search`\nsuch as the ask-and-tell interface, trial pruning, callbacks,\nmulti-objective optimization, etc. .\n\nDirectly using Optuna ourselves is also easy, as we will show now. What makes\nthis possible is that we can pass an Optuna Trial to\n:meth:`DataOp.skb.make_learner` in which case the parameters suggested by the\ntrial are used to create the learner.\n\nWe revisit the example above, following the typical Optuna workflow.\n\nThe :class:`optuna.Study <optuna.study.Study>` runs the hyperparameter\nsearch.\n\nIts method :meth:`optimize <optuna.study.Study.optimize>` is given an\n``objective`` function. The ``objective`` must accept a\n:class:`~optuna.trial.Trial` object (which is produced by the study and picks\nthe parameters for a given evaluation of the objective) and return the value\nto maximize (or minimize).\n\nTo use Optuna with a :class:`DataOp`, we just need to pass the Trial object\nto :meth:`DataOp.skb.make_learner`. This creates a :class:`SkrubLearner`\ninitialized with the parameters picked by the optuna Trial.\n\nWe can then cross-validate the SkrubLearner, or score it however we prefer,\nand return the score so that the optuna Study can take it into account.\n\nHere we return a single score (R\u00b2), but multi-objective\noptimization is also possible. Please refer to the Optuna documentation for\nmore information.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n    learner = pred.skb.make_learner(choose=trial)\n    cv_results = skrub.cross_validate(learner, environment=env, cv=cv)\n    return cv_results[\"test_score\"].mean()\n\n\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=10)\nstudy.best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also use Optuna's visualization capabilities to inspect the study:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "optuna.visualization.plot_optimization_history(study)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we build a learner with the best hyperparameters and fit it on the full\ndataset:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "best_learner = pred.skb.make_learner(choose=study.best_trial)\n\n# This would achieve the same result:\n# best_learner = pred.skb.make_learner()\n# best_learner.set_params(**study.best_params)\n\nbest_learner.fit(env)\nprint(best_learner.describe_params())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}