{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class='alert alert-warning'>\n\n# JupyterLite warning\n\nRunning the skrub examples in JupyterLite is experimental and you mayencounter some unexpected behavior.\n\nThe main difference is that imports will take a lot longer than usual, for example the first `import skrub` can take roughly 10-20s.\n\nIf you notice problems, feel free to open an [issue](https://github.com/skrub-data/skrub/issues/new/choose) about it.\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# JupyterLite-specific code\nimport micropip\nawait micropip.install('skrub')\n%pip install seaborn\n%pip install pyodide-http\nimport pyodide_http\npyodide_http.patch_all()\nimport matplotlib\nimport pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Fuzzy joining dirty tables with the Joiner\n\nHere we show how to combine data from different sources,\nwith a vocabulary not well normalized.\n\nJoining is difficult: one entry on one side does not have\nan exact match on the other side.\n\nThe |fj| function enables to join tables without cleaning the data by\naccounting for the label variations.\n\nTo illustrate, we will join data from the\n[2022 World Happiness Report](https://worldhappiness.report/), with tables\nprovided in [the World Bank open data platform](https://data.worldbank.org/)\nin order to create a first prediction model.\n\nMoreover, the |joiner| is a scikit-learn Transformer that makes it easy to\nuse such fuzzy joining multiple tables to bring in information in a\nmachine-learning pipeline. In particular, it enables tuning parameters of\n|fj| to find the matches that maximize prediction accuracy.\n\n\n.. |fj| replace:: :func:`~skrub.fuzzy_join`\n\n.. |joiner| replace:: :func:`~skrub.Joiner`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Importing and preprocessing\n\nWe import the happiness score table first:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n\ndf = pd.read_csv(\n    (\n        \"https://raw.githubusercontent.com/skrub-data/datasets/\"\n        \"master/data/Happiness_report_2022.csv\"\n    ),\n    thousands=\",\",\n)\ndf.drop(df.tail(1).index, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at the table:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is a table that contains the happiness index of a country along with\nsome of the possible explanatory factors: GDP per capita, Social support,\nGenerosity etc.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the sake of this example, we only keep the country names and our\nvariable of interest: the 'Happiness score'.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df = df[[\"Country\", \"Happiness score\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additional tables from other sources\n\nNow, we need to include explanatory factors from other sources, to\ncomplete our covariates (X table).\n\nInteresting tables can be found on [the World Bank open data platform](https://data.worldbank.org/), for which we have a downloading\nfunction:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skrub.datasets import fetch_world_bank_indicator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We extract the table containing GDP per capita by country:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gdp_per_capita = fetch_world_bank_indicator(indicator_id=\"NY.GDP.PCAP.CD\").X\ngdp_per_capita.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then another table, with life expectancy by country:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "life_exp = fetch_world_bank_indicator(\"SP.DYN.LE00.IN\").X\nlife_exp.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And a table with legal rights strength by country:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "legal_rights = fetch_world_bank_indicator(\"IC.LGL.CRED.XQ\").X\nlegal_rights.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A correspondence problem\n\nAlas, the entries for countries do not perfectly match between our\noriginal table (df), and those that we downloaded from the worldbank\n(gdp_per_capita):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df.sort_values(by=\"Country\").tail(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gdp_per_capita.sort_values(by=\"Country Name\").tail(7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that Yemen is written \"Yemen*\" on one side, and\n\"Yemen, Rep.\" on the other.\n\nWe also have entries that probably do not have correspondences: \"World\"\non one side, whereas the other table only has country-level data.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Joining tables with imperfect correspondence\n\nWe will now join our initial table, df, with the 3 additional ones that\nwe have extracted.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n### 1. Joining GDP per capita table\n\nTo join them with skrub, we only need to do the following:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skrub import fuzzy_join\n\naugmented_df = fuzzy_join(\n    df,  # our table to join\n    gdp_per_capita,  # the table to join with\n    left_on=\"Country\",  # the first join key column\n    right_on=\"Country Name\",  # the second join key column\n    add_match_info=True,\n)\n\naugmented_df.tail(20)\n\n# We merged the first World Bank table to our initial one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. topic:: Note:\n\n   We set the ``add_match_info`` parameter to `True` to show distances\n   between the rows that have been matched, that we will use later to show\n   what are the worst matches.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that our |fj| succesfully identified the countries,\neven though some country names differ between tables.\n\nFor instance, \"Egypt\" and \"Egypt, Arab Rep.\" are correctly matched, as are\n\"Lesotho*\" and \"Lesotho\".\n\n.. topic:: Note:\n\n   This would all be missed out if we were using other methods such as\n   [pandas.merge](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge.html),\n   which can only find exact matches.\n   In this case, to reach the best result, we would have to `manually` clean\n   the data (e.g. remove the * after country name) and look\n   for matching patterns in every observation.\n\nLet's do some more inspection of the merging done.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's print the worst matches, which will give\nus an overview of the situation:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "augmented_df.sort_values(\"skrub_Joiner_rescaled_distance\").tail(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that some matches were unsuccesful\n(e.g \"Palestinian Territories*\" and \"Palau\"),\nbecause there is simply no match in the two tables.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this case, it is better to use the threshold parameter (``max_dist``)\nso as to include only precise-enough matches:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "augmented_df = fuzzy_join(\n    df,\n    gdp_per_capita,\n    left_on=\"Country\",\n    right_on=\"Country Name\",\n    max_dist=0.9,\n    add_match_info=True,\n)\naugmented_df.sort_values(\"skrub_Joiner_rescaled_distance\", ascending=False).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Matches that are not available (or precise enough) are marked as `NaN`.\nWe will remove them using the ``drop_unmatched`` parameter:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "augmented_df = fuzzy_join(\n    df,\n    gdp_per_capita,\n    left_on=\"Country\",\n    right_on=\"Country Name\",\n    drop_unmatched=True,\n    max_dist=0.9,\n    add_match_info=True,\n)\n\naugmented_df.drop(columns=[\"Country Name\"], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can finally plot and look at the link between GDP per capital\nand happiness:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_context(\"notebook\")\n\nplt.figure(figsize=(4, 3))\nax = sns.regplot(\n    data=augmented_df,\n    x=\"GDP per capita (current US$)\",\n    y=\"Happiness score\",\n    lowess=True,\n)\nax.set_ylabel(\"Happiness index\")\nax.set_title(\"Is a higher GDP per capita linked to happiness?\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It seems that the happiest countries are those\nhaving a high GDP per capita.\nHowever, unhappy countries do not have only low levels\nof GDP per capita. We have to search for other patterns.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Joining life expectancy table\n\nNow let's include other information that may be relevant, such as in the\nlife_exp table:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "augmented_df = fuzzy_join(\n    augmented_df,\n    life_exp,\n    left_on=\"Country\",\n    right_on=\"Country Name\",\n    max_dist=0.9,\n    add_match_info=True,\n)\n\naugmented_df.drop(columns=[\"Country Name\"], inplace=True)\n\naugmented_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot this relation:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(4, 3))\nfig = sns.regplot(\n    data=augmented_df,\n    x=\"Life expectancy at birth, total (years)\",\n    y=\"Happiness score\",\n    lowess=True,\n)\nfig.set_ylabel(\"Happiness index\")\nfig.set_title(\"Is a higher life expectancy linked to happiness?\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It seems the answer is yes!\nCountries with higher life expectancy are also happier.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Joining legal rights strength table\n\nAnd the table with a measure of legal rights strength in the country:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "augmented_df = fuzzy_join(\n    augmented_df,\n    legal_rights,\n    left_on=\"Country\",\n    right_on=\"Country Name\",\n    max_dist=0.9,\n    add_match_info=True,\n)\n\naugmented_df.drop(columns=[\"Country Name\"], inplace=True)\n\naugmented_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's take a look at their correspondence in a figure:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(4, 3))\nfig = sns.regplot(\n    data=augmented_df,\n    x=\"Strength of legal rights index (0=weak to 12=strong)\",\n    y=\"Happiness score\",\n    lowess=True,\n)\nfig.set_ylabel(\"Happiness index\")\nfig.set_title(\"Does a country's legal rights strength lead to happiness?\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From this plot, it is not clear that this measure of legal strength\nis linked to happiness.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Great! Our joined table has become bigger and full of useful information.\nAnd now we are ready to apply a first machine learning model to it!\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prediction model\n\nWe now separate our covariates (X), from the target (or exogenous)\nvariables: y.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y = augmented_df[\"Happiness score\"]\nX = augmented_df.drop([\"Happiness score\", \"Country\"], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us now define the model that will be used to predict the happiness score:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import HistGradientBoostingRegressor\nfrom sklearn.model_selection import KFold\n\nhgdb = HistGradientBoostingRegressor(random_state=0)\ncv = KFold(n_splits=5, shuffle=True, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To evaluate our model, we will apply a `5-fold cross-validation`.\nWe evaluate our model using the `R2` score.\n\nLet's finally assess the results of our models:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_validate\n\ncv_results_t = cross_validate(hgdb, X, y, cv=cv, scoring=\"r2\")\n\ncv_r2_t = cv_results_t[\"test_score\"]\n\nprint(f\"Mean R\u00b2 score is {cv_r2_t.mean():.2f} +- {cv_r2_t.std():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have a satisfying first result: an R\u00b2 of 0.63!\n\nData cleaning varies from dataset to dataset: there are as\nmany ways to clean a table as there are errors. |fj|\nmethod is generalizable across all datasets.\n\nData transformation is also often very costly in both time and ressources.\n|fj| is fast and easy-to-use.\n\nNow up to you, try improving our model by adding information into it and\nbeating our result!\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using the |joiner| to fuzzy join multiple tables\nA convenient way to merge different tables from the World Bank\nto `X` in a scikit-learn Pipeline and tune the parameters is to use the |joiner|.\n\nThe |joiner| is a transformer that can fuzzy-join a table on\na main table.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n### Instantiating the transformer\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y = df[\"Happiness score\"]\ndf = df.drop(\"Happiness score\", axis=1)\n\nfrom sklearn.pipeline import make_pipeline\n\nfrom skrub import Joiner, SelectCols\n\n# We create a selector that we will insert at the end of our pipeline, to\n# select the relevant columns before fitting the regressor\nselector = SelectCols(\n    [\n        \"GDP per capita (current US$) gdp\",\n        \"Life expectancy at birth, total (years) life_exp\",\n        \"Strength of legal rights index (0=weak to 12=strong) legal_rights\",\n    ]\n)\n\n# And we can now put together the pipeline\npipeline = make_pipeline(\n    Joiner(gdp_per_capita, main_key=\"Country\", aux_key=\"Country Name\", suffix=\" gdp\"),\n    Joiner(life_exp, main_key=\"Country\", aux_key=\"Country Name\", suffix=\" life_exp\"),\n    Joiner(\n        legal_rights, main_key=\"Country\", aux_key=\"Country Name\", suffix=\" legal_rights\"\n    ),\n    selector,\n    HistGradientBoostingRegressor(),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the best part is that we are now able to evaluate the parameters of the |fj|.\nFor instance, the ``match_score`` was manually picked and can now be\nintroduced into a grid search:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n\n# We will test 2 possible values of max_dist:\nparams = {\n    \"joiner-1__max_dist\": [0.1, 0.9],\n    \"joiner-2__max_dist\": [0.1, 0.9],\n    \"joiner-3__max_dist\": [0.1, 0.9],\n}\n\ngrid = GridSearchCV(pipeline, param_grid=params, cv=cv)\ngrid.fit(df, y)\n\nprint(\"Best parameters:\", grid.best_params_)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}