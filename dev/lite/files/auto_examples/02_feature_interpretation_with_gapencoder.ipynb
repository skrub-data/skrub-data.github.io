{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class='alert alert-warning'>\n\n# JupyterLite warning\n\nRunning the skrub examples in JupyterLite is experimental and you mayencounter some unexpected behavior.\n\nThe main difference is that imports will take a lot longer than usual, for example the first `import skrub` can take roughly 10-20s.\n\nIf you notice problems, feel free to open an [issue](https://github.com/skrub-data/skrub/issues/new/choose) about it.\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# JupyterLite-specific code\nimport micropip\nawait micropip.install('skrub')\n%pip install pyodide-http\nimport pyodide_http\npyodide_http.patch_all()\nimport matplotlib\nimport pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Feature interpretation with the GapEncoder\n\nIn this notebook, we will explore the output and inner workings of the\n|GapEncoder|, one of the [high cardinality categorical encoders](https://inria.hal.science/hal-02171256v4)\nprovided by skrub.\n\n.. |GapEncoder| replace::\n     :class:`~skrub.GapEncoder`\n\n.. |SimilarityEncoder| replace::\n     :class:`~skrub.SimilarityEncoder`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The |GapEncoder| is scalable and interpretable in terms of\nfinding latent categories, as we will show.\n\nFirst, let's retrieve the\n[employee salaries dataset](https://www.openml.org/d/42125):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skrub.datasets import fetch_employee_salaries\n\ndataset = fetch_employee_salaries()\n\n# Alias X and y\nX, y = dataset.X, dataset.y\n\nX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Encoding job titles\n\nLet's look at the job titles, the column containing dirty data we want to encode:\n\n.. topic:: Note:\n\n  Dirty data, as opposed to clean, are all non-curated categorical\n  columns with variations such as typos, abbreviations, duplications,\n  alternate naming conventions etc.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_dirty = X[\"employee_position_title\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's have a look at a sample of the job titles:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_dirty.sort_values().tail(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we create an instance of the |GapEncoder| with 10 components.\nThis means that the encoder will attempt to extract 10 latent topics\nfrom the input data:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skrub import GapEncoder\n\nenc = GapEncoder(n_components=10, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we fit the model on the dirty categorical data and transform it\nin order to obtain encoded vectors of size 10:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_enc = enc.fit_transform(X_dirty)\nX_enc.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interpreting encoded vectors\n\nThe |GapEncoder| can be understood as a continuous encoding\non a set of latent topics estimated from the data. The latent topics\nare built by capturing combinations of substrings that frequently\nco-occur, and encoded vectors correspond to their activations.\nTo interpret these latent topics, we select for each of them a few labels\nfrom the input data with the highest activations.\nIn the example below we select 3 labels to summarize each topic.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "topic_labels = enc.get_feature_names_out(n_labels=3)\nfor k, labels in enumerate(topic_labels):\n    print(f\"Topic n\u00b0{k}: {labels}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected, topics capture labels that frequently co-occur. For instance,\nthe labels \"firefighter\", \"rescuer\", \"rescue\" appear together in\n\"Firefighter/Rescuer III\", or \"Fire/Rescue Lieutenant\".\n\nWe can now understand the encoding of different samples.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nencoded_labels = enc.transform(X_dirty[:20])\nplt.figure(figsize=(8, 10))\nplt.imshow(encoded_labels)\nplt.xlabel(\"Latent topics\", size=12)\nplt.xticks(range(0, 10), labels=topic_labels, rotation=50, ha=\"right\")\nplt.ylabel(\"Data entries\", size=12)\nplt.yticks(range(0, 20), labels=X_dirty[:20].to_numpy().flatten())\nplt.colorbar().set_label(label=\"Topic activations\", size=12)\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, each dirty category encodes on a small number of topics,\nThese can thus be reliably used to summarize each topic, which are in\neffect latent categories captured from the data.\n\n## Conclusion\n\nIn this notebook, we have seen how to interpret the output of the\n|GapEncoder|, and how it can be used to summarize categorical variables\nas a set of latent topics.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}