{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class='alert alert-warning'>\n\n# JupyterLite warning\n\nRunning the skrub examples in JupyterLite is experimental and you mayencounter some unexpected behavior.\n\nThe main difference is that imports will take a lot longer than usual, for example the first `import skrub` can take roughly 10-20s.\n\nIf you notice problems, feel free to open an [issue](https://github.com/skrub-data/skrub/issues/new/choose) about it.\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# JupyterLite-specific code\nimport micropip\nawait micropip.install('https://test-files.pythonhosted.org/packages/3c/03/e1598c7abe536e56834f568f61497ad075d966c4c8fb7d0ad004b81e7bfc/skrub-0.0.1.dev1-py3-none-any.whl')\nimport matplotlib\nimport pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Handling datetime features with the DatetimeEncoder\n\nWe illustrate here how to handle datetime features with the\nDatetimeEncoder.\n\nThe |DtE| breaks down each datetime\nfeatures into several numerical features, by extracting relevant\ninformation from the datetime features, such as the month, the day\nof the week, the hour of the day, etc.\nUsed in the |TV|, which automatically detects\nthe datetime features, the |DtE| allows to\nhandle datetime features easily.\n\n\n.. |DtE| replace:: :class:`~skrub.DatetimeEncoder`\n\n.. |TV| replace:: :class:`~skrub.TableVectorizer`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import warnings\n\nwarnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Importing\n\nWe first fetch the dataset.\n\nWe want to predict the NO2 air concentration in different cities, based\non the date and the time of measurement.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n\ndata = pd.read_csv(\n    \"https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/air_quality_no2_long.csv\"  # noqa\n)\ny = data[\"value\"]\nX = data[[\"city\", \"date.utc\"]]\nX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Encoding the data to numerical representations\n\n### Encoders for categorical and datetime features\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n\nfrom skrub import DatetimeEncoder\n\ncat_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n# We encode dates using the day of the week as it is probably relevant,\n# but no longer than minutes: we are probably not interested in seconds\n# and below\ndatetime_encoder = DatetimeEncoder(add_day_of_the_week=True, extract_until=\"minute\")\n\nfrom sklearn.compose import make_column_transformer\n\ndatetime_columns = [\"date.utc\"]\ncategorical_columns = [\"city\"]\n\nencoder = make_column_transformer(\n    (cat_encoder, categorical_columns),\n    (datetime_encoder, datetime_columns),\n    remainder=\"drop\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Transforming the input data\nWe can see that the encoder is working as expected: the date feature has\nbeen replaced by features for the month, day, hour, and day of the week.\nNote that the year and minute features have been removed by the encoder\nbecause they are constant.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_ = encoder.fit_transform(X)\nencoder.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### One-liner with the |TV|\nThe |DtE| is used by default in the |TV|, which\nautomatically detects datetime features.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n\nfrom skrub import TableVectorizer\n\ntable_vec = TableVectorizer()\ntable_vec.fit_transform(X)\npprint(table_vec.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we want the day of the week, we can just replace |TV|'s default parameter:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "table_vec = TableVectorizer(\n    datetime_transformer=DatetimeEncoder(add_day_of_the_week=True),\n)\ntable_vec.fit_transform(X)\ntable_vec.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the |TV| is indeed using\na |DtE| for the datetime features.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pprint(table_vec.transformers_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predictions with date features\nFor prediction tasks, we recommend using the |TV| inside a\npipeline, combined with a model that uses the features extracted by the\n|DtE|.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom sklearn.ensemble import HistGradientBoostingRegressor\nfrom sklearn.pipeline import make_pipeline\n\ntable_vec = TableVectorizer(\n    datetime_transformer=DatetimeEncoder(add_day_of_the_week=True),\n)\nreg = HistGradientBoostingRegressor()\npipeline = make_pipeline(table_vec, reg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluating the model\nWhen using date and time features, we often care about predicting the future.\nIn this case, we have to be careful when evaluating our model, because\nstandard tools like cross-validation do not respect the time ordering.\nInstead, we can use the :class:`~sklearn.model_selection.TimeSeriesSplit`,\nwhich makes sure that the test set is always in the future.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X[\"date.utc\"] = pd.to_datetime(X[\"date.utc\"])\nsorted_indices = np.argsort(X[\"date.utc\"])\nX = X.iloc[sorted_indices]\ny = y.iloc[sorted_indices]\n\nfrom sklearn.model_selection import TimeSeriesSplit, cross_val_score\n\ncross_val_score(\n    pipeline,\n    X,\n    y,\n    scoring=\"neg_mean_squared_error\",\n    cv=TimeSeriesSplit(n_splits=5),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting the prediction\nThe mean squared error is not obvious to interpret, so we compare\nvisually the prediction of our model with the actual values.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nfrom matplotlib.dates import ConciseDateFormatter\n\nX_train = X[X[\"date.utc\"] < \"2019-06-01\"]\nX_test = X[X[\"date.utc\"] >= \"2019-06-01\"]\n\ny_train = y[X[\"date.utc\"] < \"2019-06-01\"]\ny_test = y[X[\"date.utc\"] >= \"2019-06-01\"]\n\npipeline.fit(X_train, y_train)\nfig, axs = plt.subplots(nrows=len(X_test.city.unique()), ncols=1, figsize=(12, 9))\n\nfor i, city in enumerate(X_test.city.unique()):\n    axs[i].plot(\n        X.loc[X.city == city, \"date.utc\"],\n        y.loc[X.city == city],\n        label=\"Actual\",\n    )\n    axs[i].plot(\n        X_test.loc[X_test.city == city, \"date.utc\"],\n        pipeline.predict(X_test.loc[X_test.city == city]),\n        label=\"Predicted\",\n    )\n    axs[i].set_title(city)\n    axs[i].set_ylabel(\"NO2\")\n    axs[i].xaxis.set_major_formatter(\n        ConciseDateFormatter(axs[i].xaxis.get_major_locator())\n    )\n    axs[i].legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's zoom on a few days:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_zoomed = X[X[\"date.utc\"] <= \"2019-06-04\"][X[\"date.utc\"] >= \"2019-06-01\"]\ny_zoomed = y[X[\"date.utc\"] <= \"2019-06-04\"][X[\"date.utc\"] >= \"2019-06-01\"]\n\nX_train_zoomed = X_zoomed[X_zoomed[\"date.utc\"] < \"2019-06-03\"]\nX_test_zoomed = X_zoomed[X_zoomed[\"date.utc\"] >= \"2019-06-03\"]\n\ny_train_zoomed = y[X[\"date.utc\"] < \"2019-06-03\"]\ny_test_zoomed = y[X[\"date.utc\"] >= \"2019-06-03\"]\n\npipeline.fit(X_train, y_train)\nfig, axs = plt.subplots(\n    nrows=len(X_test_zoomed.city.unique()), ncols=1, figsize=(12, 9)\n)\n\nfor i, city in enumerate(X_test_zoomed.city.unique()):\n    axs[i].plot(\n        X_zoomed.loc[X_zoomed.city == city, \"date.utc\"],\n        y_zoomed.loc[X_zoomed.city == city],\n        label=\"Actual\",\n    )\n    axs[i].plot(\n        X_test_zoomed.loc[X_test_zoomed.city == city, \"date.utc\"],\n        pipeline.predict(X_test_zoomed.loc[X_test_zoomed.city == city]),\n        label=\"Predicted\",\n    )\n    axs[i].set_title(city)\n    axs[i].set_ylabel(\"NO2\")\n    axs[i].xaxis.set_major_formatter(\n        ConciseDateFormatter(axs[i].xaxis.get_major_locator())\n    )\n    axs[i].legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature importances\nUsing the |DtE| allows us to better understand how the date\nimpacts the NO2 concentration. To this aim, we can compute the\nimportance of the features created by the |DtE|, using the\n:func:`~sklearn.inspection.permutation_importance` function, which\nbasically shuffles a feature and sees how the model changes its prediction.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.inspection import permutation_importance\n\ntable_vec = TableVectorizer(\n    datetime_transformer=DatetimeEncoder(add_day_of_the_week=True),\n)\n\n# In this case, we don't use a pipeline, because we want to compute the\n# importance of the features created by the DatetimeEncoder\nX_ = table_vec.fit_transform(X)\nreg = HistGradientBoostingRegressor().fit(X_, y)\nresult = permutation_importance(reg, X_, y, n_repeats=10, random_state=0)\nstd = result.importances_std\nimportances = result.importances_mean\nindices = np.argsort(importances)\n# Sort from least to most\nindices = list(reversed(indices))\n\nplt.figure(figsize=(12, 9))\nplt.title(\"Feature importances\")\nn = len(indices)\nlabels = np.array(table_vec.get_feature_names_out())[indices]\nplt.barh(range(n), importances[indices], color=\"b\", yerr=std[indices])\nplt.yticks(range(n), labels, size=15)\nplt.tight_layout(pad=1)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the hour of the day is the most important feature,\nwhich seems reasonable.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}