
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />
<meta property="og:title" content="skrub.GapEncoder" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://skrub-data.github.io/stable/generated/skrub.GapEncoder.html" />
<meta property="og:site_name" content="skrub" />
<meta property="og:description" content="Usage examples at the bottom of this page. Examples using skrub.GapEncoder: Dirty categories: machine learning with non normalized strings Investigating and interpreting dirty categories" />
<meta property="og:image" content="https://skrub-data.github.io/stable/_images/sphx_glr_01_dirty_categories_thumb.png" />
<meta property="og:image:alt" content="" />
<meta name="description" content="Usage examples at the bottom of this page. Examples using skrub.GapEncoder: Dirty categories: machine learning with non normalized strings Investigating and interpreting dirty categories" />

    <title>skrub.GapEncoder &#8212; skrub</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/scrolltoc.js"></script>
    <script src="../_static/stable_doc_redirect.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="skrub.MinHashEncoder" href="skrub.MinHashEncoder.html" />
    <link rel="prev" title="skrub.TableVectorizer" href="skrub.TableVectorizer.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><!--
    Inherited from the original Alabaster theme:
    https://github.com/bitprophet/alabaster/blob/master/alabaster/about.html
    Only the "Version" number is added.
-->

<div class="warn-banner">
    <p>
        This is the documentation for the unstable development version.<br />
        <a id="stable_page_link" href="https://skrub-data.github.io/stable/">Click here to go to the stable version documentation</a>.
    </p>
</div>


<p class="logo">
  <a href="../index.html">
    <img class="logo" src="../_static/skrub.svg" alt="Logo"/>
    
    <h1 class="logo logo-name">skrub</h1>
    
  </a>
  <div class="version-switcher">
    <h4>Version 0.0.1.dev0</h4>
    <details>
	<summary>Other versions</summary>
	<ul>
	    <li><a href="https://skrub-data.github.io/stable">Stable</a></li>
	    <li><a href="https://skrub-data.github.io/dev">Dev</a></li>
	</ul>
    </details>
  </div>
</p>






<p>
<iframe src="https://ghbtns.com/github-btn.html?user=skrub-data&repo=skrub&type=star&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<ul>
    <li class="toctree-l1"><a href="../index.html#usage-examples">Usage</a></li>
    <li class="toctree-l1"><a href="../index.html#api-documentation">API</a></li>
    <li class="toctree-l1"><a href="../index.html#about">About</a></li>
</ul>
  <h3 class="this-page"><a href="../index.html">This page</a></h3>
  <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skrub</span></code>.GapEncoder</a><ul>
<li><a class="reference internal" href="#examples-using-skrub-gapencoder">Examples using <code class="docutils literal notranslate"><span class="pre">skrub.GapEncoder</span></code></a></li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="skrub.TableVectorizer.html" title="previous chapter"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skrub</span></code>.TableVectorizer</a></li>
      <li>Next: <a href="skrub.MinHashEncoder.html" title="next chapter"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skrub</span></code>.MinHashEncoder</a></li>
  </ul></li>
</ul>
</div>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="skrub-gapencoder">
<h1><code class="xref py py-mod docutils literal notranslate"><span class="pre">skrub</span></code>.GapEncoder<a class="headerlink" href="#skrub-gapencoder" title="Permalink to this heading">¶</a></h1>
<p class="side-comment">Usage examples at the bottom of this page.</p>
<dl class="py class">
<dt class="sig sig-object py" id="skrub.GapEncoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">skrub.</span></span><span class="sig-name descname"><span class="pre">GapEncoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_components</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma_shape_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma_scale_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rho</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.95</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rescale_rho</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hashing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hashing_n_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4096</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'k-means++'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ngram_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(2,</span> <span class="pre">4)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">analyzer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'char'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_words</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rescale_W</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_e_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">handle_missing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'zero_impute'</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/skrub-data/skrub/blob/2f5f06e/skrub/_gap_encoder.py#L555"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skrub.GapEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs latent topics with continuous encoding.</p>
<p>This encoder can be understood as a continuous encoding on a set of latent
categories estimated from the data. The latent categories are built by
capturing combinations of substrings that frequently co-occur.</p>
<p>The <a class="reference internal" href="#skrub.GapEncoder" title="skrub.GapEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">GapEncoder</span></code></a> supports online learning on batches of
data for scalability through the <a class="reference internal" href="#skrub.GapEncoder.partial_fit" title="skrub.GapEncoder.partial_fit"><code class="xref py py-func docutils literal notranslate"><span class="pre">partial_fit()</span></code></a>
method.</p>
<p>The principle is as follows:</p>
<ol class="arabic simple">
<li><p>Given an input string array <cite>X</cite>, we build its bag-of-n-grams
representation <cite>V</cite> (<cite>n_samples</cite>, <cite>vocab_size</cite>).</p></li>
<li><p>Instead of using the n-grams counts as encodings, we look for low-
dimensional representations by modeling n-grams counts as linear
combinations of topics <code class="docutils literal notranslate"><span class="pre">V</span> <span class="pre">=</span> <span class="pre">HW</span></code>, with <cite>W</cite> (<cite>n_topics</cite>, <cite>vocab_size</cite>)
the topics and <cite>H</cite> (<cite>n_samples</cite>, <cite>n_topics</cite>) the associated activations.</p></li>
<li><p>Assuming that n-grams counts follow a Poisson law, we fit <cite>H</cite> and <cite>W</cite> to
maximize the likelihood of the data, with a Gamma prior for the
activations <cite>H</cite> to induce sparsity.</p></li>
<li><p>In practice, this is equivalent to a non-negative matrix factorization
with the Kullback-Leibler divergence as loss, and a Gamma prior on <cite>H</cite>.
We thus optimize <cite>H</cite> and <cite>W</cite> with the multiplicative update method.</p></li>
</ol>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>n_components</strong><span class="classifier">int, optional, default=10</span></dt><dd><p>Number of latent categories used to model string data.</p>
</dd>
<dt><strong>batch_size</strong><span class="classifier">int, optional, default=128</span></dt><dd><p>Number of samples per batch.</p>
</dd>
<dt><strong>gamma_shape_prior</strong><span class="classifier">float, optional, default=1.1</span></dt><dd><p>Shape parameter for the Gamma prior distribution.</p>
</dd>
<dt><strong>gamma_scale_prior</strong><span class="classifier">float, optional, default=1.0</span></dt><dd><p>Scale parameter for the Gamma prior distribution.</p>
</dd>
<dt><strong>rho</strong><span class="classifier">float, optional, default=0.95</span></dt><dd><p>Weight parameter for the update of the <cite>W</cite> matrix.</p>
</dd>
<dt><strong>rescale_rho</strong><span class="classifier">bool, optional, default=False</span></dt><dd><p>If <cite>True</cite>, use <code class="docutils literal notranslate"><span class="pre">rho</span> <span class="pre">**</span> <span class="pre">(batch_size</span> <span class="pre">/</span> <span class="pre">len(X))</span></code> instead of rho to obtain
an update rate per iteration that is independent of the batch size.</p>
</dd>
<dt><strong>hashing</strong><span class="classifier">bool, optional, default=False</span></dt><dd><p>If <cite>True</cite>, <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer" title="(in scikit-learn v1.2)"><code class="xref py py-class docutils literal notranslate"><span class="pre">HashingVectorizer</span></code></a>
is used instead of <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer" title="(in scikit-learn v1.2)"><code class="xref py py-class docutils literal notranslate"><span class="pre">CountVectorizer</span></code></a>.
It has the advantage of being very low memory, scalable to large
datasets as there is no need to store a vocabulary dictionary in
memory.</p>
</dd>
<dt><strong>hashing_n_features</strong><span class="classifier">int, default=2**12</span></dt><dd><p>Number of features for the
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer" title="(in scikit-learn v1.2)"><code class="xref py py-class docutils literal notranslate"><span class="pre">HashingVectorizer</span></code></a>.
Only relevant if <cite>hashing=True</cite>.</p>
</dd>
<dt><strong>init</strong><span class="classifier">{‘k-means++’, ‘random’, ‘k-means’}, default=’k-means++’</span></dt><dd><p>Initialization method of the <cite>W</cite> matrix.
If <cite>init=’k-means++’</cite>, we use the init method of
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans" title="(in scikit-learn v1.2)"><code class="xref py py-class docutils literal notranslate"><span class="pre">KMeans</span></code></a>.
If <cite>init=’random’</cite>, topics are initialized with a Gamma distribution.
If <cite>init=’k-means’</cite>, topics are initialized with a
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans" title="(in scikit-learn v1.2)"><code class="xref py py-class docutils literal notranslate"><span class="pre">KMeans</span></code></a> on the n-grams counts.</p>
</dd>
<dt><strong>tol</strong><span class="classifier">float, default=1e-4</span></dt><dd><p>Tolerance for the convergence of the matrix <cite>W</cite>.</p>
</dd>
<dt><strong>min_iter</strong><span class="classifier">int, default=2</span></dt><dd><p>Minimum number of iterations on the input data.</p>
</dd>
<dt><strong>max_iter</strong><span class="classifier">int, default=5</span></dt><dd><p>Maximum number of iterations on the input data.</p>
</dd>
<dt><strong>ngram_range</strong><span class="classifier">int 2-tuple, default=(2, 4)</span></dt><dd><dl class="simple">
<dt>The lower and upper boundaries of the range of n-values for different</dt><dd><p>n-grams used in the string similarity. All values of <cite>n</cite> such
that <code class="docutils literal notranslate"><span class="pre">min_n</span> <span class="pre">&lt;=</span> <span class="pre">n</span> <span class="pre">&lt;=</span> <span class="pre">max_n</span></code> will be used.</p>
</dd>
</dl>
</dd>
<dt><strong>analyzer</strong><span class="classifier">{‘word’, ‘char’, ‘char_wb’}, default=’char’</span></dt><dd><p>Analyzer parameter for the
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer" title="(in scikit-learn v1.2)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HashingVectorizer</span></code></a>
/ <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer" title="(in scikit-learn v1.2)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CountVectorizer</span></code></a>.
Describes whether the matrix <cite>V</cite> to factorize should be made of
word counts or character-level n-gram counts.
Option ‘char_wb’ creates character n-grams only from text inside word
boundaries; n-grams at the edges of words are padded with space.</p>
</dd>
<dt><strong>add_words</strong><span class="classifier">bool, default=False</span></dt><dd><p>If <cite>True</cite>, add the words counts to the bag-of-n-grams representation
of the input data.</p>
</dd>
<dt><strong>random_state</strong><span class="classifier">int or <a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(in NumPy v1.24)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RandomState</span></code></a>, optional</span></dt><dd><p>Random number generator seed for reproducible output across multiple
function calls.</p>
</dd>
<dt><strong>rescale_W</strong><span class="classifier">bool, default=True</span></dt><dd><p>If <cite>True</cite>, the weight matrix <cite>W</cite> is rescaled at each iteration
to have a l1 norm equal to 1 for each row.</p>
</dd>
<dt><strong>max_iter_e_step</strong><span class="classifier">int, default=20</span></dt><dd><p>Maximum number of iterations to adjust the activations h at each step.</p>
</dd>
<dt><strong>handle_missing</strong><span class="classifier">{‘error’, ‘empty_impute’}, default=’empty_impute’</span></dt><dd><p>Whether to raise an error or impute with empty string (‘’) if missing
values (NaN) are present during <a class="reference internal" href="#skrub.GapEncoder.fit" title="skrub.GapEncoder.fit"><code class="xref py py-func docutils literal notranslate"><span class="pre">fit()</span></code></a>
(default is to impute).
In <code class="xref py py-func docutils literal notranslate"><span class="pre">inverse_transform()</span></code>, the missing categories will
be denoted as <cite>None</cite>.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="skrub.MinHashEncoder.html#skrub.MinHashEncoder" title="skrub.MinHashEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">skrub.MinHashEncoder</span></code></a></dt><dd><p>Encode string columns as a numeric array with the minhash method.</p>
</dd>
<dt><a class="reference internal" href="skrub.SimilarityEncoder.html#skrub.SimilarityEncoder" title="skrub.SimilarityEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">skrub.SimilarityEncoder</span></code></a></dt><dd><p>Encode string columns as a numeric array with n-gram string similarity.</p>
</dd>
<dt><a class="reference internal" href="skrub.deduplicate.html#skrub.deduplicate" title="skrub.deduplicate"><code class="xref py py-class docutils literal notranslate"><span class="pre">skrub.deduplicate</span></code></a></dt><dd><p>Deduplicate data by hierarchically clustering similar strings.</p>
</dd>
</dl>
</div>
<p class="rubric">References</p>
<p>For a detailed description of the method, see
<a class="reference external" href="https://hal.inria.fr/hal-02171256v4">Encoding high-cardinality string categorical variables</a> by Cerda, Varoquaux (2019).</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span> <span class="o">=</span> <span class="n">GapEncoder</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p>Let’s encode the following non-normalized data:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;paris, FR&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Paris&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;London, UK&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Paris, France&#39;</span><span class="p">],</span>
<span class="go">         [&#39;london&#39;], [&#39;London, England&#39;], [&#39;London&#39;], [&#39;Pqris&#39;]]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">GapEncoder(n_components=2)</span>
</pre></div>
</div>
<p>The <a class="reference internal" href="#skrub.GapEncoder" title="skrub.GapEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">GapEncoder</span></code></a> has found the following two topics:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()</span>
<span class="go">[&#39;england, london, uk&#39;, &#39;france, paris, pqris&#39;]</span>
</pre></div>
</div>
<p>It got it right, reccuring topics are “London” and “England” on the
one side and “Paris” and “France” on the other.</p>
<p>As this is a continuous encoding, we can look at the level of
activation of each topic for each category:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([[ 0.05202843, 10.54797156],</span>
<span class="go">      [ 0.05000118,  4.54999882],</span>
<span class="go">      [12.04734788,  0.05265212],</span>
<span class="go">      [ 0.05263068, 16.54736932],</span>
<span class="go">      [ 6.04999624,  0.05000376],</span>
<span class="go">      [19.546716  ,  0.053284  ],</span>
<span class="go">      [ 6.04999623,  0.05000376],</span>
<span class="go">      [ 0.05002016,  4.54997983]])</span>
</pre></div>
</div>
<p>The higher the value, the bigger the correspondance with the topic.</p>
<dl class="field-list">
<dt class="field-odd">Attributes<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>rho_</strong><span class="classifier">float</span></dt><dd><p>Effective update rate for the <cite>W</cite> matrix.</p>
</dd>
<dt><strong>fitted_models_</strong><span class="classifier">list of <code class="xref py py-obj docutils literal notranslate"><span class="pre">GapEncoderColumn</span></code></span></dt><dd><p>Column-wise fitted GapEncoders.</p>
</dd>
<dt><strong>column_names_</strong><span class="classifier">list of str</span></dt><dd><p>Column names of the data the Gap was fitted on.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#skrub.GapEncoder.fit" title="skrub.GapEncoder.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(X[, y])</p></td>
<td><p>Fit the instance on X.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skrub.GapEncoder.fit_transform" title="skrub.GapEncoder.fit_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_transform</span></code></a>(X[, y])</p></td>
<td><p>Fit to data, then transform it.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skrub.GapEncoder.get_feature_names" title="skrub.GapEncoder.get_feature_names"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_feature_names</span></code></a>([col_names, n_labels, ...])</p></td>
<td><p>Return clean feature names.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skrub.GapEncoder.get_feature_names_out" title="skrub.GapEncoder.get_feature_names_out"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_feature_names_out</span></code></a>([col_names, n_labels, ...])</p></td>
<td><p>Return the labels that best summarize the learned components/topics.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skrub.GapEncoder.get_params" title="skrub.GapEncoder.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a>([deep])</p></td>
<td><p>Get parameters for this estimator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skrub.GapEncoder.partial_fit" title="skrub.GapEncoder.partial_fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">partial_fit</span></code></a>(X[, y])</p></td>
<td><p>Partial fit this instance on X.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skrub.GapEncoder.score" title="skrub.GapEncoder.score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">score</span></code></a>(X)</p></td>
<td><p>Score this instance on <cite>X</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skrub.GapEncoder.set_output" title="skrub.GapEncoder.set_output"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_output</span></code></a>(*[, transform])</p></td>
<td><p>Set output container.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skrub.GapEncoder.set_params" title="skrub.GapEncoder.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a>(**params)</p></td>
<td><p>Set the parameters of this estimator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skrub.GapEncoder.transform" title="skrub.GapEncoder.transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transform</span></code></a>(X)</p></td>
<td><p>Return the encoded vectors (activations) <cite>H</cite> of input strings in <cite>X</cite>.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="skrub.GapEncoder.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/skrub-data/skrub/blob/2f5f06e/skrub/_gap_encoder.py#L805"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skrub.GapEncoder.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the instance on X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like, shape (n_samples, n_features)</span></dt><dd><p>The string data to fit the model on.</p>
</dd>
<dt><strong>y</strong><span class="classifier">None</span></dt><dd><p>Unused, only here for compatibility.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><a class="reference internal" href="#skrub.GapEncoder" title="skrub.GapEncoder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GapEncoder</span></code></a></dt><dd><p>The fitted <a class="reference internal" href="#skrub.GapEncoder" title="skrub.GapEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">GapEncoder</span></code></a> instance (self).</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="skrub.GapEncoder.fit_transform">
<span class="sig-name descname"><span class="pre">fit_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">fit_params</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/skrub-data/skrub/blob/2f5f06e/skrub/../miniconda/envs/testenv/lib/python3.9/site-packages/sklearn/base.py#L850"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skrub.GapEncoder.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to <cite>X</cite> and <cite>y</cite> with optional parameters <cite>fit_params</cite>
and returns a transformed version of <cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like of shape (n_samples, n_features)</span></dt><dd><p>Input samples.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None</span></dt><dd><p>Target values (None for unsupervised transformations).</p>
</dd>
<dt><strong>**fit_params</strong><span class="classifier">dict</span></dt><dd><p>Additional fit parameters.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>X_new</strong><span class="classifier">ndarray array of shape (n_samples, n_features_new)</span></dt><dd><p>Transformed array.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="skrub.GapEncoder.get_feature_names">
<span class="sig-name descname"><span class="pre">get_feature_names</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">col_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/skrub-data/skrub/blob/2f5f06e/skrub/_gap_encoder.py#L958"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skrub.GapEncoder.get_feature_names" title="Permalink to this definition">¶</a></dt>
<dd><p>Return clean feature names. Compatibility method for sklearn &lt; 1.0.</p>
<p>Use <a class="reference internal" href="#skrub.GapEncoder.get_feature_names_out" title="skrub.GapEncoder.get_feature_names_out"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_feature_names_out()</span></code></a> instead.</p>
<p>For each topic, labels with the highest activations are selected.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>col_names</strong><span class="classifier">‘auto’ or list of str, optional</span></dt><dd><p>The column names to be added as prefixes before the labels.
If <cite>col_names=None</cite>, no prefixes are used.
If <cite>col_names=’auto’</cite>, column names are automatically defined:</p>
<blockquote>
<div><ul class="simple">
<li><p>if the input data was a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v2.0.1)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataFrame</span></code></a>,
its column names are used,</p></li>
<li><p>otherwise, ‘col1’, …, ‘colN’ are used as prefixes.</p></li>
</ul>
</div></blockquote>
<p>Prefixes can be manually set by passing a list for <cite>col_names</cite>.</p>
</dd>
<dt><strong>n_labels</strong><span class="classifier">int, default=3</span></dt><dd><p>The number of labels used to describe each topic.</p>
</dd>
<dt><strong>input_features</strong><span class="classifier">None</span></dt><dd><p>Unused, only here for compatibility.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>list of str</dt><dd><p>The labels that best describe each topic.
Each element contains the labels joined by a comma.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="skrub.GapEncoder.get_feature_names_out">
<span class="sig-name descname"><span class="pre">get_feature_names_out</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">col_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/skrub-data/skrub/blob/2f5f06e/skrub/_gap_encoder.py#L906"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skrub.GapEncoder.get_feature_names_out" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the labels that best summarize the learned components/topics.</p>
<p>For each topic, labels with the highest activations are selected.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>col_names</strong><span class="classifier">‘auto’ or list of str, optional</span></dt><dd><p>The column names to be added as prefixes before the labels.
If <cite>col_names=None</cite>, no prefixes are used.
If <cite>col_names=’auto’</cite>, column names are automatically defined:</p>
<blockquote>
<div><ul class="simple">
<li><p>if the input data was a <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v2.0.1)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataFrame</span></code></a>,
its column names are used,</p></li>
<li><p>otherwise, ‘col1’, …, ‘colN’ are used as prefixes.</p></li>
</ul>
</div></blockquote>
<p>Prefixes can be manually set by passing a list for <cite>col_names</cite>.</p>
</dd>
<dt><strong>n_labels</strong><span class="classifier">int, default=3</span></dt><dd><p>The number of labels used to describe each topic.</p>
</dd>
<dt><strong>input_features</strong><span class="classifier">None</span></dt><dd><p>Unused, only here for compatibility.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>list of str</dt><dd><p>The labels that best describe each topic.
Each element contains the labels joined by a comma.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="skrub.GapEncoder.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/skrub-data/skrub/blob/2f5f06e/skrub/../miniconda/envs/testenv/lib/python3.9/site-packages/sklearn/base.py#L153"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skrub.GapEncoder.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>deep</strong><span class="classifier">bool, default=True</span></dt><dd><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>params</strong><span class="classifier">dict</span></dt><dd><p>Parameter names mapped to their values.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="skrub.GapEncoder.partial_fit">
<span class="sig-name descname"><span class="pre">partial_fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/skrub-data/skrub/blob/2f5f06e/skrub/_gap_encoder.py#L871"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skrub.GapEncoder.partial_fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Partial fit this instance on X.</p>
<p>To be used in an online learning procedure where batches of data are
coming one by one.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like, shape (n_samples, n_features)</span></dt><dd><p>The string data to fit the model on.</p>
</dd>
<dt><strong>y</strong><span class="classifier">None</span></dt><dd><p>Unused, only here for compatibility.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><a class="reference internal" href="#skrub.GapEncoder" title="skrub.GapEncoder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GapEncoder</span></code></a></dt><dd><p>The fitted <a class="reference internal" href="#skrub.GapEncoder" title="skrub.GapEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">GapEncoder</span></code></a> instance (self).</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="skrub.GapEncoder.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/skrub-data/skrub/blob/2f5f06e/skrub/_gap_encoder.py#L1005"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skrub.GapEncoder.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score this instance on <cite>X</cite>.</p>
<p>Returns the sum over the columns of <cite>X</cite> of the Kullback-Leibler
divergence between the n-grams counts matrix <cite>V</cite> of <cite>X</cite>, and its
non-negative factorization <cite>HW</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like, shape (n_samples, n_features)</span></dt><dd><p>The data to encode.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>float</dt><dd><p>The Kullback-Leibler divergence.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="skrub.GapEncoder.set_output">
<span class="sig-name descname"><span class="pre">set_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/skrub-data/skrub/blob/2f5f06e/skrub/../miniconda/envs/testenv/lib/python3.9/site-packages/sklearn/utils/_set_output.py#L208"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skrub.GapEncoder.set_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Set output container.</p>
<p>See <a class="reference external" href="https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_set_output.html#sphx-glr-auto-examples-miscellaneous-plot-set-output-py" title="(in scikit-learn v1.2)"><span>Introducing the set_output API</span></a>
for an example on how to use the API.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>transform</strong><span class="classifier">{“default”, “pandas”}, default=None</span></dt><dd><p>Configure output of <cite>transform</cite> and <cite>fit_transform</cite>.</p>
<ul class="simple">
<li><p><cite>“default”</cite>: Default output format of a transformer</p></li>
<li><p><cite>“pandas”</cite>: DataFrame output</p></li>
<li><p><cite>None</cite>: Transform configuration is unchanged</p></li>
</ul>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">estimator instance</span></dt><dd><p>Estimator instance.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="skrub.GapEncoder.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/skrub-data/skrub/blob/2f5f06e/skrub/../miniconda/envs/testenv/lib/python3.9/site-packages/sklearn/base.py#L177"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skrub.GapEncoder.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="(in scikit-learn v1.2)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>). The latter have
parameters of the form <code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s
possible to update each component of a nested object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>**params</strong><span class="classifier">dict</span></dt><dd><p>Estimator parameters.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">estimator instance</span></dt><dd><p>Estimator instance.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="skrub.GapEncoder.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/skrub-data/skrub/blob/2f5f06e/skrub/_gap_encoder.py#L840"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skrub.GapEncoder.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the encoded vectors (activations) <cite>H</cite> of input strings in <cite>X</cite>.</p>
<p>Given the learnt topics <cite>W</cite>, the activations <cite>H</cite> are tuned to fit
<code class="docutils literal notranslate"><span class="pre">V</span> <span class="pre">=</span> <span class="pre">HW</span></code>. When <cite>X</cite> has several columns, they are encoded separately
and then concatenated.</p>
<p>Remark: calling transform multiple times in a row on the same
input <cite>X</cite> can give slightly different encodings. This is expected
due to a caching mechanism to speed things up.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like, shape (n_samples, n_features)</span></dt><dd><p>The string data to encode.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.24)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ndarray</span></code></a>, shape (n_samples, n_topics * n_features)</dt><dd><p>Transformed input.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<section id="examples-using-skrub-gapencoder">
<h2>Examples using <code class="docutils literal notranslate"><span class="pre">skrub.GapEncoder</span></code><a class="headerlink" href="#examples-using-skrub-gapencoder" title="Permalink to this heading">¶</a></h2>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Including strings that represent categories often calls for much data preparation. In particula..."><img alt="" src="../_images/sphx_glr_01_dirty_categories_thumb.png" />
<p><a class="reference internal" href="../auto_examples/01_dirty_categories.html#sphx-glr-auto-examples-01-dirty-categories-py"><span class="std std-ref">Dirty categories: machine learning with non normalized strings</span></a></p>
  <div class="sphx-glr-thumbnail-title">Dirty categories: machine learning with non normalized strings</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="What are dirty categorical variables and how can a good encoding help with statistical learning..."><img alt="" src="../_images/sphx_glr_02_investigating_dirty_categories_thumb.png" />
<p><a class="reference internal" href="../auto_examples/02_investigating_dirty_categories.html#sphx-glr-auto-examples-02-investigating-dirty-categories-py"><span class="std std-ref">Investigating and interpreting dirty categories</span></a></p>
  <div class="sphx-glr-thumbnail-title">Investigating and interpreting dirty categories</div>
</div></div><div class="clearer"></div></section>
</section>


          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2018-2023, the skrub developers.
      
      |
      <a href="../_sources/generated/skrub.GapEncoder.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>