
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/01_dirty_categories.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_01_dirty_categories.py>`
        to download the full example code or to run this example in your browser via JupyterLite or Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_01_dirty_categories.py:


Dirty categories: machine learning with non normalized strings
==============================================================

Including strings that represent categories often calls for much data
preparation. In particular categories may appear with many morphological
variants, when they have been manually input or assembled from diverse
sources.

Here we look at a dataset on wages [#]_ where the column 'Employee
Position Title' contains dirty categories. On such a column, standard
categorical encodings leads to very high dimensions and can lose
information on which categories are similar.

We investigate various encodings of this dirty column for the machine
learning workflow, predicting the 'Current Annual Salary' with gradient
boosted trees. First we manually assemble a complex encoder for the full
dataframe, after which we show a much simpler way, albeit with less fine
control.


.. [#] https://www.openml.org/d/42125


 .. |TV| replace::
     :class:`~skrub.TableVectorizer`

 .. |Pipeline| replace::
     :class:`~sklearn.pipeline.Pipeline`

 .. |OneHotEncoder| replace::
     :class:`~sklearn.preprocessing.OneHotEncoder`

 .. |ColumnTransformer| replace::
     :class:`~sklearn.compose.ColumnTransformer`

 .. |RandomForestRegressor| replace::
     :class:`~sklearn.ensemble.RandomForestRegressor`

 .. |Gap| replace::
     :class:`~skrub.GapEncoder`

 .. |MinHash| replace::
     :class:`~skrub.MinHashEncoder`

 .. |HGBR| replace::
     :class:`~sklearn.ensemble.HistGradientBoostingRegressor`

 .. |SE| replace::
     :class:`~skrub.SimilarityEncoder`

 .. |permutation importances| replace::
     :func:`~sklearn.inspection.permutation_importance`

.. GENERATED FROM PYTHON SOURCE LINES 57-61

The data
--------

We first retrieve the dataset:

.. GENERATED FROM PYTHON SOURCE LINES 61-65

.. code-block:: default

    from skrub.datasets import fetch_employee_salaries

    employee_salaries = fetch_employee_salaries()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /home/circleci/project/miniconda/envs/testenv/lib/python3.10/site-packages/skrub/datasets/_fetching.py:618: UserWarning: Could not find the dataset 42125 locally. Downloading it from OpenML; this might take a while... If it is interrupted, some files might be invalid/incomplete: if on the following run, the fetching raises errors, you can try fixing this issue by deleting the directory /home/circleci/skrub_data/openml.
      info = _fetch_openml_dataset(dataset_id, data_directory)




.. GENERATED FROM PYTHON SOURCE LINES 66-67

X, the input data (descriptions of employees):

.. GENERATED FROM PYTHON SOURCE LINES 67-70

.. code-block:: default

    X = employee_salaries.X
    X






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>gender</th>
          <th>department</th>
          <th>department_name</th>
          <th>division</th>
          <th>assignment_category</th>
          <th>employee_position_title</th>
          <th>date_first_hired</th>
          <th>year_first_hired</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>F</td>
          <td>POL</td>
          <td>Department of Police</td>
          <td>MSB Information Mgmt and Tech Division Records...</td>
          <td>Fulltime-Regular</td>
          <td>Office Services Coordinator</td>
          <td>09/22/1986</td>
          <td>1986</td>
        </tr>
        <tr>
          <th>1</th>
          <td>M</td>
          <td>POL</td>
          <td>Department of Police</td>
          <td>ISB Major Crimes Division Fugitive Section</td>
          <td>Fulltime-Regular</td>
          <td>Master Police Officer</td>
          <td>09/12/1988</td>
          <td>1988</td>
        </tr>
        <tr>
          <th>2</th>
          <td>F</td>
          <td>HHS</td>
          <td>Department of Health and Human Services</td>
          <td>Adult Protective and Case Management Services</td>
          <td>Fulltime-Regular</td>
          <td>Social Worker IV</td>
          <td>11/19/1989</td>
          <td>1989</td>
        </tr>
        <tr>
          <th>3</th>
          <td>M</td>
          <td>COR</td>
          <td>Correction and Rehabilitation</td>
          <td>PRRS Facility and Security</td>
          <td>Fulltime-Regular</td>
          <td>Resident Supervisor II</td>
          <td>05/05/2014</td>
          <td>2014</td>
        </tr>
        <tr>
          <th>4</th>
          <td>M</td>
          <td>HCA</td>
          <td>Department of Housing and Community Affairs</td>
          <td>Affordable Housing Programs</td>
          <td>Fulltime-Regular</td>
          <td>Planning Specialist III</td>
          <td>03/05/2007</td>
          <td>2007</td>
        </tr>
        <tr>
          <th>...</th>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
        </tr>
        <tr>
          <th>9223</th>
          <td>F</td>
          <td>HHS</td>
          <td>Department of Health and Human Services</td>
          <td>School Based Health Centers</td>
          <td>Fulltime-Regular</td>
          <td>Community Health Nurse II</td>
          <td>11/03/2015</td>
          <td>2015</td>
        </tr>
        <tr>
          <th>9224</th>
          <td>F</td>
          <td>FRS</td>
          <td>Fire and Rescue Services</td>
          <td>Human Resources Division</td>
          <td>Fulltime-Regular</td>
          <td>Fire/Rescue Division Chief</td>
          <td>11/28/1988</td>
          <td>1988</td>
        </tr>
        <tr>
          <th>9225</th>
          <td>M</td>
          <td>HHS</td>
          <td>Department of Health and Human Services</td>
          <td>Child and Adolescent Mental Health Clinic Serv...</td>
          <td>Parttime-Regular</td>
          <td>Medical Doctor IV - Psychiatrist</td>
          <td>04/30/2001</td>
          <td>2001</td>
        </tr>
        <tr>
          <th>9226</th>
          <td>M</td>
          <td>CCL</td>
          <td>County Council</td>
          <td>Council Central Staff</td>
          <td>Fulltime-Regular</td>
          <td>Manager II</td>
          <td>09/05/2006</td>
          <td>2006</td>
        </tr>
        <tr>
          <th>9227</th>
          <td>M</td>
          <td>DLC</td>
          <td>Department of Liquor Control</td>
          <td>Licensure, Regulation and Education</td>
          <td>Fulltime-Regular</td>
          <td>Alcohol/Tobacco Enforcement Specialist II</td>
          <td>01/30/2012</td>
          <td>2012</td>
        </tr>
      </tbody>
    </table>
    <p>9228 rows Ã— 8 columns</p>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 71-72

and y, our target column (the annual salary):

.. GENERATED FROM PYTHON SOURCE LINES 72-75

.. code-block:: default

    y = employee_salaries.y
    y.name





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    'current_annual_salary'



.. GENERATED FROM PYTHON SOURCE LINES 76-77

Now, let's carry out some basic preprocessing:

.. GENERATED FROM PYTHON SOURCE LINES 77-88

.. code-block:: default

    import pandas as pd
    import numpy as np

    X["date_first_hired"] = pd.to_datetime(X["date_first_hired"])
    X["year_first_hired"] = X["date_first_hired"].apply(lambda x: x.year)
    # Get a mask of the rows with missing values in 'gender'
    mask = X.isna()["gender"]
    # And remove them
    X.dropna(subset=["gender"], inplace=True)
    y = y[~mask]








.. GENERATED FROM PYTHON SOURCE LINES 89-94

Assembling a machine-learning pipeline that encodes the data
------------------------------------------------------------

To build a learning pipeline, we need to assemble encoders for each
column, and apply a supervised learning model on top.

.. GENERATED FROM PYTHON SOURCE LINES 96-101

The categorical encoders
........................

An encoder is needed to turn a categorical column into a numerical
representation:

.. GENERATED FROM PYTHON SOURCE LINES 101-105

.. code-block:: default

    from sklearn.preprocessing import OneHotEncoder

    one_hot = OneHotEncoder(handle_unknown="ignore", sparse_output=False)








.. GENERATED FROM PYTHON SOURCE LINES 106-109

We assemble these to apply them to the relevant columns.
The |ColumnTransformer| is created by specifying a set of transformers
alongside with the column names on which each must be applied:

.. GENERATED FROM PYTHON SOURCE LINES 109-120

.. code-block:: default


    from sklearn.compose import make_column_transformer

    encoder = make_column_transformer(
        (one_hot, ["gender", "department_name", "assignment_category"]),
        ("passthrough", ["year_first_hired"]),
        # Last but not least, our dirty column
        (one_hot, ["employee_position_title"]),
        remainder="drop",
    )








.. GENERATED FROM PYTHON SOURCE LINES 121-126

Pipelining an encoder with a learner
....................................

We will use a |HGBR|,
which is a good predictor for data with heterogeneous columns

.. GENERATED FROM PYTHON SOURCE LINES 126-134

.. code-block:: default


    from sklearn.ensemble import HistGradientBoostingRegressor

    # We then create a pipeline chaining our encoders to a learner
    from sklearn.pipeline import make_pipeline

    pipeline = make_pipeline(encoder, HistGradientBoostingRegressor())








.. GENERATED FROM PYTHON SOURCE LINES 135-136

The pipeline can be readily applied to the dataframe for prediction:

.. GENERATED FROM PYTHON SOURCE LINES 136-138

.. code-block:: default

    pipeline.fit(X, y)






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "â–¸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "â–¾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,
                     ColumnTransformer(transformers=[(&#x27;onehotencoder-1&#x27;,
                                                      OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,
                                                                    sparse_output=False),
                                                      [&#x27;gender&#x27;, &#x27;department_name&#x27;,
                                                       &#x27;assignment_category&#x27;]),
                                                     (&#x27;passthrough&#x27;, &#x27;passthrough&#x27;,
                                                      [&#x27;year_first_hired&#x27;]),
                                                     (&#x27;onehotencoder-2&#x27;,
                                                      OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,
                                                                    sparse_output=False),
                                                      [&#x27;employee_position_title&#x27;])])),
                    (&#x27;histgradientboostingregressor&#x27;,
                     HistGradientBoostingRegressor())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" ><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,
                     ColumnTransformer(transformers=[(&#x27;onehotencoder-1&#x27;,
                                                      OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,
                                                                    sparse_output=False),
                                                      [&#x27;gender&#x27;, &#x27;department_name&#x27;,
                                                       &#x27;assignment_category&#x27;]),
                                                     (&#x27;passthrough&#x27;, &#x27;passthrough&#x27;,
                                                      [&#x27;year_first_hired&#x27;]),
                                                     (&#x27;onehotencoder-2&#x27;,
                                                      OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,
                                                                    sparse_output=False),
                                                      [&#x27;employee_position_title&#x27;])])),
                    (&#x27;histgradientboostingregressor&#x27;,
                     HistGradientBoostingRegressor())])</pre></div></div></div><div class="sk-serial"><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" ><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">columntransformer: ColumnTransformer</label><div class="sk-toggleable__content"><pre>ColumnTransformer(transformers=[(&#x27;onehotencoder-1&#x27;,
                                     OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,
                                                   sparse_output=False),
                                     [&#x27;gender&#x27;, &#x27;department_name&#x27;,
                                      &#x27;assignment_category&#x27;]),
                                    (&#x27;passthrough&#x27;, &#x27;passthrough&#x27;,
                                     [&#x27;year_first_hired&#x27;]),
                                    (&#x27;onehotencoder-2&#x27;,
                                     OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,
                                                   sparse_output=False),
                                     [&#x27;employee_position_title&#x27;])])</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" ><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">onehotencoder-1</label><div class="sk-toggleable__content"><pre>[&#x27;gender&#x27;, &#x27;department_name&#x27;, &#x27;assignment_category&#x27;]</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox" ><label for="sk-estimator-id-4" class="sk-toggleable__label sk-toggleable__label-arrow">OneHotEncoder</label><div class="sk-toggleable__content"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div></div><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-5" type="checkbox" ><label for="sk-estimator-id-5" class="sk-toggleable__label sk-toggleable__label-arrow">passthrough</label><div class="sk-toggleable__content"><pre>[&#x27;year_first_hired&#x27;]</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-6" type="checkbox" ><label for="sk-estimator-id-6" class="sk-toggleable__label sk-toggleable__label-arrow">passthrough</label><div class="sk-toggleable__content"><pre>passthrough</pre></div></div></div></div></div></div><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-7" type="checkbox" ><label for="sk-estimator-id-7" class="sk-toggleable__label sk-toggleable__label-arrow">onehotencoder-2</label><div class="sk-toggleable__content"><pre>[&#x27;employee_position_title&#x27;]</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-8" type="checkbox" ><label for="sk-estimator-id-8" class="sk-toggleable__label sk-toggleable__label-arrow">OneHotEncoder</label><div class="sk-toggleable__content"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-9" type="checkbox" ><label for="sk-estimator-id-9" class="sk-toggleable__label sk-toggleable__label-arrow">HistGradientBoostingRegressor</label><div class="sk-toggleable__content"><pre>HistGradientBoostingRegressor()</pre></div></div></div></div></div></div></div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 139-144

Dirty category encoding
-----------------------

The |OneHotEncoder| is actually not well suited to the 'Employee
Position Title' column, as this column contains 400 different entries:

.. GENERATED FROM PYTHON SOURCE LINES 144-146

.. code-block:: default

    X["employee_position_title"].value_counts()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    employee_position_title
    Bus Operator                                         638
    Police Officer III                                   620
    Firefighter/Rescuer III                              388
    Manager III                                          243
    Firefighter/Rescuer II                               219
                                                        ... 
    SCBA Technician                                        1
    Senior Water Quality Specialist                        1
    Director Office of Human Resources                     1
    Director Criminal Justice Coordinating Commission      1
    Legal Secretary I                                      1
    Name: count, Length: 442, dtype: int64



.. GENERATED FROM PYTHON SOURCE LINES 147-151

.. _example_minhash_encoder:

We will now experiment with encoders specially made for handling
dirty columns:

.. GENERATED FROM PYTHON SOURCE LINES 151-162

.. code-block:: default


    from skrub import GapEncoder, MinHashEncoder, SimilarityEncoder, TargetEncoder

    encoders = {
        "one-hot": one_hot,
        "similarity": SimilarityEncoder(),
        "target": TargetEncoder(handle_unknown="ignore"),
        "minhash": MinHashEncoder(n_components=100),
        "gap": GapEncoder(n_components=100),
    }








.. GENERATED FROM PYTHON SOURCE LINES 163-166

We now loop over the different encoding methods,
instantiate a new |Pipeline| each time, fit it
and store the returned cross-validation score:

.. GENERATED FROM PYTHON SOURCE LINES 166-186

.. code-block:: default


    from sklearn.model_selection import cross_val_score

    all_scores = dict()

    for name, method in encoders.items():
        encoder = make_column_transformer(
            (one_hot, ["gender", "department_name", "assignment_category"]),
            ("passthrough", ["year_first_hired"]),
            # Last but not least, our dirty column
            (method, ["employee_position_title"]),
            remainder="drop",
        )

        pipeline = make_pipeline(encoder, HistGradientBoostingRegressor())
        scores = cross_val_score(pipeline, X, y)
        print(f"{name} encoding")
        print(f"r2 score:  mean: {np.mean(scores):.3f}; std: {np.std(scores):.3f}\n")
        all_scores[name] = scores





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    one-hot encoding
    r2 score:  mean: 0.770; std: 0.032

    similarity encoding
    r2 score:  mean: 0.928; std: 0.014

    target encoding
    r2 score:  mean: 0.846; std: 0.031

    /home/circleci/project/miniconda/envs/testenv/lib/python3.10/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but MinHashEncoder was fitted with feature names
      warnings.warn(
    /home/circleci/project/miniconda/envs/testenv/lib/python3.10/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but MinHashEncoder was fitted with feature names
      warnings.warn(
    /home/circleci/project/miniconda/envs/testenv/lib/python3.10/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but MinHashEncoder was fitted with feature names
      warnings.warn(
    /home/circleci/project/miniconda/envs/testenv/lib/python3.10/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but MinHashEncoder was fitted with feature names
      warnings.warn(
    /home/circleci/project/miniconda/envs/testenv/lib/python3.10/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but MinHashEncoder was fitted with feature names
      warnings.warn(
    /home/circleci/project/miniconda/envs/testenv/lib/python3.10/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but MinHashEncoder was fitted with feature names
      warnings.warn(
    /home/circleci/project/miniconda/envs/testenv/lib/python3.10/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but MinHashEncoder was fitted with feature names
      warnings.warn(
    /home/circleci/project/miniconda/envs/testenv/lib/python3.10/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but MinHashEncoder was fitted with feature names
      warnings.warn(
    /home/circleci/project/miniconda/envs/testenv/lib/python3.10/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but MinHashEncoder was fitted with feature names
      warnings.warn(
    /home/circleci/project/miniconda/envs/testenv/lib/python3.10/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but MinHashEncoder was fitted with feature names
      warnings.warn(
    minhash encoding
    r2 score:  mean: 0.923; std: 0.013

    gap encoding
    r2 score:  mean: 0.927; std: 0.016





.. GENERATED FROM PYTHON SOURCE LINES 187-191

Plotting the results
....................

Finally, we plot the scores on a boxplot:

.. GENERATED FROM PYTHON SOURCE LINES 191-202

.. code-block:: default


    import matplotlib.pyplot as plt
    import seaborn

    plt.figure(figsize=(4, 3))
    ax = seaborn.boxplot(data=pd.DataFrame(all_scores), orient="h")
    plt.ylabel("Encoding", size=20)
    plt.xlabel("Prediction accuracy     ", size=20)
    plt.yticks(size=20)
    plt.tight_layout()




.. image-sg:: /auto_examples/images/sphx_glr_01_dirty_categories_001.png
   :alt: 01 dirty categories
   :srcset: /auto_examples/images/sphx_glr_01_dirty_categories_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /home/circleci/project/miniconda/envs/testenv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead
      if pd.api.types.is_categorical_dtype(vector):
    /home/circleci/project/miniconda/envs/testenv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead
      if pd.api.types.is_categorical_dtype(vector):
    /home/circleci/project/miniconda/envs/testenv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead
      if pd.api.types.is_categorical_dtype(vector):
    /home/circleci/project/miniconda/envs/testenv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead
      if pd.api.types.is_categorical_dtype(vector):
    /home/circleci/project/miniconda/envs/testenv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead
      if pd.api.types.is_categorical_dtype(vector):




.. GENERATED FROM PYTHON SOURCE LINES 203-214

The clear trend is that encoders grasping similarities between categories
(|SE|, |MinHash|, and |Gap|) perform better than those discarding it.

|SE| is the best performer, but it is less scalable on big
data than the |MinHash| and |Gap|. The most scalable encoder is
the |MinHash|. On the other hand, the |Gap| has the benefit of
providing interpretable features
(see :ref:`sphx_glr_auto_examples_02_investigating_dirty_categories.py`)

|


.. GENERATED FROM PYTHON SOURCE LINES 216-225

.. _example_table_vectorizer:

A simpler way: automatic vectorization
--------------------------------------

The code to assemble a column transformer is a bit tedious. We will
now explore a simpler, automated, way of encoding the data.

Let's start again from the raw data:

.. GENERATED FROM PYTHON SOURCE LINES 225-229

.. code-block:: default

    employee_salaries = fetch_employee_salaries()
    X = employee_salaries.X
    y = employee_salaries.y








.. GENERATED FROM PYTHON SOURCE LINES 230-232

We'll drop the 'date_first_hired' column as it's redundant with
'year_first_hired'.

.. GENERATED FROM PYTHON SOURCE LINES 232-234

.. code-block:: default

    X = X.drop(["date_first_hired"], axis=1)








.. GENERATED FROM PYTHON SOURCE LINES 235-236

We still have a complex and heterogeneous dataframe:

.. GENERATED FROM PYTHON SOURCE LINES 236-238

.. code-block:: default

    X






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>gender</th>
          <th>department</th>
          <th>department_name</th>
          <th>division</th>
          <th>assignment_category</th>
          <th>employee_position_title</th>
          <th>year_first_hired</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>F</td>
          <td>POL</td>
          <td>Department of Police</td>
          <td>MSB Information Mgmt and Tech Division Records...</td>
          <td>Fulltime-Regular</td>
          <td>Office Services Coordinator</td>
          <td>1986</td>
        </tr>
        <tr>
          <th>1</th>
          <td>M</td>
          <td>POL</td>
          <td>Department of Police</td>
          <td>ISB Major Crimes Division Fugitive Section</td>
          <td>Fulltime-Regular</td>
          <td>Master Police Officer</td>
          <td>1988</td>
        </tr>
        <tr>
          <th>2</th>
          <td>F</td>
          <td>HHS</td>
          <td>Department of Health and Human Services</td>
          <td>Adult Protective and Case Management Services</td>
          <td>Fulltime-Regular</td>
          <td>Social Worker IV</td>
          <td>1989</td>
        </tr>
        <tr>
          <th>3</th>
          <td>M</td>
          <td>COR</td>
          <td>Correction and Rehabilitation</td>
          <td>PRRS Facility and Security</td>
          <td>Fulltime-Regular</td>
          <td>Resident Supervisor II</td>
          <td>2014</td>
        </tr>
        <tr>
          <th>4</th>
          <td>M</td>
          <td>HCA</td>
          <td>Department of Housing and Community Affairs</td>
          <td>Affordable Housing Programs</td>
          <td>Fulltime-Regular</td>
          <td>Planning Specialist III</td>
          <td>2007</td>
        </tr>
        <tr>
          <th>...</th>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
        </tr>
        <tr>
          <th>9223</th>
          <td>F</td>
          <td>HHS</td>
          <td>Department of Health and Human Services</td>
          <td>School Based Health Centers</td>
          <td>Fulltime-Regular</td>
          <td>Community Health Nurse II</td>
          <td>2015</td>
        </tr>
        <tr>
          <th>9224</th>
          <td>F</td>
          <td>FRS</td>
          <td>Fire and Rescue Services</td>
          <td>Human Resources Division</td>
          <td>Fulltime-Regular</td>
          <td>Fire/Rescue Division Chief</td>
          <td>1988</td>
        </tr>
        <tr>
          <th>9225</th>
          <td>M</td>
          <td>HHS</td>
          <td>Department of Health and Human Services</td>
          <td>Child and Adolescent Mental Health Clinic Serv...</td>
          <td>Parttime-Regular</td>
          <td>Medical Doctor IV - Psychiatrist</td>
          <td>2001</td>
        </tr>
        <tr>
          <th>9226</th>
          <td>M</td>
          <td>CCL</td>
          <td>County Council</td>
          <td>Council Central Staff</td>
          <td>Fulltime-Regular</td>
          <td>Manager II</td>
          <td>2006</td>
        </tr>
        <tr>
          <th>9227</th>
          <td>M</td>
          <td>DLC</td>
          <td>Department of Liquor Control</td>
          <td>Licensure, Regulation and Education</td>
          <td>Fulltime-Regular</td>
          <td>Alcohol/Tobacco Enforcement Specialist II</td>
          <td>2012</td>
        </tr>
      </tbody>
    </table>
    <p>9228 rows Ã— 7 columns</p>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 239-241

The |TV| can to turn this dataframe into a form suited for
machine learning.

.. GENERATED FROM PYTHON SOURCE LINES 243-252

Using the TableVectorizer in a supervised-learning pipeline
-----------------------------------------------------------

Assembling the |TV| in a |Pipeline| with a powerful learner,
such as gradient boosted trees, gives **a machine-learning method that
can be readily applied to the dataframe**.

The |TV| requires at least skrub 0.2.0.


.. GENERATED FROM PYTHON SOURCE LINES 252-259

.. code-block:: default


    from skrub import TableVectorizer

    pipeline = make_pipeline(
        TableVectorizer(auto_cast=True), HistGradientBoostingRegressor()
    )








.. GENERATED FROM PYTHON SOURCE LINES 260-261

Let's perform a cross-validation to see how well this model predicts:

.. GENERATED FROM PYTHON SOURCE LINES 261-270

.. code-block:: default


    from sklearn.model_selection import cross_val_score

    scores = cross_val_score(pipeline, X, y, scoring="r2")

    print(f"scores={scores}")
    print(f"mean={np.mean(scores)}")
    print(f"std={np.std(scores)}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    scores=[0.9205234  0.89794896 0.92917836 0.93122637 0.94167259]
    mean=0.9241099356081441
    std=0.014710808188510938




.. GENERATED FROM PYTHON SOURCE LINES 271-274

The prediction performed here is pretty much as good as above
but the code here is much simpler as it does not involve specifying
columns manually.

.. GENERATED FROM PYTHON SOURCE LINES 276-281

Analyzing the features created
------------------------------

Let us perform the same workflow, but without the |Pipeline|, so we can
analyze the TableVectorizer's mechanisms along the way.

.. GENERATED FROM PYTHON SOURCE LINES 281-283

.. code-block:: default

    table_vec = TableVectorizer(auto_cast=True)








.. GENERATED FROM PYTHON SOURCE LINES 284-285

We split the data between train and test, and transform them:

.. GENERATED FROM PYTHON SOURCE LINES 285-294

.. code-block:: default

    from sklearn.model_selection import train_test_split

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.15, random_state=42
    )

    X_train_enc = table_vec.fit_transform(X_train, y_train)
    X_test_enc = table_vec.transform(X_test)








.. GENERATED FROM PYTHON SOURCE LINES 295-296

The encoded data, X_train_enc and X_test_enc are numerical arrays:

.. GENERATED FROM PYTHON SOURCE LINES 296-298

.. code-block:: default

    X_train_enc





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    array([[2.00700000e+03, 0.00000000e+00, 1.00000000e+00, ...,
            7.63869544e-02, 2.46631408e-01, 1.09143696e-01],
           [2.00500000e+03, 1.00000000e+00, 0.00000000e+00, ...,
            5.21855743e-02, 5.28769154e-02, 5.41137780e-02],
           [2.00900000e+03, 1.00000000e+00, 0.00000000e+00, ...,
            1.19205694e-01, 1.66445307e+01, 7.87429987e-02],
           ...,
           [1.99000000e+03, 1.00000000e+00, 0.00000000e+00, ...,
            6.43799193e-02, 5.26213923e-01, 5.84094513e-02],
           [2.01200000e+03, 0.00000000e+00, 1.00000000e+00, ...,
            6.35239618e-02, 6.60446028e-02, 6.94921503e-02],
           [2.01400000e+03, 1.00000000e+00, 0.00000000e+00, ...,
            5.34402020e-02, 6.10590242e-02, 5.32311196e-02]])



.. GENERATED FROM PYTHON SOURCE LINES 299-300

They have more columns than the original dataframe, but not much more:

.. GENERATED FROM PYTHON SOURCE LINES 300-302

.. code-block:: default

    X_train.shape, X_train_enc.shape





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    ((7843, 7), (7843, 139))



.. GENERATED FROM PYTHON SOURCE LINES 303-308

Inspecting the features created
...............................

The |TV| assigns a transformer for each column. We can inspect this
choice:

.. GENERATED FROM PYTHON SOURCE LINES 308-312

.. code-block:: default

    from pprint import pprint

    pprint(table_vec.transformers_)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [('numeric', 'passthrough', ['year_first_hired']),
     ('low_card_cat',
      OneHotEncoder(drop='if_binary', handle_unknown='infrequent_if_exist'),
      ['gender', 'department', 'department_name', 'assignment_category']),
     ('high_card_cat',
      GapEncoder(n_components=30),
      ['division', 'employee_position_title'])]




.. GENERATED FROM PYTHON SOURCE LINES 313-326

This is what is being passed to the |ColumnTransformer| under the hood.
If you're familiar with how the latter works, it should be very intuitive.
We can notice it classified the columns 'gender' and 'assignment_category'
as low cardinality string variables.
A |OneHotEncoder| will be applied to these columns.

The vectorizer actually makes the difference between string variables
(data type ``object`` and ``string``) and categorical variables
(data type ``category``).

Next, we can have a look at the encoded feature names.

Before encoding:

.. GENERATED FROM PYTHON SOURCE LINES 326-328

.. code-block:: default

    X.columns.to_list()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    ['gender', 'department', 'department_name', 'division', 'assignment_category', 'employee_position_title', 'year_first_hired']



.. GENERATED FROM PYTHON SOURCE LINES 329-330

After encoding (we only plot the first 8 feature names):

.. GENERATED FROM PYTHON SOURCE LINES 330-333

.. code-block:: default

    feature_names = table_vec.get_feature_names_out()
    feature_names[:8]





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    ['year_first_hired', 'gender_F', 'gender_M', 'gender_nan', 'department_BOA', 'department_BOE', 'department_CAT', 'department_CCL']



.. GENERATED FROM PYTHON SOURCE LINES 334-340

As we can see, it gave us interpretable columns.
This is because we used the |Gap| on the column 'division',
which was classified as a high cardinality string variable.
(default values, see |TV|'s docstring).

In total, we have a reasonable number of encoded columns:

.. GENERATED FROM PYTHON SOURCE LINES 340-343

.. code-block:: default

    len(feature_names)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    139



.. GENERATED FROM PYTHON SOURCE LINES 344-356

Feature importances in the statistical model
--------------------------------------------

In this section, we will train a regressor, and plot the feature importances.

.. topic:: Note:

   To minimize computation time, we use the feature importances computed by the
   |RandomForestRegressor|, but you should prefer |permutation importances|
   instead (which are less subject to biases).

First, let's train the |RandomForestRegressor|:

.. GENERATED FROM PYTHON SOURCE LINES 356-362

.. code-block:: default


    from sklearn.ensemble import RandomForestRegressor

    regressor = RandomForestRegressor()
    regressor.fit(X_train_enc, y_train)






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: "â–¸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "â–¾";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-10" type="checkbox" checked><label for="sk-estimator-id-10" class="sk-toggleable__label sk-toggleable__label-arrow">RandomForestRegressor</label><div class="sk-toggleable__content"><pre>RandomForestRegressor()</pre></div></div></div></div></div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 363-364

Retrieving the feature importances:

.. GENERATED FROM PYTHON SOURCE LINES 364-371

.. code-block:: default


    importances = regressor.feature_importances_
    std = np.std([tree.feature_importances_ for tree in regressor.estimators_], axis=0)
    indices = np.argsort(importances)
    # Sort from least to most
    indices = list(reversed(indices))








.. GENERATED FROM PYTHON SOURCE LINES 372-373

Plotting the results:

.. GENERATED FROM PYTHON SOURCE LINES 373-386

.. code-block:: default


    import matplotlib.pyplot as plt

    plt.figure(figsize=(12, 9))
    plt.title("Feature importances")
    n = 20
    n_indices = indices[:n]
    labels = np.array(feature_names)[n_indices]
    plt.barh(range(n), importances[n_indices], color="b", yerr=std[n_indices])
    plt.yticks(range(n), labels, size=15)
    plt.tight_layout(pad=1)
    plt.show()




.. image-sg:: /auto_examples/images/sphx_glr_01_dirty_categories_002.png
   :alt: Feature importances
   :srcset: /auto_examples/images/sphx_glr_01_dirty_categories_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 387-398

We can deduce from this data that the three factors that define the
most the salary are: being hired for a long time, being a manager, and
having a permanent, full-time job :)


.. topic:: The |TV| automates preprocessing

  As this notebook demonstrates, many preprocessing steps can be
  automated by the |TV|, and the resulting pipeline can still be
  inspected, even with non-normalized entries.



.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (2 minutes 11.797 seconds)


.. _sphx_glr_download_auto_examples_01_dirty_categories.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/skrub-data/skrub/main?urlpath=lab/tree/notebooks/auto_examples/01_dirty_categories.ipynb
        :alt: Launch binder
        :width: 150 px



    .. container:: lite-badge

      .. image:: images/jupyterlite_badge_logo.svg
        :target: ../lite/lab/?path=auto_examples/01_dirty_categories.ipynb
        :alt: Launch JupyterLite
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: 01_dirty_categories.py <01_dirty_categories.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: 01_dirty_categories.ipynb <01_dirty_categories.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
