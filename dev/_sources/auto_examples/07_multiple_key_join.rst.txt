
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/07_multiple_key_join.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_07_multiple_key_join.py>`
        to download the full example code. or to run this example in your browser via JupyterLite or Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_07_multiple_key_join.py:


.. _example_multiple_key_join :

Spatial join for flight data: Joining across multiple columns
=============================================================

Joining tables may be difficult if one entry on one side does not have
an exact match on the other side.

This problem becomes even more complex when multiple columns
are significant for the join. For instance, this is the case
for **spatial joins** on two columns, typically
longitude and latitude.

|joiner| is a scikit-learn compatible transformer that enables
performing joins across multiple keys,
independently of the data type (numerical, string or mixed).

The following example uses US domestic flights data
to illustrate how space and time information from a
pool of tables are combined for machine learning.

.. |fj| replace:: :func:`~skrub.fuzzy_join`

.. |joiner| replace:: :func:`~skrub.Joiner`

.. |Pipeline| replace::
     :class:`~sklearn.pipeline.Pipeline`

.. GENERATED FROM PYTHON SOURCE LINES 32-38

Flight-delays data
------------------
The goal is to predict flight delays.
We have a pool of tables that we will use to improve our prediction.

The following tables are at our disposal:

.. GENERATED FROM PYTHON SOURCE LINES 40-45

The main table: flights dataset
...............................
    - The `flights` datasets. It contains all US flights date, origin
      and destination airports and flight time.
      Here, we consider only flights from 2008.

.. GENERATED FROM PYTHON SOURCE LINES 45-58

.. code-block:: Python


    import pandas as pd

    from skrub.datasets import fetch_flight_delays

    dataset = fetch_flight_delays()
    seed = 1
    flights = dataset.flights

    # Sampling for faster computation.
    flights = flights.sample(5_000, random_state=seed, ignore_index=True)
    flights.head()






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>Year_Month_DayofMonth</th>
          <th>DayOfWeek</th>
          <th>CRSDepTime</th>
          <th>CRSArrTime</th>
          <th>UniqueCarrier</th>
          <th>FlightNum</th>
          <th>TailNum</th>
          <th>CRSElapsedTime</th>
          <th>ArrDelay</th>
          <th>Origin</th>
          <th>Dest</th>
          <th>Distance</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>2008-01-13</td>
          <td>7</td>
          <td>1900-01-01 18:35:00</td>
          <td>1900-01-01 20:08:00</td>
          <td>CO</td>
          <td>150</td>
          <td>N17244</td>
          <td>213.0</td>
          <td>1.0</td>
          <td>IAH</td>
          <td>ONT</td>
          <td>1334.0</td>
        </tr>
        <tr>
          <th>1</th>
          <td>2008-02-21</td>
          <td>4</td>
          <td>1900-01-01 14:30:00</td>
          <td>1900-01-01 16:06:00</td>
          <td>NW</td>
          <td>807</td>
          <td>N590NW</td>
          <td>216.0</td>
          <td>2.0</td>
          <td>MSP</td>
          <td>SEA</td>
          <td>1399.0</td>
        </tr>
        <tr>
          <th>2</th>
          <td>2008-03-26</td>
          <td>3</td>
          <td>1900-01-01 07:00:00</td>
          <td>1900-01-01 09:38:00</td>
          <td>US</td>
          <td>455</td>
          <td>N627AW</td>
          <td>98.0</td>
          <td>-1.0</td>
          <td>PHX</td>
          <td>SLC</td>
          <td>507.0</td>
        </tr>
        <tr>
          <th>3</th>
          <td>2008-01-03</td>
          <td>4</td>
          <td>1900-01-01 08:40:00</td>
          <td>1900-01-01 12:03:00</td>
          <td>CO</td>
          <td>287</td>
          <td>N21723</td>
          <td>383.0</td>
          <td>46.0</td>
          <td>EWR</td>
          <td>SNA</td>
          <td>2433.0</td>
        </tr>
        <tr>
          <th>4</th>
          <td>2008-01-31</td>
          <td>4</td>
          <td>1900-01-01 12:50:00</td>
          <td>1900-01-01 14:10:00</td>
          <td>MQ</td>
          <td>3157</td>
          <td>N848AE</td>
          <td>80.0</td>
          <td>-14.0</td>
          <td>SJC</td>
          <td>SNA</td>
          <td>342.0</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 59-60

Let us see the arrival delay of the flights in the dataset:

.. GENERATED FROM PYTHON SOURCE LINES 60-69

.. code-block:: Python

    import matplotlib.pyplot as plt
    import seaborn as sns

    sns.set_theme(style="ticks")

    ax = sns.histplot(data=flights, x="ArrDelay")
    ax.set_yscale("log")
    plt.show()




.. image-sg:: /auto_examples/images/sphx_glr_07_multiple_key_join_001.png
   :alt: 07 multiple key join
   :srcset: /auto_examples/images/sphx_glr_07_multiple_key_join_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 70-72

Interesting, most delays are relatively short (<100 min), but there
are some very long ones.

.. GENERATED FROM PYTHON SOURCE LINES 74-78

Airport data: an auxiliary table from the same database
.......................................................
    - The ``airports`` dataset, with information such as their name
      and location (longitude, latitude).

.. GENERATED FROM PYTHON SOURCE LINES 78-82

.. code-block:: Python


    airports = dataset.airports
    airports.head()






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>iata</th>
          <th>airport</th>
          <th>city</th>
          <th>state</th>
          <th>country</th>
          <th>lat</th>
          <th>long</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>00M</td>
          <td>Thigpen</td>
          <td>Bay Springs</td>
          <td>MS</td>
          <td>USA</td>
          <td>31.953765</td>
          <td>-89.234505</td>
        </tr>
        <tr>
          <th>1</th>
          <td>00R</td>
          <td>Livingston Municipal</td>
          <td>Livingston</td>
          <td>TX</td>
          <td>USA</td>
          <td>30.685861</td>
          <td>-95.017928</td>
        </tr>
        <tr>
          <th>2</th>
          <td>00V</td>
          <td>Meadow Lake</td>
          <td>Colorado Springs</td>
          <td>CO</td>
          <td>USA</td>
          <td>38.945749</td>
          <td>-104.569893</td>
        </tr>
        <tr>
          <th>3</th>
          <td>01G</td>
          <td>Perry-Warsaw</td>
          <td>Perry</td>
          <td>NY</td>
          <td>USA</td>
          <td>42.741347</td>
          <td>-78.052081</td>
        </tr>
        <tr>
          <th>4</th>
          <td>01J</td>
          <td>Hilliard Airpark</td>
          <td>Hilliard</td>
          <td>FL</td>
          <td>USA</td>
          <td>30.688012</td>
          <td>-81.905944</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 83-88

Weather data: auxiliary tables from external sources
....................................................
    - The ``weather`` table. Weather details by measurement station.
      Both tables are from the Global Historical Climatology Network.
      Here, we consider only weather measurements from 2008.

.. GENERATED FROM PYTHON SOURCE LINES 88-94

.. code-block:: Python


    weather = dataset.weather
    # Sampling for faster computation.
    weather = weather.sample(10_000, random_state=seed, ignore_index=True)
    weather.head()






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>ID</th>
          <th>YEAR/MONTH/DAY</th>
          <th>TMAX</th>
          <th>PRCP</th>
          <th>SNOW</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>RPM00098325</td>
          <td>2008-08-20</td>
          <td>290.0</td>
          <td>856.0</td>
          <td>NaN</td>
        </tr>
        <tr>
          <th>1</th>
          <td>ASN00023820</td>
          <td>2008-07-20</td>
          <td>NaN</td>
          <td>28.0</td>
          <td>NaN</td>
        </tr>
        <tr>
          <th>2</th>
          <td>MXN00024056</td>
          <td>2008-04-13</td>
          <td>250.0</td>
          <td>0.0</td>
          <td>NaN</td>
        </tr>
        <tr>
          <th>3</th>
          <td>GME00126742</td>
          <td>2008-11-06</td>
          <td>116.0</td>
          <td>4.0</td>
          <td>NaN</td>
        </tr>
        <tr>
          <th>4</th>
          <td>ASN00074201</td>
          <td>2008-04-12</td>
          <td>NaN</td>
          <td>0.0</td>
          <td>NaN</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 95-97

- The ``stations`` dataset. Provides location of all the weather
  measurement stations in the US.

.. GENERATED FROM PYTHON SOURCE LINES 97-101

.. code-block:: Python


    stations = dataset.stations
    stations.head()






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>ID</th>
          <th>LATITUDE</th>
          <th>LONGITUDE</th>
          <th>ELEVATION</th>
          <th>STATE</th>
          <th>NAME</th>
          <th>GSN FLAG</th>
          <th>HCN/CRN FLAG</th>
          <th>WMO ID</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>ACW00011604</td>
          <td>17.1167</td>
          <td>-61.7833</td>
          <td>10.1</td>
          <td>ST JOHNS COOLIDGE FLD</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>NaN</td>
        </tr>
        <tr>
          <th>1</th>
          <td>ACW00011647</td>
          <td>17.1333</td>
          <td>-61.7833</td>
          <td>19.2</td>
          <td>ST JOHNS</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>NaN</td>
        </tr>
        <tr>
          <th>2</th>
          <td>AE000041196</td>
          <td>25.3330</td>
          <td>55.5170</td>
          <td>34.0</td>
          <td>SHARJAH INTER. AIRP</td>
          <td>NaN</td>
          <td>GSN</td>
          <td>41196.0</td>
          <td>NaN</td>
        </tr>
        <tr>
          <th>3</th>
          <td>AEM00041194</td>
          <td>25.2550</td>
          <td>55.3640</td>
          <td>10.4</td>
          <td>DUBAI INTL</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>41194.0</td>
          <td>NaN</td>
        </tr>
        <tr>
          <th>4</th>
          <td>AEM00041217</td>
          <td>24.4330</td>
          <td>54.6510</td>
          <td>26.8</td>
          <td>ABU DHABI INTL</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>41217.0</td>
          <td>NaN</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 102-105

Joining: feature augmentation across tables
-------------------------------------------
First we join the stations with weather on the ID (exact join):

.. GENERATED FROM PYTHON SOURCE LINES 105-109

.. code-block:: Python


    aux = pd.merge(stations, weather, on="ID")
    aux.head()






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>ID</th>
          <th>LATITUDE</th>
          <th>LONGITUDE</th>
          <th>ELEVATION</th>
          <th>STATE</th>
          <th>NAME</th>
          <th>GSN FLAG</th>
          <th>HCN/CRN FLAG</th>
          <th>WMO ID</th>
          <th>YEAR/MONTH/DAY</th>
          <th>TMAX</th>
          <th>PRCP</th>
          <th>SNOW</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>AGE00147708</td>
          <td>36.720</td>
          <td>4.050</td>
          <td>222.0</td>
          <td>TIZI OUZOU</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>60395.0</td>
          <td>NaN</td>
          <td>2008-04-17</td>
          <td>225.0</td>
          <td>0.0</td>
          <td>NaN</td>
        </tr>
        <tr>
          <th>1</th>
          <td>AGM00060403</td>
          <td>36.467</td>
          <td>7.467</td>
          <td>228.0</td>
          <td>GUELMA</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>60403.0</td>
          <td>NaN</td>
          <td>2008-09-17</td>
          <td>324.0</td>
          <td>0.0</td>
          <td>NaN</td>
        </tr>
        <tr>
          <th>2</th>
          <td>AGM00060403</td>
          <td>36.467</td>
          <td>7.467</td>
          <td>228.0</td>
          <td>GUELMA</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>60403.0</td>
          <td>NaN</td>
          <td>2008-04-11</td>
          <td>245.0</td>
          <td>0.0</td>
          <td>NaN</td>
        </tr>
        <tr>
          <th>3</th>
          <td>AGM00060419</td>
          <td>36.276</td>
          <td>6.620</td>
          <td>690.4</td>
          <td>MOHAMED BOUDIAF INTL</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>60419.0</td>
          <td>NaN</td>
          <td>2008-06-30</td>
          <td>340.0</td>
          <td>0.0</td>
          <td>NaN</td>
        </tr>
        <tr>
          <th>4</th>
          <td>AGM00060430</td>
          <td>36.300</td>
          <td>2.233</td>
          <td>721.0</td>
          <td>MILIANA</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>60430.0</td>
          <td>NaN</td>
          <td>2008-08-17</td>
          <td>323.0</td>
          <td>0.0</td>
          <td>NaN</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 110-112

Then we join this table with the airports so that we get all auxiliary
tables into one.

.. GENERATED FROM PYTHON SOURCE LINES 112-121

.. code-block:: Python


    from skrub import Joiner

    joiner = Joiner(airports, aux_key=["lat", "long"], main_key=["LATITUDE", "LONGITUDE"])

    aux_augmented = joiner.fit_transform(aux)

    aux_augmented.head()






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>ID</th>
          <th>LATITUDE</th>
          <th>LONGITUDE</th>
          <th>ELEVATION</th>
          <th>STATE</th>
          <th>NAME</th>
          <th>GSN FLAG</th>
          <th>HCN/CRN FLAG</th>
          <th>WMO ID</th>
          <th>YEAR/MONTH/DAY</th>
          <th>TMAX</th>
          <th>PRCP</th>
          <th>SNOW</th>
          <th>iata</th>
          <th>airport</th>
          <th>city</th>
          <th>state</th>
          <th>country</th>
          <th>lat</th>
          <th>long</th>
          <th>skrub_Joiner_distance</th>
          <th>skrub_Joiner_rescaled_distance</th>
          <th>skrub_Joiner_match_accepted</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>AGE00147708</td>
          <td>36.720</td>
          <td>4.050</td>
          <td>222.0</td>
          <td>TIZI OUZOU</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>60395.0</td>
          <td>NaN</td>
          <td>2008-04-17</td>
          <td>225.0</td>
          <td>0.0</td>
          <td>NaN</td>
          <td>EPM</td>
          <td>Eastport Municipal</td>
          <td>Eastport</td>
          <td>ME</td>
          <td>USA</td>
          <td>44.910111</td>
          <td>-67.012694</td>
          <td>3.259659</td>
          <td>4.467246</td>
          <td>True</td>
        </tr>
        <tr>
          <th>1</th>
          <td>AGM00060403</td>
          <td>36.467</td>
          <td>7.467</td>
          <td>228.0</td>
          <td>GUELMA</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>60403.0</td>
          <td>NaN</td>
          <td>2008-09-17</td>
          <td>324.0</td>
          <td>0.0</td>
          <td>NaN</td>
          <td>EPM</td>
          <td>Eastport Municipal</td>
          <td>Eastport</td>
          <td>ME</td>
          <td>USA</td>
          <td>44.910111</td>
          <td>-67.012694</td>
          <td>3.411334</td>
          <td>4.675112</td>
          <td>True</td>
        </tr>
        <tr>
          <th>2</th>
          <td>AGM00060403</td>
          <td>36.467</td>
          <td>7.467</td>
          <td>228.0</td>
          <td>GUELMA</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>60403.0</td>
          <td>NaN</td>
          <td>2008-04-11</td>
          <td>245.0</td>
          <td>0.0</td>
          <td>NaN</td>
          <td>EPM</td>
          <td>Eastport Municipal</td>
          <td>Eastport</td>
          <td>ME</td>
          <td>USA</td>
          <td>44.910111</td>
          <td>-67.012694</td>
          <td>3.411334</td>
          <td>4.675112</td>
          <td>True</td>
        </tr>
        <tr>
          <th>3</th>
          <td>AGM00060419</td>
          <td>36.276</td>
          <td>6.620</td>
          <td>690.4</td>
          <td>MOHAMED BOUDIAF INTL</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>60419.0</td>
          <td>NaN</td>
          <td>2008-06-30</td>
          <td>340.0</td>
          <td>0.0</td>
          <td>NaN</td>
          <td>EPM</td>
          <td>Eastport Municipal</td>
          <td>Eastport</td>
          <td>ME</td>
          <td>USA</td>
          <td>44.910111</td>
          <td>-67.012694</td>
          <td>3.382942</td>
          <td>4.636201</td>
          <td>True</td>
        </tr>
        <tr>
          <th>4</th>
          <td>AGM00060430</td>
          <td>36.300</td>
          <td>2.233</td>
          <td>721.0</td>
          <td>MILIANA</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>60430.0</td>
          <td>NaN</td>
          <td>2008-08-17</td>
          <td>323.0</td>
          <td>0.0</td>
          <td>NaN</td>
          <td>EPM</td>
          <td>Eastport Municipal</td>
          <td>Eastport</td>
          <td>ME</td>
          <td>USA</td>
          <td>44.910111</td>
          <td>-67.012694</td>
          <td>3.199924</td>
          <td>4.385382</td>
          <td>True</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 122-124

Joining airports with flights data:
Let's instantiate another multiple key joiner on the date and the airport:

.. GENERATED FROM PYTHON SOURCE LINES 124-133

.. code-block:: Python


    joiner = Joiner(
        aux_augmented,
        aux_key=["YEAR/MONTH/DAY", "iata"],
        main_key=["Year_Month_DayofMonth", "Origin"],
    )

    flights.drop(columns=["TailNum", "FlightNum"])






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>Year_Month_DayofMonth</th>
          <th>DayOfWeek</th>
          <th>CRSDepTime</th>
          <th>CRSArrTime</th>
          <th>UniqueCarrier</th>
          <th>CRSElapsedTime</th>
          <th>ArrDelay</th>
          <th>Origin</th>
          <th>Dest</th>
          <th>Distance</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>2008-01-13</td>
          <td>7</td>
          <td>1900-01-01 18:35:00</td>
          <td>1900-01-01 20:08:00</td>
          <td>CO</td>
          <td>213.0</td>
          <td>1.0</td>
          <td>IAH</td>
          <td>ONT</td>
          <td>1334.0</td>
        </tr>
        <tr>
          <th>1</th>
          <td>2008-02-21</td>
          <td>4</td>
          <td>1900-01-01 14:30:00</td>
          <td>1900-01-01 16:06:00</td>
          <td>NW</td>
          <td>216.0</td>
          <td>2.0</td>
          <td>MSP</td>
          <td>SEA</td>
          <td>1399.0</td>
        </tr>
        <tr>
          <th>2</th>
          <td>2008-03-26</td>
          <td>3</td>
          <td>1900-01-01 07:00:00</td>
          <td>1900-01-01 09:38:00</td>
          <td>US</td>
          <td>98.0</td>
          <td>-1.0</td>
          <td>PHX</td>
          <td>SLC</td>
          <td>507.0</td>
        </tr>
        <tr>
          <th>3</th>
          <td>2008-01-03</td>
          <td>4</td>
          <td>1900-01-01 08:40:00</td>
          <td>1900-01-01 12:03:00</td>
          <td>CO</td>
          <td>383.0</td>
          <td>46.0</td>
          <td>EWR</td>
          <td>SNA</td>
          <td>2433.0</td>
        </tr>
        <tr>
          <th>4</th>
          <td>2008-01-31</td>
          <td>4</td>
          <td>1900-01-01 12:50:00</td>
          <td>1900-01-01 14:10:00</td>
          <td>MQ</td>
          <td>80.0</td>
          <td>-14.0</td>
          <td>SJC</td>
          <td>SNA</td>
          <td>342.0</td>
        </tr>
        <tr>
          <th>...</th>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
        </tr>
        <tr>
          <th>4995</th>
          <td>2008-04-01</td>
          <td>2</td>
          <td>1900-01-01 10:14:00</td>
          <td>1900-01-01 10:45:00</td>
          <td>EV</td>
          <td>91.0</td>
          <td>50.0</td>
          <td>ATL</td>
          <td>PFN</td>
          <td>247.0</td>
        </tr>
        <tr>
          <th>4996</th>
          <td>2008-02-25</td>
          <td>1</td>
          <td>1900-01-01 12:00:00</td>
          <td>1900-01-01 13:30:00</td>
          <td>AA</td>
          <td>210.0</td>
          <td>-2.0</td>
          <td>DFW</td>
          <td>RNO</td>
          <td>1345.0</td>
        </tr>
        <tr>
          <th>4997</th>
          <td>2008-01-20</td>
          <td>7</td>
          <td>1900-01-01 06:00:00</td>
          <td>1900-01-01 07:30:00</td>
          <td>AQ</td>
          <td>90.0</td>
          <td>-13.0</td>
          <td>LAS</td>
          <td>OAK</td>
          <td>407.0</td>
        </tr>
        <tr>
          <th>4998</th>
          <td>2008-03-14</td>
          <td>5</td>
          <td>1900-01-01 06:42:00</td>
          <td>1900-01-01 08:04:00</td>
          <td>XE</td>
          <td>82.0</td>
          <td>-16.0</td>
          <td>ROC</td>
          <td>CLE</td>
          <td>245.0</td>
        </tr>
        <tr>
          <th>4999</th>
          <td>2008-04-18</td>
          <td>5</td>
          <td>1900-01-01 19:38:00</td>
          <td>1900-01-01 20:06:00</td>
          <td>OO</td>
          <td>88.0</td>
          <td>-3.0</td>
          <td>ICT</td>
          <td>DEN</td>
          <td>419.0</td>
        </tr>
      </tbody>
    </table>
    <p>5000 rows Ã— 10 columns</p>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 134-139

Training data is then passed through a |Pipeline|:

- We will combine all the information from our pool of tables into "flights",
our main table.
- We will use this main table to model the prediction of flight delay.

.. GENERATED FROM PYTHON SOURCE LINES 139-150

.. code-block:: Python


    from sklearn.ensemble import HistGradientBoostingClassifier
    from sklearn.pipeline import make_pipeline

    from skrub import TableVectorizer

    tv = TableVectorizer()
    hgb = HistGradientBoostingClassifier()

    pipeline_hgb = make_pipeline(joiner, tv, hgb)








.. GENERATED FROM PYTHON SOURCE LINES 151-152

We isolate our target variable and remove useless ID variables:

.. GENERATED FROM PYTHON SOURCE LINES 152-156

.. code-block:: Python


    y = flights["ArrDelay"]
    X = flights.drop(columns=["ArrDelay"])








.. GENERATED FROM PYTHON SOURCE LINES 157-163

We want to frame this as a classification problem:
suppose that your company is obliged to reimburse the ticket
price if the flight is delayed.

We have a binary classification problem:
the flight was delayed (1) or not (0).

.. GENERATED FROM PYTHON SOURCE LINES 163-167

.. code-block:: Python


    y = (y > 0).astype(int)
    y.value_counts()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    ArrDelay
    0    2727
    1    2273
    Name: count, dtype: int64



.. GENERATED FROM PYTHON SOURCE LINES 168-169

The results:

.. GENERATED FROM PYTHON SOURCE LINES 169-175

.. code-block:: Python


    from sklearn.model_selection import train_test_split

    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed)
    pipeline_hgb.fit(X_train, y_train).score(X_test, y_test)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    0.5672



.. GENERATED FROM PYTHON SOURCE LINES 176-184

Conclusion
----------

In this example, we have combined multiple tables with complex joins
on imprecise and multiple-key correspondences.
This is made easy by skrub's |Joiner| transformer.

Our final cross-validated accuracy score is 0.55.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 14.782 seconds)


.. _sphx_glr_download_auto_examples_07_multiple_key_join.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/skrub-data/skrub/main?urlpath=lab/tree/notebooks/auto_examples/07_multiple_key_join.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: lite-badge

      .. image:: images/jupyterlite_badge_logo.svg
        :target: ../lite/lab/index.html?path=auto_examples/07_multiple_key_join.ipynb
        :alt: Launch JupyterLite
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: 07_multiple_key_join.ipynb <07_multiple_key_join.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: 07_multiple_key_join.py <07_multiple_key_join.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: 07_multiple_key_join.zip <07_multiple_key_join.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
