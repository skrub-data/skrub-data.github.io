
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>dirty_cat._gap_encoder &#8212; &amp;mdash; Dirty cat</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/scrolltoc.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><!--
    Inherited from the original Alabaster theme:
    https://github.com/bitprophet/alabaster/blob/master/alabaster/about.html
    Only the "Version" number is added.
-->

<p class="logo">
  <a href="../../index.html">
    <img class="logo" src="../../_static/dirty_cat.svg" alt="Logo"/>
    
    <h1 class="logo logo-name">dirty_cat</h1>
    
  </a>
  <div class="version-switcher">
    <h4>Version 0.4.dev0</h4>
    <details>
	<summary>Other versions</summary>
	<ul>
	    <li><a href="https://dirty-cat.github.io/stable">Stable</a></li>
	    <li><a href="https://dirty-cat.github.io/dev">Dev</a></li>
	</ul>
    </details>
  </div>
</p>






<p>
<iframe src="https://ghbtns.com/github-btn.html?user=dirty-cat&repo=dirty_cat&type=star&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<ul>
    <li class="toctree-l1"><a href="../../index.html#using-dirty-cat">Usage</a></li>
    <li class="toctree-l1"><a href="../../index.html#api-documentation">API</a></li>
    <li class="toctree-l1"><a href="../../index.html#about">About</a></li>
</ul><div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for dirty_cat._gap_encoder</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Online Gamma-Poisson factorization of string arrays.</span>
<span class="sd">The principle is as follows:</span>
<span class="sd">    1. Given an input string array X, we build its bag-of-n-grams</span>
<span class="sd">       representation V (n_samples, vocab_size).</span>
<span class="sd">    2. Instead of using the n-grams counts as encodings, we look for low-</span>
<span class="sd">       dimensional representations by modeling n-grams counts as linear</span>
<span class="sd">       combinations of topics V = HW, with W (n_topics, vocab_size) the topics</span>
<span class="sd">       and H (n_samples, n_topics) the associated activations.</span>
<span class="sd">    3. Assuming that n-grams counts follow a Poisson law, we fit H and W to</span>
<span class="sd">       maximize the likelihood of the data, with a Gamma prior for the</span>
<span class="sd">       activations H to induce sparsity.</span>
<span class="sd">    4. In practice, this is equivalent to a non-negative matrix factorization</span>
<span class="sd">       with the Kullback-Leibler divergence as loss, and a Gamma prior on H.</span>
<span class="sd">       We thus optimize H and W with the multiplicative update method.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Generator</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Literal</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">numpy.random</span> <span class="kn">import</span> <span class="n">RandomState</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">sparse</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">__version__</span> <span class="k">as</span> <span class="n">sklearn_version</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span><span class="p">,</span> <span class="n">HashingVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">NearestNeighbors</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">check_random_state</span><span class="p">,</span> <span class="n">gen_batches</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.extmath</span> <span class="kn">import</span> <span class="n">row_norms</span><span class="p">,</span> <span class="n">safe_sparse_dot</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.fixes</span> <span class="kn">import</span> <span class="n">_object_dtype_isnan</span>

<span class="kn">from</span> <span class="nn">dirty_cat._utils</span> <span class="kn">import</span> <span class="n">Version</span>

<span class="kn">from</span> <span class="nn">._utils</span> <span class="kn">import</span> <span class="n">check_input</span>

<span class="k">if</span> <span class="n">Version</span><span class="p">(</span><span class="n">sklearn_version</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">Version</span><span class="p">(</span><span class="s2">&quot;0.24&quot;</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">sklearn.cluster._kmeans</span> <span class="kn">import</span> <span class="n">_k_init</span>
<span class="k">else</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">kmeans_plusplus</span>

<span class="kn">from</span> <span class="nn">sklearn.decomposition._nmf</span> <span class="kn">import</span> <span class="n">_beta_divergence</span>


<span class="k">class</span> <span class="nc">GapEncoderColumn</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;See GapEncoder&#39;s docstring.&quot;&quot;&quot;</span>

    <span class="n">rho_</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">H_dict_</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_components</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
        <span class="n">gamma_shape_prior</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.1</span><span class="p">,</span>
        <span class="n">gamma_scale_prior</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">rho</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.95</span><span class="p">,</span>
        <span class="n">rescale_rho</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">hashing</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">hashing_n_features</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="mi">12</span><span class="p">,</span>
        <span class="n">init</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;k-means++&quot;</span><span class="p">,</span> <span class="s2">&quot;random&quot;</span><span class="p">,</span> <span class="s2">&quot;k-means&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;k-means++&quot;</span><span class="p">,</span>
        <span class="n">tol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">min_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
        <span class="n">ngram_range</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
        <span class="n">analyzer</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;word&quot;</span><span class="p">,</span> <span class="s2">&quot;char&quot;</span><span class="p">,</span> <span class="s2">&quot;char_wb&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;char&quot;</span><span class="p">,</span>
        <span class="n">add_words</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">random_state</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">RandomState</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">rescale_W</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">max_iter_e_step</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ngram_range</span> <span class="o">=</span> <span class="n">ngram_range</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">=</span> <span class="n">n_components</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma_shape_prior</span> <span class="o">=</span> <span class="n">gamma_shape_prior</span>  <span class="c1"># &#39;a&#39; parameter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma_scale_prior</span> <span class="o">=</span> <span class="n">gamma_scale_prior</span>  <span class="c1"># &#39;b&#39; parameter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rho</span> <span class="o">=</span> <span class="n">rho</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rescale_rho</span> <span class="o">=</span> <span class="n">rescale_rho</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hashing</span> <span class="o">=</span> <span class="n">hashing</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hashing_n_features</span> <span class="o">=</span> <span class="n">hashing_n_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_iter</span> <span class="o">=</span> <span class="n">min_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init</span> <span class="o">=</span> <span class="n">init</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">analyzer</span> <span class="o">=</span> <span class="n">analyzer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_words</span> <span class="o">=</span> <span class="n">add_words</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rescale_W</span> <span class="o">=</span> <span class="n">rescale_W</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter_e_step</span> <span class="o">=</span> <span class="n">max_iter_e_step</span>

    <span class="k">def</span> <span class="nf">_init_vars</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build the bag-of-n-grams representation V of X and initialize</span>
<span class="sd">        the topics W.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Init n-grams counts vectorizer</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hashing</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ngrams_count_</span> <span class="o">=</span> <span class="n">HashingVectorizer</span><span class="p">(</span>
                <span class="n">analyzer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">analyzer</span><span class="p">,</span>
                <span class="n">ngram_range</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ngram_range</span><span class="p">,</span>
                <span class="n">n_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hashing_n_features</span><span class="p">,</span>
                <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">alternate_sign</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_words</span><span class="p">:</span>  <span class="c1"># Init a word counts vectorizer if needed</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">word_count_</span> <span class="o">=</span> <span class="n">HashingVectorizer</span><span class="p">(</span>
                    <span class="n">analyzer</span><span class="o">=</span><span class="s2">&quot;word&quot;</span><span class="p">,</span>
                    <span class="n">n_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hashing_n_features</span><span class="p">,</span>
                    <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">alternate_sign</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ngrams_count_</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span>
                <span class="n">analyzer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">analyzer</span><span class="p">,</span> <span class="n">ngram_range</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ngram_range</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_words</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">word_count_</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

        <span class="c1"># Init H_dict_ with empty dict to train from scratch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">H_dict_</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="c1"># Build the n-grams counts matrix unq_V on unique elements of X</span>
        <span class="n">unq_X</span><span class="p">,</span> <span class="n">lookup</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">unq_V</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ngrams_count_</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_words</span><span class="p">:</span>  <span class="c1"># Add word counts to unq_V</span>
            <span class="n">unq_V2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_count_</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
            <span class="n">unq_V</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">unq_V</span><span class="p">,</span> <span class="n">unq_V2</span><span class="p">),</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">hashing</span><span class="p">:</span>  <span class="c1"># Build n-grams/word vocabulary</span>
            <span class="k">if</span> <span class="n">Version</span><span class="p">(</span><span class="n">sklearn_version</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">Version</span><span class="p">(</span><span class="s2">&quot;1.0&quot;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">vocabulary</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ngrams_count_</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">vocabulary</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ngrams_count_</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_words</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">Version</span><span class="p">(</span><span class="n">sklearn_version</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">Version</span><span class="p">(</span><span class="s2">&quot;1.0&quot;</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">vocabulary</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
                        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_count_</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">vocabulary</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
                        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_count_</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">())</span>
                    <span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vocab</span> <span class="o">=</span> <span class="n">unq_V</span><span class="o">.</span><span class="n">shape</span>
        <span class="c1"># Init the topics W given the n-grams counts V</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">A_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">B_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_w</span><span class="p">(</span><span class="n">unq_V</span><span class="p">[</span><span class="n">lookup</span><span class="p">],</span> <span class="n">X</span><span class="p">)</span>
        <span class="c1"># Init the activations unq_H of each unique input string</span>
        <span class="n">unq_H</span> <span class="o">=</span> <span class="n">_rescale_h</span><span class="p">(</span><span class="n">unq_V</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">unq_X</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">)))</span>
        <span class="c1"># Update self.H_dict_ with unique input strings and their activations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">H_dict_</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">unq_X</span><span class="p">,</span> <span class="n">unq_H</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_rho</span><span class="p">:</span>
            <span class="c1"># Make update rate per iteration independent of the batch_size</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rho_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rho</span> <span class="o">**</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">unq_X</span><span class="p">,</span> <span class="n">unq_V</span><span class="p">,</span> <span class="n">lookup</span>

    <span class="k">def</span> <span class="nf">_get_H</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the bag-of-n-grams representation of X.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">H_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">h_out</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">H_out</span><span class="p">):</span>
            <span class="n">h_out</span><span class="p">[:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">H_dict_</span><span class="p">[</span><span class="n">x</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">H_out</span>

    <span class="k">def</span> <span class="nf">_init_w</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">V</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the topics W.</span>
<span class="sd">        If self.init=&#39;k-means++&#39;, we use the init method of</span>
<span class="sd">        sklearn.cluster.KMeans.</span>
<span class="sd">        If self.init=&#39;random&#39;, topics are initialized with a Gamma</span>
<span class="sd">        distribution.</span>
<span class="sd">        If self.init=&#39;k-means&#39;, topics are initialized with a KMeans on the</span>
<span class="sd">        n-grams counts.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">init</span> <span class="o">==</span> <span class="s2">&quot;k-means++&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">Version</span><span class="p">(</span><span class="n">sklearn_version</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">Version</span><span class="p">(</span><span class="s2">&quot;0.24&quot;</span><span class="p">):</span>
                <span class="n">W</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">_k_init</span><span class="p">(</span>
                        <span class="n">V</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">,</span>
                        <span class="n">x_squared_norms</span><span class="o">=</span><span class="n">row_norms</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                        <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
                        <span class="n">n_local_trials</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="o">+</span> <span class="mf">0.1</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">W</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">kmeans_plusplus</span><span class="p">(</span>
                    <span class="n">V</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">,</span>
                    <span class="n">x_squared_norms</span><span class="o">=</span><span class="n">row_norms</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                    <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
                    <span class="n">n_local_trials</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">W</span> <span class="o">=</span> <span class="n">W</span> <span class="o">+</span> <span class="mf">0.1</span>  <span class="c1"># To avoid restricting topics to a few n-grams only</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">init</span> <span class="o">==</span> <span class="s2">&quot;random&quot;</span><span class="p">:</span>
            <span class="n">W</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span>
                <span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma_shape_prior</span><span class="p">,</span>
                <span class="n">scale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma_scale_prior</span><span class="p">,</span>
                <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vocab</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">init</span> <span class="o">==</span> <span class="s2">&quot;k-means&quot;</span><span class="p">:</span>
            <span class="n">prototypes</span> <span class="o">=</span> <span class="n">get_kmeans_prototypes</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">,</span>
                <span class="n">analyzer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">analyzer</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">W</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ngrams_count_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">prototypes</span><span class="p">)</span><span class="o">.</span><span class="n">A</span> <span class="o">+</span> <span class="mf">0.1</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_words</span><span class="p">:</span>
                <span class="n">W2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_count_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">prototypes</span><span class="p">)</span><span class="o">.</span><span class="n">A</span> <span class="o">+</span> <span class="mf">0.1</span>
                <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">W</span><span class="p">,</span> <span class="n">W2</span><span class="p">))</span>
            <span class="c1"># if k-means doesn&#39;t find the exact number of prototypes</span>
            <span class="k">if</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">Version</span><span class="p">(</span><span class="n">sklearn_version</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">Version</span><span class="p">(</span><span class="s2">&quot;0.24&quot;</span><span class="p">):</span>
                    <span class="n">W2</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">_k_init</span><span class="p">(</span>
                            <span class="n">V</span><span class="p">,</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">-</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                            <span class="n">x_squared_norms</span><span class="o">=</span><span class="n">row_norms</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                            <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
                            <span class="n">n_local_trials</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="p">)</span>
                        <span class="o">+</span> <span class="mf">0.1</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">W2</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">kmeans_plusplus</span><span class="p">(</span>
                        <span class="n">V</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">-</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                        <span class="n">x_squared_norms</span><span class="o">=</span><span class="n">row_norms</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                        <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
                        <span class="n">n_local_trials</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">W2</span> <span class="o">=</span> <span class="n">W2</span> <span class="o">+</span> <span class="mf">0.1</span>
                <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">W</span><span class="p">,</span> <span class="n">W2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initialization method </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="si">!r}</span><span class="s2"> does not exist. &quot;</span><span class="p">)</span>
        <span class="n">W</span> <span class="o">/=</span> <span class="n">W</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vocab</span><span class="p">))</span> <span class="o">*</span> <span class="mf">1e-10</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">W</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;GapEncoderColumn&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the GapEncoder on batches of X.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape (n_samples, )</span>
<span class="sd">            The string data to fit the model on.</span>
<span class="sd">        y : None</span>
<span class="sd">            Unused, only here for compatibility.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self</span>
<span class="sd">            Fitting GapEncoderColumn instance.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Copy parameter rho</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rho_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rho</span>
        <span class="c1"># Check if first item has str or np.str_ type</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">str</span><span class="p">),</span> <span class="s2">&quot;Input data is not string. &quot;</span>
        <span class="c1"># Make n-grams counts matrix unq_V</span>
        <span class="n">unq_X</span><span class="p">,</span> <span class="n">unq_V</span><span class="p">,</span> <span class="n">lookup</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_vars</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">n_batch</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">del</span> <span class="n">X</span>
        <span class="c1"># Get activations unq_H</span>
        <span class="n">unq_H</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_H</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">n_iter_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">):</span>
            <span class="c1"># Loop over batches</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">unq_idx</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch_lookup</span><span class="p">(</span><span class="n">lookup</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)):</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">n_batch</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">W_last</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="c1"># Update activations unq_H</span>
                <span class="n">unq_H</span><span class="p">[</span><span class="n">unq_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">_multiplicative_update_h</span><span class="p">(</span>
                    <span class="n">unq_V</span><span class="p">[</span><span class="n">unq_idx</span><span class="p">],</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">,</span>
                    <span class="n">unq_H</span><span class="p">[</span><span class="n">unq_idx</span><span class="p">],</span>
                    <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
                    <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter_e_step</span><span class="p">,</span>
                    <span class="n">rescale_W</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rescale_W</span><span class="p">,</span>
                    <span class="n">gamma_shape_prior</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma_shape_prior</span><span class="p">,</span>
                    <span class="n">gamma_scale_prior</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma_scale_prior</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="c1"># Update the topics self.W_</span>
                <span class="n">_multiplicative_update_w</span><span class="p">(</span>
                    <span class="n">unq_V</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">A_</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">B_</span><span class="p">,</span>
                    <span class="n">unq_H</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">rescale_W</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">rho_</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">n_batch</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="c1"># Compute the norm of the update of W in the last batch</span>
                    <span class="n">W_change</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_</span> <span class="o">-</span> <span class="n">W_last</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">W_last</span><span class="p">)</span>

            <span class="k">if</span> <span class="p">(</span><span class="n">W_change</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">n_iter_</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_iter</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
                <span class="k">break</span>  <span class="c1"># Stop if the change in W is smaller than the tolerance</span>

        <span class="c1"># Update self.H_dict_ with the learned encoded vectors (activations)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">H_dict_</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">unq_X</span><span class="p">,</span> <span class="n">unq_H</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">get_feature_names</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_labels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Ensures compatibility with sklearn &lt; 1.0.</span>
<span class="sd">        Use `get_feature_names_out` instead.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;Following the changes in scikit-learn 1.0, &quot;</span>
            <span class="s2">&quot;get_feature_names is deprecated. &quot;</span>
            <span class="s2">&quot;Use get_feature_names_out instead. &quot;</span><span class="p">,</span>
            <span class="ne">DeprecationWarning</span><span class="p">,</span>
            <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">(</span><span class="n">n_labels</span><span class="o">=</span><span class="n">n_labels</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="n">prefix</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_feature_names_out</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_labels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the labels that best summarize the learned components/topics.</span>
<span class="sd">        For each topic, labels with the highest activations are selected.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_labels : int, default=3</span>
<span class="sd">            The number of labels used to describe each topic.</span>
<span class="sd">        prefix : str, default=&quot;&quot;</span>
<span class="sd">            Used as a prefix for the categories.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        topic_labels : typing.List[str]</span>
<span class="sd">            The labels that best describe each topic.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
        <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">H_dict_</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
        <span class="k">if</span> <span class="n">Version</span><span class="p">(</span><span class="n">sklearn_version</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">Version</span><span class="p">(</span><span class="s2">&quot;1.0&quot;</span><span class="p">):</span>
            <span class="n">vocabulary</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">vocabulary</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">())</span>
        <span class="n">encoding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">encoding</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">encoding</span><span class="p">)</span>
        <span class="n">encoding</span> <span class="o">=</span> <span class="n">encoding</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">encoding</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">n_components</span> <span class="o">=</span> <span class="n">encoding</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">topic_labels</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_components</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">encoding</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">vocabulary</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">)[:</span><span class="n">n_labels</span><span class="p">]]</span>
            <span class="n">topic_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">topic_labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">prefix</span> <span class="o">+</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">topic_labels</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">topic_labels</span>

    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the Kullback-Leibler divergence between the n-grams counts</span>
<span class="sd">        matrix V of X, and its non-negative factorization HW.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like (str), shape (n_samples, )</span>
<span class="sd">            The data to encode.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float.</span>
<span class="sd">            The Kullback-Leibler divergence.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Build n-grams/word counts matrix</span>
        <span class="n">unq_X</span><span class="p">,</span> <span class="n">lookup</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">unq_V</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ngrams_count_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_words</span><span class="p">:</span>
            <span class="n">unq_V2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_count_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
            <span class="n">unq_V</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">unq_V</span><span class="p">,</span> <span class="n">unq_V2</span><span class="p">),</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_add_unseen_keys_to_H_dict</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
        <span class="n">unq_H</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_H</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
        <span class="c1"># Given the learnt topics W, optimize the activations H to fit V = HW</span>
        <span class="k">for</span> <span class="nb">slice</span> <span class="ow">in</span> <span class="n">gen_batches</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">unq_H</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="n">unq_H</span><span class="p">[</span><span class="nb">slice</span><span class="p">]</span> <span class="o">=</span> <span class="n">_multiplicative_update_h</span><span class="p">(</span>
                <span class="n">unq_V</span><span class="p">[</span><span class="nb">slice</span><span class="p">],</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">,</span>
                <span class="n">unq_H</span><span class="p">[</span><span class="nb">slice</span><span class="p">],</span>
                <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
                <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter_e_step</span><span class="p">,</span>
                <span class="n">rescale_W</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rescale_W</span><span class="p">,</span>
                <span class="n">gamma_shape_prior</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma_shape_prior</span><span class="p">,</span>
                <span class="n">gamma_scale_prior</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma_scale_prior</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="c1"># Compute the KL divergence between V and HW</span>
        <span class="n">kl_divergence</span> <span class="o">=</span> <span class="n">_beta_divergence</span><span class="p">(</span>
            <span class="n">unq_V</span><span class="p">[</span><span class="n">lookup</span><span class="p">],</span> <span class="n">unq_H</span><span class="p">[</span><span class="n">lookup</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">,</span> <span class="s2">&quot;kullback-leibler&quot;</span><span class="p">,</span> <span class="n">square_root</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">kl_divergence</span>

    <span class="k">def</span> <span class="nf">partial_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;GapEncoderColumn&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Partial fit of the GapEncoder on X.</span>
<span class="sd">        To be used in an online learning procedure where batches of data are</span>
<span class="sd">        coming one by one.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape (n_samples, )</span>
<span class="sd">            The string data to fit the model on.</span>
<span class="sd">        y : None</span>
<span class="sd">            Unused, only here for compatibility.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        GapEncoderColumn</span>
<span class="sd">            The fitted GapEncoderColumn instance.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Init H_dict_ with empty dict if it&#39;s the first call of partial_fit</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;H_dict_&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">H_dict_</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="c1"># Same thing for the rho_ parameter</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;rho_&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rho_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rho</span>
        <span class="c1"># Check if first item has str or np.str_ type</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">str</span><span class="p">),</span> <span class="s2">&quot;Input data is not string. &quot;</span>
        <span class="c1"># Check if it is not the first batch</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;vocabulary&quot;</span><span class="p">):</span>  <span class="c1"># Update unq_X, unq_V with new batch</span>
            <span class="n">unq_X</span><span class="p">,</span> <span class="n">lookup</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">unq_V</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ngrams_count_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_words</span><span class="p">:</span>
                <span class="n">unq_V2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_count_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
                <span class="n">unq_V</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">unq_V</span><span class="p">,</span> <span class="n">unq_V2</span><span class="p">),</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">)</span>

            <span class="n">unseen_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">setdiff1d</span><span class="p">(</span><span class="n">unq_X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">H_dict_</span><span class="p">]))</span>
            <span class="n">unseen_V</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ngrams_count_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">unseen_X</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_words</span><span class="p">:</span>
                <span class="n">unseen_V2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_count_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">unseen_X</span><span class="p">)</span>
                <span class="n">unseen_V</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">unseen_V</span><span class="p">,</span> <span class="n">unseen_V2</span><span class="p">),</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">unseen_V</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">unseen_H</span> <span class="o">=</span> <span class="n">_rescale_h</span><span class="p">(</span>
                    <span class="n">unseen_V</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">unseen_X</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">))</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">unseen_X</span><span class="p">,</span> <span class="n">unseen_H</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">H_dict_</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">h</span>
                <span class="k">del</span> <span class="n">unseen_H</span>
            <span class="k">del</span> <span class="n">unseen_X</span><span class="p">,</span> <span class="n">unseen_V</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># If it is the first batch, call _init_vars to init unq_X, unq_V</span>
            <span class="n">unq_X</span><span class="p">,</span> <span class="n">unq_V</span><span class="p">,</span> <span class="n">lookup</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_vars</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="n">unq_H</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_H</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
        <span class="c1"># Update unq_H, the activations</span>
        <span class="n">unq_H</span> <span class="o">=</span> <span class="n">_multiplicative_update_h</span><span class="p">(</span>
            <span class="n">unq_V</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">,</span>
            <span class="n">unq_H</span><span class="p">,</span>
            <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
            <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter_e_step</span><span class="p">,</span>
            <span class="n">rescale_W</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rescale_W</span><span class="p">,</span>
            <span class="n">gamma_shape_prior</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma_shape_prior</span><span class="p">,</span>
            <span class="n">gamma_scale_prior</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma_scale_prior</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Update the topics self.W_</span>
        <span class="n">_multiplicative_update_w</span><span class="p">(</span>
            <span class="n">unq_V</span><span class="p">[</span><span class="n">lookup</span><span class="p">],</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">A_</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">B_</span><span class="p">,</span>
            <span class="n">unq_H</span><span class="p">[</span><span class="n">lookup</span><span class="p">],</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rescale_W</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rho_</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Update self.H_dict_ with the learned encoded vectors (activations)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">H_dict_</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">unq_X</span><span class="p">,</span> <span class="n">unq_H</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">_add_unseen_keys_to_H_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add activations of unseen string categories from X to H_dict.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">unseen_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">setdiff1d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">H_dict_</span><span class="p">]))</span>
        <span class="k">if</span> <span class="n">unseen_X</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">unseen_V</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ngrams_count_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">unseen_X</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_words</span><span class="p">:</span>
                <span class="n">unseen_V2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_count_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">unseen_X</span><span class="p">)</span>
                <span class="n">unseen_V</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">unseen_V</span><span class="p">,</span> <span class="n">unseen_V2</span><span class="p">),</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">)</span>

            <span class="n">unseen_H</span> <span class="o">=</span> <span class="n">_rescale_h</span><span class="p">(</span>
                <span class="n">unseen_V</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">unseen_V</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">))</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">H_dict_</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">unseen_X</span><span class="p">,</span> <span class="n">unseen_H</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the encoded vectors (activations) H of input strings in X.</span>
<span class="sd">        Given the learnt topics W, the activations H are tuned to fit V = HW.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape (n_samples)</span>
<span class="sd">            The string data to encode.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        H : 2-d array, shape (n_samples, n_topics)</span>
<span class="sd">            Transformed input.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check if first item has str or np.str_ type</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">str</span><span class="p">),</span> <span class="s2">&quot;Input data is not string. &quot;</span>
        <span class="n">unq_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="c1"># Build the n-grams counts matrix V for the string data to encode</span>
        <span class="n">unq_V</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ngrams_count_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_words</span><span class="p">:</span>  <span class="c1"># Add words counts</span>
            <span class="n">unq_V2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_count_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
            <span class="n">unq_V</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">unq_V</span><span class="p">,</span> <span class="n">unq_V2</span><span class="p">),</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">)</span>
        <span class="c1"># Add unseen strings in X to H_dict</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_add_unseen_keys_to_H_dict</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
        <span class="n">unq_H</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_H</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
        <span class="c1"># Loop over batches</span>
        <span class="k">for</span> <span class="n">slc</span> <span class="ow">in</span> <span class="n">gen_batches</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">unq_H</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="c1"># Given the learnt topics W, optimize H to fit V = HW</span>
            <span class="n">unq_H</span><span class="p">[</span><span class="n">slc</span><span class="p">]</span> <span class="o">=</span> <span class="n">_multiplicative_update_h</span><span class="p">(</span>
                <span class="n">unq_V</span><span class="p">[</span><span class="n">slc</span><span class="p">],</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">,</span>
                <span class="n">unq_H</span><span class="p">[</span><span class="n">slc</span><span class="p">],</span>
                <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
                <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                <span class="n">rescale_W</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rescale_W</span><span class="p">,</span>
                <span class="n">gamma_shape_prior</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma_shape_prior</span><span class="p">,</span>
                <span class="n">gamma_scale_prior</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma_scale_prior</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="c1"># Store and return the encoded vectors of X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">H_dict_</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">unq_X</span><span class="p">,</span> <span class="n">unq_H</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_H</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>


<div class="viewcode-block" id="GapEncoder"><a class="viewcode-back" href="../../generated/dirty_cat.GapEncoder.html#dirty_cat.GapEncoder">[docs]</a><span class="k">class</span> <span class="nc">GapEncoder</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This encoder can be understood as a continuous encoding on a set of latent</span>
<span class="sd">    categories estimated from the data. The latent categories are built by</span>
<span class="sd">    capturing combinations of substrings that frequently co-occur.</span>

<span class="sd">    The GapEncoder supports online learning on batches of data for</span>
<span class="sd">    scalability through the partial_fit method.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_components : int, default=10</span>
<span class="sd">        Number of latent categories used to model string data.</span>
<span class="sd">    batch_size : int, default=128</span>
<span class="sd">        Number of samples per batch.</span>
<span class="sd">    gamma_shape_prior : float, default=1.1</span>
<span class="sd">        Shape parameter for the Gamma prior distribution.</span>
<span class="sd">    gamma_scale_prior : float, default=1.0</span>
<span class="sd">        Scale parameter for the Gamma prior distribution.</span>
<span class="sd">    rho : float, default=0.95</span>
<span class="sd">        Weight parameter for the update of the W matrix.</span>
<span class="sd">    rescale_rho : bool, default=False</span>
<span class="sd">        If true, use rho ** (batch_size / len(X)) instead of rho to obtain an</span>
<span class="sd">        update rate per iteration that is independent of the batch size.</span>
<span class="sd">    hashing : bool, default=False</span>
<span class="sd">        If true, HashingVectorizer is used instead of CountVectorizer.</span>
<span class="sd">        It has the advantage of being very low memory scalable to large</span>
<span class="sd">        datasets as there is no need to store a vocabulary dictionary in</span>
<span class="sd">        memory.</span>
<span class="sd">    hashing_n_features : int, default=2**12</span>
<span class="sd">        Number of features for the HashingVectorizer. Only relevant if</span>
<span class="sd">        hashing=True.</span>
<span class="sd">    init : typing.Literal[&quot;k-means++&quot;, &quot;random&quot;, &quot;k-means&quot;], default=&#39;k-means++&#39;</span>
<span class="sd">        Initialization method of the W matrix.</span>
<span class="sd">        Options: {&#39;k-means++&#39;, &#39;random&#39;, &#39;k-means&#39;}.</span>
<span class="sd">        If init=&#39;k-means++&#39;, we use the init method of sklearn.cluster.KMeans.</span>
<span class="sd">        If init=&#39;random&#39;, topics are initialized with a Gamma distribution.</span>
<span class="sd">        If init=&#39;k-means&#39;, topics are initialized with a KMeans on the n-grams</span>
<span class="sd">        counts. This usually makes convergence faster but is a bit slower.</span>
<span class="sd">    tol : float, default=1e-4</span>
<span class="sd">        Tolerance for the convergence of the matrix W.</span>
<span class="sd">    min_iter : int, default=2</span>
<span class="sd">        Minimum number of iterations on the input data.</span>
<span class="sd">    max_iter : int, default=5</span>
<span class="sd">        Maximum number of iterations on the input data.</span>
<span class="sd">    ngram_range : typing.Tuple[int, int], default=(2, 4)</span>
<span class="sd">        The range of ngram length that will be used to build the</span>
<span class="sd">        bag-of-n-grams representation of the input data.</span>
<span class="sd">    analyzer : typing.Literal[&quot;word&quot;, &quot;char&quot;, &quot;char_wb&quot;], default=&#39;char&#39;.</span>
<span class="sd">        Analyzer parameter for the CountVectorizer/HashingVectorizer.</span>
<span class="sd">        Options: {word, char, char_wb}, describing whether the matrix V</span>
<span class="sd">        to factorize should be made of word counts or character n-gram counts.</span>
<span class="sd">        Option char_wb creates character n-grams only from text inside word</span>
<span class="sd">        boundaries; n-grams at the edges of words are padded with space.</span>
<span class="sd">    add_words : bool, default=False</span>
<span class="sd">        If true, add the words counts to the bag-of-n-grams representation</span>
<span class="sd">        of the input data.</span>
<span class="sd">    random_state : typing.Optional[Union[int, RandomState]], default=None</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>
<span class="sd">    rescale_W : bool, default=True</span>
<span class="sd">        If true, the weight matrix W is rescaled at each iteration</span>
<span class="sd">        to have a l1 norm equal to 1 for each row.</span>
<span class="sd">    max_iter_e_step : int, default=20</span>
<span class="sd">        Maximum number of iterations to adjust the activations h at each step.</span>
<span class="sd">    handle_missing : typing.Literal[&quot;error&quot;, &quot;empty_impute&quot;], default=empty_impute</span>
<span class="sd">        Whether to raise an error or impute with empty string &#39;&#39; if missing</span>
<span class="sd">        values (NaN) are present during fit (default is to impute).</span>
<span class="sd">        In the inverse transform, the missing category will be denoted as None.</span>


<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    rho_: float</span>
<span class="sd">    fitted_models_: typing.List[GapEncoderColumn]</span>
<span class="sd">    column_names_: typing.List[str]</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    For a detailed description of the method, see</span>
<span class="sd">    `Encoding high-cardinality string categorical variables</span>
<span class="sd">    &lt;https://hal.inria.fr/hal-02171256v4&gt;`_ by Cerda, Varoquaux (2019).</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">rho_</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">fitted_models_</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">GapEncoderColumn</span><span class="p">]</span>
    <span class="n">column_names_</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_components</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
        <span class="n">gamma_shape_prior</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.1</span><span class="p">,</span>
        <span class="n">gamma_scale_prior</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">rho</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.95</span><span class="p">,</span>
        <span class="n">rescale_rho</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">hashing</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">hashing_n_features</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="mi">12</span><span class="p">,</span>
        <span class="n">init</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;k-means++&quot;</span><span class="p">,</span> <span class="s2">&quot;random&quot;</span><span class="p">,</span> <span class="s2">&quot;k-means&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;k-means++&quot;</span><span class="p">,</span>
        <span class="n">tol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">min_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
        <span class="n">ngram_range</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
        <span class="n">analyzer</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;word&quot;</span><span class="p">,</span> <span class="s2">&quot;char&quot;</span><span class="p">,</span> <span class="s2">&quot;char_wb&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;char&quot;</span><span class="p">,</span>
        <span class="n">add_words</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">random_state</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">RandomState</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">rescale_W</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">max_iter_e_step</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
        <span class="n">handle_missing</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;error&quot;</span><span class="p">,</span> <span class="s2">&quot;empty_impute&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;zero_impute&quot;</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ngram_range</span> <span class="o">=</span> <span class="n">ngram_range</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">=</span> <span class="n">n_components</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma_shape_prior</span> <span class="o">=</span> <span class="n">gamma_shape_prior</span>  <span class="c1"># &#39;a&#39; parameter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma_scale_prior</span> <span class="o">=</span> <span class="n">gamma_scale_prior</span>  <span class="c1"># &#39;b&#39; parameter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rho</span> <span class="o">=</span> <span class="n">rho</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rescale_rho</span> <span class="o">=</span> <span class="n">rescale_rho</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hashing</span> <span class="o">=</span> <span class="n">hashing</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hashing_n_features</span> <span class="o">=</span> <span class="n">hashing_n_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_iter</span> <span class="o">=</span> <span class="n">min_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init</span> <span class="o">=</span> <span class="n">init</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">analyzer</span> <span class="o">=</span> <span class="n">analyzer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_words</span> <span class="o">=</span> <span class="n">add_words</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rescale_W</span> <span class="o">=</span> <span class="n">rescale_W</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter_e_step</span> <span class="o">=</span> <span class="n">max_iter_e_step</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">handle_missing</span> <span class="o">=</span> <span class="n">handle_missing</span>

    <span class="k">def</span> <span class="nf">_more_tags</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Used internally by sklearn to ease the estimator checks.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;X_types&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;categorical&quot;</span><span class="p">]}</span>

    <span class="k">def</span> <span class="nf">_create_column_gap_encoder</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GapEncoderColumn</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">GapEncoderColumn</span><span class="p">(</span>
            <span class="n">ngram_range</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ngram_range</span><span class="p">,</span>
            <span class="n">n_components</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">,</span>
            <span class="n">analyzer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">analyzer</span><span class="p">,</span>
            <span class="n">gamma_shape_prior</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma_shape_prior</span><span class="p">,</span>
            <span class="n">gamma_scale_prior</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma_scale_prior</span><span class="p">,</span>
            <span class="n">rho</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rho</span><span class="p">,</span>
            <span class="n">rescale_rho</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rescale_rho</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
            <span class="n">hashing</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hashing</span><span class="p">,</span>
            <span class="n">hashing_n_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hashing_n_features</span><span class="p">,</span>
            <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
            <span class="n">init</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="p">,</span>
            <span class="n">add_words</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">add_words</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
            <span class="n">rescale_W</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rescale_W</span><span class="p">,</span>
            <span class="n">max_iter_e_step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter_e_step</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_handle_missing</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Imputes missing values with `` or raises an error</span>
<span class="sd">        Note: modifies the array in-place.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">handle_missing</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;error&quot;</span><span class="p">,</span> <span class="s2">&quot;zero_impute&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;handle_missing should be either &#39;error&#39; or &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;&#39;zero_impute&#39;, got </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">handle_missing</span><span class="si">!r}</span><span class="s2">. &quot;</span>
            <span class="p">)</span>

        <span class="n">missing_mask</span> <span class="o">=</span> <span class="n">_object_dtype_isnan</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">missing_mask</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">handle_missing</span> <span class="o">==</span> <span class="s2">&quot;error&quot;</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Input data contains missing values. &quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">handle_missing</span> <span class="o">==</span> <span class="s2">&quot;zero_impute&quot;</span><span class="p">:</span>
                <span class="n">X</span><span class="p">[</span><span class="n">missing_mask</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

        <span class="k">return</span> <span class="n">X</span>

<div class="viewcode-block" id="GapEncoder.fit"><a class="viewcode-back" href="../../generated/dirty_cat.GapEncoder.html#dirty_cat.GapEncoder.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;GapEncoder&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the GapEncoder on batches of X.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape (n_samples, n_features)</span>
<span class="sd">            The string data to fit the model on.</span>
<span class="sd">        y : None</span>
<span class="sd">            Unused, only here for compatibility.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        GapEncoder</span>
<span class="sd">            Fitted GapEncoder instance.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Copy parameter rho</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rho_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rho</span>
        <span class="c1"># If X is a dataframe, store its column names</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">column_names_</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
        <span class="c1"># Check input data shape</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_input</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_handle_missing</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fitted_models_</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">col_enc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_column_gap_encoder</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fitted_models_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">col_enc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">k</span><span class="p">]))</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="GapEncoder.transform"><a class="viewcode-back" href="../../generated/dirty_cat.GapEncoder.html#dirty_cat.GapEncoder.transform">[docs]</a>    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the encoded vectors (activations) H of input strings in X.</span>
<span class="sd">        Given the learnt topics W, the activations H are tuned to fit V = HW.</span>
<span class="sd">        When X has several columns, they are encoded separately and</span>
<span class="sd">        then concatenated.</span>

<span class="sd">        Remark: calling transform multiple times in a row on the same</span>
<span class="sd">        input X can give slightly different encodings. This is expected</span>
<span class="sd">        due to a caching mechanism to speed things up.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape (n_samples, n_features)</span>
<span class="sd">            The string data to encode.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        H : 2-d array, shape (n_samples, n_topics * n_features)</span>
<span class="sd">            Transformed input.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Check input data shape</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_input</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_handle_missing</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">X_enc</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">X_enc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fitted_models_</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">k</span><span class="p">]))</span>
        <span class="n">X_enc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">X_enc</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">X_enc</span></div>

<div class="viewcode-block" id="GapEncoder.partial_fit"><a class="viewcode-back" href="../../generated/dirty_cat.GapEncoder.html#dirty_cat.GapEncoder.partial_fit">[docs]</a>    <span class="k">def</span> <span class="nf">partial_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;GapEncoder&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Partial fit of the GapEncoder on X.</span>
<span class="sd">        To be used in an online learning procedure where batches of data are</span>
<span class="sd">        coming one by one.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape (n_samples, n_features)</span>
<span class="sd">            The string data to fit the model on.</span>
<span class="sd">        y : None</span>
<span class="sd">            Unused, only here for compatibility.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        GapEncoder</span>
<span class="sd">            Fitted GapEncoder instance.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># If X is a dataframe, store its column names</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">column_names_</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
        <span class="c1"># Check input data shape</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_input</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_handle_missing</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="c1"># Init the `GapEncoderColumn` instances if the model was</span>
        <span class="c1"># not fitted already.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;fitted_models_&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fitted_models_</span> <span class="o">=</span> <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_create_column_gap_encoder</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="p">]</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fitted_models_</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">partial_fit</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">k</span><span class="p">])</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="GapEncoder.get_feature_names_out"><a class="viewcode-back" href="../../generated/dirty_cat.GapEncoder.html#dirty_cat.GapEncoder.get_feature_names_out">[docs]</a>    <span class="k">def</span> <span class="nf">get_feature_names_out</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">col_names</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;auto&quot;</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">n_labels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the labels that best summarize the learned components/topics.</span>
<span class="sd">        For each topic, labels with the highest activations are selected.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        col_names : typing.Optional[typing.Union[typing.Literal[&quot;auto&quot;], typing.List[str]]], default=None  # noqa</span>
<span class="sd">            The column names to be added as prefixes before the labels.</span>
<span class="sd">            If col_names == None, no prefixes are used.</span>
<span class="sd">            If col_names == &#39;auto&#39;, column names are automatically defined:</span>
<span class="sd">                - if the input data was a dataframe, its column names are used,</span>
<span class="sd">                - otherwise, &#39;col1&#39;, ..., &#39;colN&#39; are used as prefixes.</span>
<span class="sd">            Prefixes can be manually set by passing a list for col_names.</span>

<span class="sd">        n_labels : int, default=3</span>
<span class="sd">            The number of labels used to describe each topic.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        topic_labels : list of strings</span>
<span class="sd">            The labels that best describe each topic.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">hasattr</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;fitted_models_&quot;</span>
        <span class="p">),</span> <span class="s2">&quot;ERROR: GapEncoder must be fitted first.&quot;</span>
        <span class="c1"># Generate prefixes</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">col_names</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">col_names</span> <span class="o">==</span> <span class="s2">&quot;auto&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;column_names_&quot;</span><span class="p">):</span>  <span class="c1"># Use column names</span>
                <span class="n">prefixes</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">: &quot;</span> <span class="o">%</span> <span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">column_names_</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># Use &#39;col1: &#39;, ... &#39;colN: &#39; as prefixes</span>
                <span class="n">prefixes</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;col</span><span class="si">%d</span><span class="s2">: &quot;</span> <span class="o">%</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fitted_models_</span><span class="p">))]</span>
        <span class="k">elif</span> <span class="n">col_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># Empty prefixes</span>
            <span class="n">prefixes</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fitted_models_</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prefixes</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">: &quot;</span> <span class="o">%</span> <span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">col_names</span><span class="p">]</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">enc</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fitted_models_</span><span class="p">):</span>
            <span class="n">col_labels</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">(</span><span class="n">n_labels</span><span class="p">,</span> <span class="n">prefixes</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
            <span class="n">labels</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">col_labels</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">labels</span></div>

<div class="viewcode-block" id="GapEncoder.get_feature_names"><a class="viewcode-back" href="../../generated/dirty_cat.GapEncoder.html#dirty_cat.GapEncoder.get_feature_names">[docs]</a>    <span class="k">def</span> <span class="nf">get_feature_names</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">input_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">col_names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">n_labels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Ensures compatibility with sklearn &lt; 1.0.</span>
<span class="sd">        Use `get_feature_names_out` instead.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">Version</span><span class="p">(</span><span class="n">sklearn_version</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="s2">&quot;1.0&quot;</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Following the changes in scikit-learn 1.0, &quot;</span>
                <span class="s2">&quot;get_feature_names is deprecated. &quot;</span>
                <span class="s2">&quot;Use get_feature_names_out instead. &quot;</span><span class="p">,</span>
                <span class="ne">DeprecationWarning</span><span class="p">,</span>
                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">(</span><span class="n">col_names</span><span class="p">,</span> <span class="n">n_labels</span><span class="p">)</span></div>

<div class="viewcode-block" id="GapEncoder.score"><a class="viewcode-back" href="../../generated/dirty_cat.GapEncoder.html#dirty_cat.GapEncoder.score">[docs]</a>    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the sum over the columns of X of the Kullback-Leibler</span>
<span class="sd">        divergence between the n-grams counts matrix V of X, and its</span>
<span class="sd">        non-negative factorization HW.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like (str), shape (n_samples, n_features)</span>
<span class="sd">            The data to encode.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float.</span>
<span class="sd">            The Kullback-Leibler divergence.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_input</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">kl_divergence</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">kl_divergence</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fitted_models_</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">k</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">kl_divergence</span></div></div>


<span class="k">def</span> <span class="nf">_rescale_W</span><span class="p">(</span><span class="n">W</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="n">A</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Rescale the topics W to have a L1-norm equal to 1.</span>
<span class="sd">    Note that they are modified in-place.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">W</span> <span class="o">/=</span> <span class="n">s</span>
    <span class="n">A</span> <span class="o">/=</span> <span class="n">s</span>


<span class="k">def</span> <span class="nf">_multiplicative_update_w</span><span class="p">(</span>
    <span class="n">Vt</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span>
    <span class="n">W</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span>
    <span class="n">A</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span>
    <span class="n">B</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span>
    <span class="n">Ht</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span>
    <span class="n">rescale_W</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">rho</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Multiplicative update step for the topics W.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">A</span> <span class="o">*=</span> <span class="n">rho</span>
    <span class="n">A</span> <span class="o">+=</span> <span class="n">W</span> <span class="o">*</span> <span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">Ht</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Vt</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Ht</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-10</span><span class="p">)))</span>
    <span class="n">B</span> <span class="o">*=</span> <span class="n">rho</span>
    <span class="n">B</span> <span class="o">+=</span> <span class="n">Ht</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">W</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">rescale_W</span><span class="p">:</span>
        <span class="n">_rescale_W</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">W</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span>


<span class="k">def</span> <span class="nf">_rescale_h</span><span class="p">(</span><span class="n">V</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="n">H</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Rescale the activations H.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-10</span>  <span class="c1"># in case of a document having length=0</span>
    <span class="n">H</span> <span class="o">*=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">V</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">A</span><span class="p">)</span>
    <span class="n">H</span> <span class="o">/=</span> <span class="n">H</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">H</span>


<span class="k">def</span> <span class="nf">_multiplicative_update_h</span><span class="p">(</span>
    <span class="n">Vt</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span>
    <span class="n">W</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span>
    <span class="n">Ht</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span>
    <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
    <span class="n">max_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">rescale_W</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">gamma_shape_prior</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.1</span><span class="p">,</span>
    <span class="n">gamma_scale_prior</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Multiplicative update step for the activations H.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">rescale_W</span><span class="p">:</span>
        <span class="n">WT1</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">gamma_scale_prior</span>
        <span class="n">W_WT1</span> <span class="o">=</span> <span class="n">W</span> <span class="o">/</span> <span class="n">WT1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">WT1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">gamma_scale_prior</span>
        <span class="n">W_WT1</span> <span class="o">=</span> <span class="n">W</span> <span class="o">/</span> <span class="n">WT1</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">const</span> <span class="o">=</span> <span class="p">(</span><span class="n">gamma_shape_prior</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">WT1</span>
    <span class="n">squared_epsilon</span> <span class="o">=</span> <span class="n">epsilon</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">for</span> <span class="n">vt</span><span class="p">,</span> <span class="n">ht</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">Vt</span><span class="p">,</span> <span class="n">Ht</span><span class="p">):</span>
        <span class="n">vt_</span> <span class="o">=</span> <span class="n">vt</span><span class="o">.</span><span class="n">data</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">vt</span><span class="o">.</span><span class="n">indices</span>
        <span class="n">W_WT1_</span> <span class="o">=</span> <span class="n">W_WT1</span><span class="p">[:,</span> <span class="n">idx</span><span class="p">]</span>
        <span class="n">W_</span> <span class="o">=</span> <span class="n">W</span><span class="p">[:,</span> <span class="n">idx</span><span class="p">]</span>
        <span class="n">squared_norm</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">n_iter_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">squared_norm</span> <span class="o">&lt;=</span> <span class="n">squared_epsilon</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">aux</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W_WT1_</span><span class="p">,</span> <span class="n">vt_</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ht</span><span class="p">,</span> <span class="n">W_</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-10</span><span class="p">))</span>
            <span class="n">ht_out</span> <span class="o">=</span> <span class="n">ht</span> <span class="o">*</span> <span class="n">aux</span> <span class="o">+</span> <span class="n">const</span>
            <span class="n">squared_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ht_out</span> <span class="o">-</span> <span class="n">ht</span><span class="p">,</span> <span class="n">ht_out</span> <span class="o">-</span> <span class="n">ht</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ht</span><span class="p">,</span> <span class="n">ht</span><span class="p">)</span>
            <span class="n">ht</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">ht_out</span>
    <span class="k">return</span> <span class="n">Ht</span>


<span class="k">def</span> <span class="nf">batch_lookup</span><span class="p">(</span>
    <span class="n">lookup</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span>
    <span class="n">n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Generator</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">],</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Make batches of the lookup array.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">len_iter</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">lookup</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">len_iter</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">lookup</span><span class="p">[</span><span class="nb">slice</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">idx</span> <span class="o">+</span> <span class="n">n</span><span class="p">,</span> <span class="n">len_iter</span><span class="p">))]</span>
        <span class="n">unq_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
        <span class="k">yield</span> <span class="n">unq_indices</span><span class="p">,</span> <span class="n">indices</span>


<span class="k">def</span> <span class="nf">get_kmeans_prototypes</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">n_prototypes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">analyzer</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;word&quot;</span><span class="p">,</span> <span class="s2">&quot;char&quot;</span><span class="p">,</span> <span class="s2">&quot;char_wb&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;char&quot;</span><span class="p">,</span>
    <span class="n">hashing_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
    <span class="n">ngram_range</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
    <span class="n">sparse</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">random_state</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">RandomState</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes prototypes based on:</span>
<span class="sd">      - dimensionality reduction (via hashing n-grams)</span>
<span class="sd">      - k-means clustering</span>
<span class="sd">      - nearest neighbor</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">vectorizer</span> <span class="o">=</span> <span class="n">HashingVectorizer</span><span class="p">(</span>
        <span class="n">analyzer</span><span class="o">=</span><span class="n">analyzer</span><span class="p">,</span>
        <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">alternate_sign</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">ngram_range</span><span class="o">=</span><span class="n">ngram_range</span><span class="p">,</span>
        <span class="n">n_features</span><span class="o">=</span><span class="n">hashing_dim</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">projected</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sparse</span><span class="p">:</span>
        <span class="n">projected</span> <span class="o">=</span> <span class="n">projected</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">n_prototypes</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
    <span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">projected</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
    <span class="n">centers</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span>
    <span class="n">neighbors</span> <span class="o">=</span> <span class="n">NearestNeighbors</span><span class="p">()</span>
    <span class="n">neighbors</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">projected</span><span class="p">)</span>
    <span class="n">indexes_prototypes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">neighbors</span><span class="o">.</span><span class="n">kneighbors</span><span class="p">(</span><span class="n">centers</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">indexes_prototypes</span><span class="p">])</span>
</pre></div>

          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2018-2021, dirty_cat developers.
      
    </div>

    

    
  </body>
</html>