{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Scalability considerations for similarity encoding\n\nWe discuss in this notebook how to efficiently apply the |SE| to larger\ndatasets: reducing the number of reference categories to \"prototypes\",\neither chosen as the most frequent categories, or with kmeans clustering.\n\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The |Gap| naturally does data reduction and comes with online estimation.\n    As a result, is it more scalable than the |SE|,\n    and should be preferred in large-scale settings.</p></div>\n\n\n.. |SE| replace:: :class:`~dirty_cat.SimilarityEncoder`\n\n.. |Gap| replace:: :class:`~dirty_cat.GapEncoder`\n\n.. |ColumnTransformer| replace:: :class:`~sklearn.compose.ColumnTransformer`\n\n.. |OHE| replace:: :class:`~sklearn.preprocessing.OneHotEncoder`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A tool to report memory usage and run time\n\nFor this example, we build a small tool that reports memory\nusage and compute time of a function\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from time import perf_counter\nimport functools\nimport tracemalloc\n\n\ndef resource_used(func):\n    \"\"\"\n    Decorator for performance analysis.\n    \"\"\"\n\n    @functools.wraps(func)\n    def wrapped_func(*args, **kwargs):\n        t0 = perf_counter()  # Launch a time\n        tracemalloc.start()\n        out = func(*args, **kwargs)\n        size, peak = tracemalloc.get_traced_memory()\n        tracemalloc.stop()\n        peak /= (1024 ** 2)  # Convert to megabytes\n        print(f\"Run time: {perf_counter() - t0:.2f}s | \"\n              f\"Memory used: {peak:.2f}MB. \")\n        return out\n\n    return wrapped_func"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Importing and preprocessing\n\nFirst, let's fetch the dataset we'll use further down\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\nfrom dirty_cat.datasets import fetch_open_payments\n\nopen_payments = fetch_open_payments()\nX = open_payments.X\n\nopen_payments.description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll perform a some cleaning\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from functools import reduce\n\n# Remove the missing lines in X\nna_mask: pd.DataFrame = X.isna()\nX = X.dropna(axis=0).reset_index(drop=True)\n\ny = open_payments.y\n# Combine boolean masks\nna_mask = na_mask.any(axis=1)\n# Drop the lines in y that contained missing values in X\ny = y[~na_mask].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll write down which columns are clean and which are dirty\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "clean_columns = [\n    'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name',\n    'Dispute_Status_for_Publication',\n    'Physician_Specialty',\n]\ndirty_columns = [\n    'Name_of_Associated_Covered_Device_or_Medical_Supply1',\n    'Name_of_Associated_Covered_Drug_or_Biological1',\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will use |SE| on the two dirty columns defined above.\nOne difficulty is that they have many entries, and because of that, as we'll\nsee, the :code:`SimilarityEncoder` will take a while.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X[dirty_columns].value_counts()[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X[dirty_columns].nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SimilarityEncoder with default options\n\nLet us build our vectorizer, using a |ColumnTransformer| to combine\na |OHE| and a |SE|\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom dirty_cat import SimilarityEncoder\n\nclean_col_transformer = [\n    ('one_hot',\n     OneHotEncoder(sparse=False, handle_unknown='ignore'),\n     clean_columns),\n]\n\ncolumn_trans = ColumnTransformer(\n    transformers=clean_col_transformer + [\n        ('sim_enc',\n         SimilarityEncoder(),\n         dirty_columns)\n    ],\n    remainder='drop')\n\nt0 = perf_counter()\nX_enc = column_trans.fit_transform(X)\nt1 = perf_counter()\nprint(f'Time to vectorize: {t1 - t0:.3f}s')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's now run a cross-validation!\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn import pipeline, model_selection\nfrom sklearn.linear_model import LogisticRegression\n\n# We specify max_iter to avoid convergence warnings\nlog_reg = LogisticRegression(max_iter=10000)\n\nmodel = pipeline.make_pipeline(column_trans, log_reg)\nresults = resource_used(model_selection.cross_validate)(model, X, y)\nprint(f\"Cross-validation score: {results['test_score']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Store results for later\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scores = dict()\nscores['Default options'] = results['test_score']\ntimes = dict()\ntimes['Default options'] = results['fit_time']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Most frequent strategy to define prototypes\n\nThe :code:`most_frequent` strategy selects the :code:`n` most frequent\nvalues in a dirty categorical variable to reduce the dimensionality of the\nproblem and thus speed things up.\nHere, we arbitrarily choose 100 as the number of prototypes we want to use.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "column_trans = ColumnTransformer(\n    transformers=clean_col_transformer + [\n        ('sim_enc',\n         SimilarityEncoder(categories='most_frequent', n_prototypes=100),\n         dirty_columns)\n    ],\n    remainder='drop')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check that the prediction is still as good\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = pipeline.make_pipeline(column_trans, log_reg)\nresults = resource_used(model_selection.cross_validate)(model, X, y)\nprint(f\"Cross-validation score: {results['test_score']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Store results for later\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scores['Most frequent'] = results['test_score']\ntimes['Most frequent'] = results['fit_time']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## KMeans strategy to define prototypes\n\nThe k-means strategy is also a dimensionality reduction technique.\nThe :code:`SimilarityEncoder` can apply a K-means and nearest neighbors\nalgorithm to find the prototypes. Once again, the number of prototypes\nwe chose here is arbitrary.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "column_trans = ColumnTransformer(\n    transformers=clean_col_transformer + [\n        ('sim_enc',\n         SimilarityEncoder(categories='k-means', n_prototypes=100),\n         dirty_columns)\n    ],\n    remainder='drop')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check that the prediction is still as good\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = pipeline.make_pipeline(column_trans, log_reg)\nresults = resource_used(model_selection.cross_validate)(model, X, y)\nprint(\"Cross-validation score: %s\" % results['test_score'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Store results for later\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scores['KMeans'] = results['test_score']\ntimes['KMeans'] = results['fit_time']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import seaborn\nimport matplotlib.pyplot as plt\n\n_, (ax1, ax2) = plt.subplots(nrows=2, figsize=(4, 3))\nseaborn.boxplot(data=pd.DataFrame(scores), orient='h', ax=ax1)\nax1.set_xlabel('Prediction accuracy', size=16)\n[t.set(size=16) for t in ax1.get_yticklabels()]\n\nseaborn.boxplot(data=pd.DataFrame(times), orient='h', ax=ax2)\nax2.set_xlabel('Computation time', size=16)\n[t.set(size=16) for t in ax2.get_yticklabels()]\nplt.tight_layout()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}