{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Skrub expressions\n\nSkrub provides special objects that represent intermediate results in a\ncomputation. They record the different operations we perform on them (such as\napplying operators or calling methods), which allows to later retrieve the\nwhole computation graph as a machine-learning estimator that can be fitted and\napplied to unseen data.\n\nBecause those Skrub objects encapsulate a computation, which can be evaluated\nto produce a result, we call them \"expressions\".\n\nThe simplest expressions are variables, which represent inputs to our\nmachine-learning estimator such as a ``\"products\"`` or a ``\"customers\"`` table.\nThose variables can be combined with operators and function calls to build up\nmore complex expressions. The estimator is being constructed implicitly when we\napply those operations, rather than by providing an explicit list of\ntransformations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We start by declaring inputs with ``skrub.var``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import skrub\n\na = skrub.var(\"a\")\nb = skrub.var(\"b\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then apply transformations, composing more complex expressions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "c = a + b\nc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can evaluate the expression.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "c.skb.eval({\"a\": 10, \"b\": 6})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "c.skb.eval({\"a\": 2, \"b\": 3})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As shown above, the special ``.skb`` attribute provides access to skrub\nfunctionality to interact with the expression object itself. Access to any other\nattribute is simply added as a new operation in the computation\ngraph:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "d = c.capitalize()\nd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "d.skb.eval({\"a\": \"hello, \", \"b\": \"world!\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we can get an estimator that can be fitted and applied to data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "estimator = c.skb.get_estimator()\nestimator.fit_transform({\"a\": 10, \"b\": 7})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Handling multiple inputs\n\nOne advantage of the approach outlined above is that we can build models that\nhandle and transform multiple tables (and other kinds of inputs).\n\nScikit-learn pipelines represent a linear sequence of transformations on one\ntable with a fixed number of rows.\n\n<img src=\"file://../../_static/sklearn_pipeline.svg\" width=\"500\">\n\nSkrub expressions, on the other hand, can manipulate any number of variables.\nThe transformation they perform is not a linear sequence but any Directed\nAcyclic Graph of computations.\n\n<img src=\"file://../../_static/skrub_expressions.svg\">\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Previews of the results\n\nAs we saw above, we can call ``eval()`` with a dictionary of bindings for the\nvariables in our expression in order to compute the result of the pipeline.\nHowever, this is an operation that we want to do very often during development:\nto avoid having to call ``eval()`` repeatedly, skrub provides a way to\npreview the result of the expression as we work on it.\n\nWhen we create a variable, we can pass a value in addition to its name. If a value\nis provided, skrub will use it to compute the result of the expression on the\nvalue. This makes\nthe development more interactive, allows catching errors early, and can\nprovide better help and tab-completion in an interactive Python shell.\n\nMoreover, those values can be used to obtain a fitted estimator or\ncross-validation scores as we will see.\n\nNote that example values are immutable throughout the pipeline. This means that\nto change the value of a variable, we need to create the pipeline again with\nthe new value.\n\nTo provide an example value to ``var(\"a\")``, we can write:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "a = skrub.var(\"a\", 10)  # note the value 10\nb = skrub.var(\"b\", 6)\nc = a + b\nc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the display above, you can still see the graph by clicking on the dropdown\n``\u25b6 Show graph``.\n\nSeeing results for the values we provided does *not* change the fact that we\nare building a computation graph that we want to reuse, not just computing\nthe result for a fixed input. We can think of the displayed result as a\npreview of the output on one example dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "c.skb.eval({\"a\": 3, \"b\": 2})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In what follows we will always provide values for our variables. When\nbuilding your own estimator we recommend you do so as well, because running\nthe estimator on example data every step of the way makes development much\neasier by catching errors as soon as the operation is added, rather than\nlater when fitting the full estimator.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Composing expressions\n\nThe simplest expressions are variables created with ``skrub.var``. Complex\nexpressions are constructed by applying functions or operators to other\nexpressions.\n\nSo what operations are allowed? Remember that when we apply an operation to\nan expression, it is implicitly added as a step in our computation. When we\nrun the computation, those operations are replayed on the actual data we\nprovide.\n\nSo we can use any operation that is valid for the types we will pass to run\nthe computation (with some caveats detailed below). If we know we will pass a\npandas DataFrame as the ``\"products\"`` table, we can use any of the methods\nof pandas DataFrames. If instead we know we will pass a numpy array, we use\nthe methods of numpy arrays, etc.\n\nMore operations (e.g. applying a scikit-learn estimator) are available\nthrough the special ``skb`` attribute, as we will see later.\n\n### Basic operations\n\nSuppose we want to process dataframes that look like this:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n\norders_df = pd.DataFrame(\n    {\n        \"item\": [\"pen\", \"cup\", \"pen\", \"fork\"],\n        \"price\": [1.5, None, 1.5, 2.2],\n        \"qty\": [1, 1, 2, 4],\n    }\n)\norders_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can create a skrub variable to represent that input\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "orders = skrub.var(\"orders\", orders_df)\norders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Because we know we will feed a DataFrame to the computation, we manipulate\n``products`` as if it were a DataFrame.\n\nWe can access its attributes:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "orders.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Access the \"items\" column, indexing, slicing:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "orders[\"item\"].iloc[1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Applying operators:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "orders[\"price\"] * orders[\"qty\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calling methods:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "orders.assign(total=orders[\"price\"] * orders[\"qty\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is important to note that the original ``orders`` pipeline is not modified\nby the previous cells. Instead, in each cell a new expression is created that\nrepresents the result of the operation.\n\nThis is similar to how pandas and polars\nDataFrames work: when we call a method on a DataFrame, it returns a new\nDataFrame that represents the result of the operation, rather than modifying\nthe original DataFrame in place. However, while in pandas it is possible to\nwork on a DataFrame in place, skrub does not allow this.\n\nWe can check this by looking at the graph of ``orders`` (which remains unmodified),\nand ``new_orders`` (which instead contains the new steps):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "orders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "new_orders = orders.assign(total=orders[\"price\"] * orders[\"qty\"])\nnew_orders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Applying machine-learning estimators\n\nAs mentioned above, in addition to those usual operations, the expressions\nhave a special attribute: ``.skb``, which gives access to the methods and objects\nprovided by skrub. A particularly important one is\n``.skb.apply()``, which allows to scikit-learn estimators to the pipeline.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "orders.skb.apply(skrub.TableVectorizer())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is also possible to apply a transformer to a subset of the columns:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "orders.skb.apply(skrub.StringEncoder(n_components=3), cols=\"item\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Again, the crucial part is that when applying such operations, the return\nvalue encapsulates the whole computation that produces the result we see. We are\nnot interested in a single result for the example values we provided, but in\nthe ability to retrieve a machine-learning estimator that we can fit and then\napply to unseen data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vectorized_orders = orders.assign(total=orders[\"price\"] * orders[\"qty\"]).skb.apply(\n    skrub.TableVectorizer()\n)\nvectorized_orders\n\n# We can use ``.skb.get_estimator(fitted=True)`` to retrieve the estimator and\n# fit it on the data we provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "estimator = vectorized_orders.skb.get_estimator(fitted=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now use the fitted estimator to transform new data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "new_orders = pd.DataFrame({\"item\": [\"fork\"], \"price\": [2.2], \"qty\": [5]})\nestimator.transform({\"orders\": new_orders})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deferred evaluation\n\nExpressions represent a computation that has not yet been executed, and will\nbe executed when we trigger it, for example by calling ``eval()`` or getting\nthe estimator and calling ``fit()``.\n\nThis means that we cannot use usual Python control flow statements such as\n``if``, ``for``, ``with`` etc. with expressions, because those constructs would\nexecute immediately.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For example, we cannot do this::\n\n    for column in orders.columns:\n        pass\n\n```none\nTypeError: This object is an expression that will be evaluated later, when your pipeline runs. So it is not possible to eagerly iterate over it now.\n```\nWe get an error because the ``for`` statement tries to iterate immediately\nover the columns. However, ``orders.columns`` is not an actual list of\ncolumns: it is a skrub expression that will produce a list of columns, later,\nwhen we run the computation.\n\n<img src=\"file://../../_static/skrub_3d_2.svg\" width=\"200\">\n\nThis remains true even if we have provided a value for ``orders`` and we can\nsee a result for that value:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "orders.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The \"result\" we see is an *example* result that the computation produces for\nthe data we provided. But we want to fit our estimator and apply it many\ntimes to different datasets, for which it will return a new object every\ntime. So even if we see a preview of the output on the data we provided,\n``orders.columns`` still represents a future computation that remains to be\nevaluated.\n\nSo we must delay the execution of the ``for`` statement until the computation\nactually runs and ``orders.columns`` has been evaluated.\n\nWe can do this by wrapping it in a function and using ``skrub.deferred``.\nSuppose we want to convert the columns to upper case, and our first attempt\nruns into the problem we just described::\n\n    COLUMNS = [c.upper() for c in orders.columns]\n\n```none\nTypeError: This object is an expression that will be evaluated later, when your pipeline runs. So it is not possible to eagerly iterate over it now.\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define a function that contains the control flow statement we need. Then,\nwe apply the ``skrub.deferred`` decorator to it. What this does is deferring\nthe calls to our function. Now when we call it, instead of running\nimmediately, it returns a skrub expression that wraps the function call. The\noriginal function is actually called when we evaluate the expression.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@skrub.deferred\ndef with_upper_columns(df):\n    new_columns = [c.upper() for c in df.columns]\n    return df.set_axis(new_columns, axis=\"columns\")\n\n\nwith_upper_columns(orders)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you unfold the dropdown ``\u25b6 Show graph`` above, you can\nsee that a call to our function has been added to the computation graph.\n\n<img src=\"file://../../_static/skrub_3d_3.svg\" width=\"200\">\n\nWhen the computation runs, ``orders`` will be evaluated first and the result (an\nactual dataframe) will be passed as the ``df`` argument to our function.\n\n<img src=\"file://../../_static/skrub_3d_4.svg\" width=\"400\">\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``skrub.deferred`` is useful for our own functions but also when we need to\ncall module-level functions from a library. For example to delay loading of a\ncsv file we could use something like:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "csv_path = skrub.var(\"csv_path\")\ndata = skrub.deferred(pd.read_csv)(csv_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Also note that for the same reason (we are building a computation graph, not\nimmediately computing a single result), any transformation that we have must\nnot modify its input, but leave it unchanged and return a new value.\n\nThink of the transformers in a scikit-learn pipeline: each computes a new\nresult without modifying its input.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This would raise an error::\n\n    orders['total'] = orders['price'] * orders['qty']\n\n```none\nTypeError: Do not modify an expression in-place. Instead, use a function that returns a new value.This is necessary to allow chaining several steps in a sequence of transformations.\nFor example if df is a pandas DataFrame:\ndf = df.assign(new_col=...) instead of df['new_col'] = ...\n```\nIn this case the error message suggests a solution: use ``assign()`` instead\nof item assignment. Luckily, we are mostly focussed on pandas and polars\ndataframes and they provide an API supporting this functional (returning\ntransformed values without modifying the inputs) style for most operations\n(even more so polars than pandas).\n\nWhen we do need assignments or in-place transformations, we can put them in a\n``deferred`` function. But remember to make a (shallow) copy and return the new value.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@skrub.deferred\ndef add_total(df):\n    new_df = df.copy(deep=False)  # Creates a new dataframe but does not copy any data\n    new_df[\"total\"] = new_df[\"price\"] * new_df[\"qty\"]\n    return new_df\n\n\nadd_total(orders)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, there are other occasions where we may need to use ``deferred``:\n\n- we have many nodes in our graph, and we want to collapse a sequence of\n  steps into a single function call, that will appear as a single node\n- we have steps that need to be deferred until the full computation runs,\n  because they depend on the runtime environment or on objects that cannot be\n  pickled together with the rest of the computation graph -- for example\n  opening and reading a file.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}