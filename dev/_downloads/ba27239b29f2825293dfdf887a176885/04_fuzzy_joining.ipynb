{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Fuzzy joining dirty tables with the Joiner\n\nHere we show how to combine data from different sources,\nwith a vocabulary not well normalized.\n\nJoining is difficult: one entry on one side does not have\nan exact match on the other side.\n\nThe |fj| function enables to join tables without cleaning the data by\naccounting for the label variations.\n\nTo illustrate, we will join data from the\n[2022 World Happiness Report](https://worldhappiness.report/), with tables\nprovided in [the World Bank open data platform](https://data.worldbank.org/)\nin order to create a first prediction model.\n\nMoreover, the |joiner| is a scikit-learn Transformer that makes it easy to\nuse such fuzzy joining multiple tables to bring in information in a\nmachine-learning pipeline. In particular, it enables tuning parameters of\n|fj| to find the matches that maximize prediction accuracy.\n\n\n.. |fj| replace:: :func:`~skrub.fuzzy_join`\n\n.. |joiner| replace:: :func:`~skrub.Joiner`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Importing and preprocessing\n\nWe import the happiness score table first:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n\ndf = pd.read_csv(\n    \"https://raw.githubusercontent.com/skrub-data/datasets/master/data/Happiness_report_2022.csv\",  # noqa\n    thousands=\",\",\n)\ndf.drop(df.tail(1).index, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at the table:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is a table that contains the happiness index of a country along with\nsome of the possible explanatory factors: GDP per capita, Social support,\nGenerosity etc.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the sake of this example, we only keep the country names and our\nvariable of interest: the 'Happiness score'.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df = df[[\"Country\", \"Happiness score\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additional tables from other sources\n\nNow, we need to include explanatory factors from other sources, to\ncomplete our covariates (X table).\n\nInteresting tables can be found on [the World Bank open data platform](https://data.worldbank.org/), for which we have a downloading\nfunction:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skrub.datasets import fetch_world_bank_indicator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We extract the table containing GDP per capita by country:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gdppc = fetch_world_bank_indicator(indicator_id=\"NY.GDP.PCAP.CD\").X\ngdppc.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then another table, with life expectancy by country:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "life_exp = fetch_world_bank_indicator(\"SP.DYN.LE00.IN\").X\nlife_exp.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And a table with legal rights strength by country:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "legal_rights = fetch_world_bank_indicator(\"IC.LGL.CRED.XQ\").X\nlegal_rights.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A correspondence problem\n\nAlas, the entries for countries do not perfectly match between our\noriginal table (df), and those that we downloaded from the worldbank\n(gdppc):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df.sort_values(by=\"Country\").tail(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gdppc.sort_values(by=\"Country Name\").tail(7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that Yemen is written \"Yemen*\" on one side, and\n\"Yemen, Rep.\" on the other.\n\nWe also have entries that probably do not have correspondences: \"World\"\non one side, whereas the other table only has country-level data.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Joining tables with imperfect correspondence\n\nWe will now join our initial table, df, with the 3 additional ones that\nwe have extracted.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We will ignore the warnings:\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n### 1. Joining GDP per capita table\n\nTo join them with skrub, we only need to do the following:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skrub import fuzzy_join\n\ndf1 = fuzzy_join(\n    df,  # our table to join\n    gdppc,  # the table to join with\n    left_on=\"Country\",  # the first join key column\n    right_on=\"Country Name\",  # the second join key column\n    return_score=True,\n)\n\ndf1.tail(20)\n# We merged the first WB table to our initial one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. topic:: Note:\n\n   We fix the ``return_score`` parameter to `True` so as to keep the matching\n   score, that we will use later to show what are the worst matches.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that our |fj| succesfully identified the countries,\neven though some country names differ between tables.\n\nFor instance, \"Czechia\" is well identified as \"Czech Republic\" and\n\"Luxembourg*\" as \"Luxembourg\".\n\n.. topic:: Note:\n\n   This would all be missed out if we were using other methods such as\n   [pandas.merge](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge.html),  # noqa\n   which can only find exact matches.\n   In this case, to reach the best result, we would have to `manually` clean\n   the data (e.g. remove the * after country name) and look\n   for matching patterns in every observation.\n\nLet's do some more inspection of the merging done.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's print the four worst matches, which will give\nus an overview of the situation:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df1.sort_values(\"matching_score\").head(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that some matches were unsuccesful\n(e.g \"Palestinian Territories*\" and \"Palau\"),\nbecause there is simply no match in the two tables.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this case, it is better to use the threshold parameter\nso as to include only precise-enough matches:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df1 = fuzzy_join(\n    df,\n    gdppc,\n    left_on=\"Country\",\n    right_on=\"Country Name\",\n    match_score=0.35,\n    return_score=True,\n)\ndf1.sort_values(\"matching_score\").head(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Matches that are not available (or precise enough) are marked as `NaN`.\nWe will remove them using the drop_unmatched parameter:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df1 = fuzzy_join(\n    df,\n    gdppc,\n    left_on=\"Country\",\n    right_on=\"Country Name\",\n    match_score=0.35,\n    drop_unmatched=True,\n)\n\ndf1.drop(columns=[\"Country Name\"], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can finally plot and look at the link between GDP per capital\nand happiness:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_context(\"notebook\")\n\nplt.figure(figsize=(4, 3))\nax = sns.regplot(\n    data=df1,\n    x=\"GDP per capita (current US$)\",\n    y=\"Happiness score\",\n    lowess=True,\n)\nax.set_ylabel(\"Happiness index\")\nax.set_title(\"Is a higher GDP per capita linked to happiness?\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It seems that the happiest countries are those\nhaving a high GDP per capita.\nHowever, unhappy countries do not have only low levels\nof GDP per capita. We have to search for other patterns.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Joining life expectancy table\n\nNow let's include other information that may be relevant, such as in the\nlife_exp table:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df2 = fuzzy_join(\n    df1,\n    life_exp,\n    left_on=\"Country\",\n    right_on=\"Country Name\",\n    match_score=0.45,\n)\n\ndf2.drop(columns=[\"Country Name\"], inplace=True)\n\ndf2.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot this relation:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(4, 3))\nfig = sns.regplot(\n    data=df2,\n    x=\"Life expectancy at birth, total (years)\",\n    y=\"Happiness score\",\n    lowess=True,\n)\nfig.set_ylabel(\"Happiness index\")\nfig.set_title(\"Is a higher life expectancy linked to happiness?\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It seems the answer is yes!\nCountries with higher life expectancy are also happier.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Joining legal rights strength table\n\nAnd the table with a measure of legal rights strength in the country:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df3 = fuzzy_join(\n    df2,\n    legal_rights,\n    left_on=\"Country\",\n    right_on=\"Country Name\",\n    match_score=0.45,\n)\n\ndf3.drop(columns=[\"Country Name\"], inplace=True)\n\ndf3.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's take a look at their correspondence in a figure:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(4, 3))\nfig = sns.regplot(\n    data=df3,\n    x=\"Strength of legal rights index (0=weak to 12=strong)\",\n    y=\"Happiness score\",\n    lowess=True,\n)\nfig.set_ylabel(\"Happiness index\")\nfig.set_title(\"Does a country's legal rights strength lead to happiness?\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From this plot, it is not clear that this measure of legal strength\nis linked to happiness.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Great! Our joined table has become bigger and full of useful information.\nAnd now we are ready to apply a first machine learning model to it!\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prediction model\n\nWe now separate our covariates (X), from the target (or exogenous)\nvariables: y\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X = df3.drop(\"Happiness score\", axis=1).select_dtypes(exclude=object)\ny = df3[[\"Happiness score\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us now define the model that will be used to predict the happiness score:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import HistGradientBoostingRegressor\nfrom sklearn.model_selection import KFold\n\nhgdb = HistGradientBoostingRegressor(random_state=0)\ncv = KFold(n_splits=2, shuffle=True, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To evaluate our model, we will apply a `4-fold cross-validation`.\nWe evaluate our model using the `R2` score.\n\nLet's finally assess the results of our models:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_validate\n\ncv_results_t = cross_validate(hgdb, X, y, cv=cv, scoring=\"r2\")\n\ncv_r2_t = cv_results_t[\"test_score\"]\n\nprint(f\"Mean R2 score is {cv_r2_t.mean():.2f} +- {cv_r2_t.std():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have a satisfying first result: an R2 of 0.66!\n\nData cleaning varies from dataset to dataset: there are as\nmany ways to clean a table as there are errors. |fj|\nmethod is generalizable across all datasets.\n\nData transformation is also often very costly in both time and ressources.\n|fj| is fast and easy-to-use.\n\nNow up to you, try improving our model by adding information into it and\nbeating our result!\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using the |joiner| to fuzzy join multiple tables\nA faster way to merge different tables from the World Bank\nto `X` is to use the |joiner|.\n\nThe |joiner| is a transformer that can easily chain joins of tables on\na main table.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n### Instantiating the transformer\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y = df[\"Happiness score\"]\ndf = df.drop(\"Happiness score\", axis=1)\n\nfrom skrub import Joiner, SelectCols, DropCols\nfrom sklearn.pipeline import make_pipeline\n\n# We create a selector that we will insert at the end of our pipeline, to\n# select the relevant columns before fitting the regressor\n\nselector = SelectCols(\n    [\n        \"GDP per capita (current US$)\",\n        \"Life expectancy at birth, total (years)\",\n        \"Strength of legal rights index (0=weak to 12=strong)\",\n    ]\n)\npipeline = make_pipeline(\n    Joiner((gdppc, \"Country Name\"), \"Country\"),\n    DropCols(\"Country Name\"),\n    Joiner((life_exp, \"Country Name\"), \"Country\"),\n    DropCols(\"Country Name\"),\n    Joiner((legal_rights, \"Country Name\"), \"Country\"),\n    selector,\n    HistGradientBoostingRegressor(),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the best part is that we are now able to evaluate the parameters of the |fj|.\nFor instance, the ``match_score`` was manually picked and can now be\nintroduced into a grid search:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n\n# We will test four possible values of match_score:\nparams = {\n    \"joiner-1__match_score\": [0.2, 0.9],\n    \"joiner-2__match_score\": [0.2, 0.9],\n    \"joiner-3__match_score\": [0.2, 0.9],\n}\n\ngrid = GridSearchCV(pipeline, param_grid=params)\ngrid.fit(df, y)\n\nprint(grid.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The grid searching gave us the best value of 0.5 for the parameter\n``match_score``. Let's use this value in our regression:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"Mean R2 score with pipeline is {grid.score(df, y):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. topic:: Note:\n\n   Here, ``grid.score()`` takes directly the best model\n   (with ``match_score=0.5``) that was found during the grid search.\n   Thus, it is equivalent to fixing the ``match_score`` to 0.5 and\n   refitting the pipeline on the data.\n\n\nGreat, by evaluating the correct ``match_score`` we improved our\nresults significantly!\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}