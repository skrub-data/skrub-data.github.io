{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Fitting scalable, non-linear models on data with dirty categories\n\nWhen training a machine learning model, it is often hard to choose between\nlinear and a non-linear models.\n\nOn one hand, linear models are well studied and understood. They are generally\nfast and easy to optimize, and generate interpretable results.\nThey do however reach their expressiveness limits when there is a complex\nrelation between the input and the output: whatever the number of samples the\ntraining set may have, past some point, their precision won't get any better.\n\nOn the other hand, non-linear models tend to scale better with sample size:\nthey are able to digest the massive amount of information and get a better\nestimate of the link between the input and the output.\n\nNon-linear models form a very large class. Among others, it includes:\n\n* Neural Networks\n* Tree-based methods such as Random Forests, and the very powerful Gradient\n  Boosting Machines [#xgboost]_\n* Kernel Methods\n\nHowever, reaching the phase where non-linear models outperform the linear ones\ncan be complicated. Indeed, a more complex model often means a longer\nfitting/tuning process\n\n* Neural networks often need extended model tuning time in order to\n  achieve good optimization and architecture.\n* Gradient Boosting Machines tend to not scale very well with increasing\n  sample size, as all the data needs to be loaded in the main memory.\n* For kernel methods, parameter fitting requires the inversion of a gram matrix\n  of size $n \\times n$ ($n$ being the number of samples), yielding\n  a quadratic dependency (with $n$) as the final computation time.\n\n\nIn order to get the best out of a non-linear model, one has to **make it\nscalable**. Quite notably, for kernel methods, approximation algorithms that\ndrop the quadratic dependency with the sample size while ensuring capacity\napproximation exist.\n\nIn this example, you will learn how to:\n    1. Build a machine learning pipeline that uses a kernel method.\n    2. Make this pipeline scalable, by using online algorithms and dimension\n       reduction methods.\n\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>This example assumes the reader is familiar with similarity encoding and\n   its use-cases.\n\n   * For an introduction to dirty categories, see `this example<https://dirty-cat.github.io/stable/auto_examples/02_investigating_dirty_categories.html#sphx-glr-auto-examples-02-investigating-dirty-categories-py>`.\n   * To learn with dirty categories using the SimilarityEncoder, see `this example<https://dirty-cat.github.io/stable/auto_examples/01_dirty_categories.html#sphx-glr-auto-examples-01-dirty-categories-py>`.</p></div>\n\n\n.. |NYS| replace:: :class:`Nystroem <sklearn.kernel_approximation.Nystroem>`\n\n.. |NYS_EXAMPLE|\n    replace:: `scikit-learn documentation <nystroem_kernel_approx>`\n\n.. |RBF| replace:: :class:`~sklearn.kernel_approximation.RBFSampler`\n\n.. |SVC| replace:: :class:`SupportVectorClassifier <sklearn.svm.SVC>`\n\n.. |SE| replace:: :class:`~dirty_cat.SimilarityEncoder`\n\n.. |SGDClassifier| replace:: :class:`~sklearn.linear_model.SGDClassifier`\n\n.. |APS| replace:: :func:`~sklearn.metrics.average_precision_score`\n\n.. |OHE| replace:: :class:`~sklearn.preprocessing.OneHotEncoder`\n\n.. |ColumnTransformer| replace:: :class:`~sklearn.compose.ColumnTransformer`\n\n.. |LabelEncoder| replace:: :class:`~sklearn.preprocessing.LabelEncoder`\n\n.. |SGDClassifier_partialfit| replace::\n    :meth:`~sklearn.linear_model.SGDClassifier.partial_fit`\n\n.. |Pipeline| replace:: :class:`~sklearn.pipeline.Pipeline`\n\n.. |pd_read_csv| replace:: :func:`pandas.read_csv`\n\n.. |sklearn| replace:: :std:doc:`scikit-learn <sklearn:index>`\n\n.. |transform| replace:: :std:term:`transform <sklearn:transform>`\n\n.. |fit| replace:: :std:term:`fit <sklearn:fit>`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training a simple pipeline\nWe will train our model on the :code:`drug_directory` dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from dirty_cat.datasets import fetch_drug_directory\n\n# We'll only gather the information, and not load the dataset in memory for now\ndrug_directory = fetch_drug_directory(load_dataframe=False)\nprint(drug_directory.description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. topic:: Problem Setting:\n\n   .. centered::\n      **predict the drug type given its composition**\n\n\nThe :code:`NONPROPRIETARYNAME` column, is composed of textual observations\ndescribing each drug's composition. The :code:`PRODUCTTYPENAME` column\nconsists of categorical values; we therefore a classification problem.\n\nYou can have a glimpse of the values here:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n\ndf = pd.read_csv(\n    drug_directory.path,\n    nrows=10,\n    **drug_directory.read_csv_kwargs,\n).astype(str)\nprint(df[['NONPROPRIETARYNAME', 'PRODUCTTYPENAME']].head())\n# This will be useful further down in the example.\ncolumns_names = df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Estimators construction\nOur input is categorical, thus needs to be encoded.\n\nAs observations often consist in variations around a few concepts\n- for instance, \"Amlodipine Besylate\" and\n\"Amlodipine besylate and atorvastatin calcium\"\nhave one ingredient in common - we need an encoding able to\ncapture similarities between observations. We choose to use a |SE|.\n\nTwo other columns are used to predict the output: ``DOSAGEFORMNAME`` and\n``ROUTENAME``.\nThey are both categorical and can be encoded with a |OHE|.\nWe use a |ColumnTransformer| to stack both.\nWe can now choose a kernel method. Here, we'll use a |SVC| to fit\nthe encoded inputs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from dirty_cat import SimilarityEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import make_column_transformer\n\ncolumn_transformer = make_column_transformer(\n    (SimilarityEncoder(), ['NONPROPRIETARYNAME']),\n    (OneHotEncoder(handle_unknown='ignore'), ['DOSAGEFORMNAME', 'ROUTENAME']),\n    sparse_threshold=1,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will bundle the ColumnTransformer and the classifier into a |Pipeline|\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\nfrom sklearn.pipeline import Pipeline\nclassifier = SVC(kernel='rbf', random_state=42, gamma=1)\nsteps = [('transformer', column_transformer), ('classifier', classifier)]\nmodel = Pipeline(steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading and Preprocessing\n\nAs usual in most machine learning setups, the data has to be split into 2\nexclusive parts:\n\nAs usual in machine learning settings, we will split our data in two\nexclusive sets:\n\n* One for model training\n* One for model testing\n\nWe create a simple wrapper around |pd_read_csv|, that extracts :code:`X`,\nand :code:`y` from the dataset.\n\n.. topic:: Note about class imbalance:\n\n   The :code:`y` labels are composed of 7 unique classes. However, the two\n   classes ``HUMAN OTC DRUG`` and ``HUMAN PRESCRIPTION DRUG`` represent\n   around 97% of the data. The other 5 classes are much rarer.\n   Dealing with class imbalance is out of the scope of this example, so the\n   models will be trained only on the two most common classes.\n\nClassifiers in |sklearn| often require :code:`y` to be integer labels.\nAdditionally, |APS| requires a binary version of the labels.\n\nWe therefore create for these respective constraints a |LabelEncoder| and\na |OHE|\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom typing import Tuple\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\n\nlabel_encoder = LabelEncoder()\n# Pre-fit on the known classes of y\nlabel_encoder.fit(['HUMAN OTC DRUG', 'HUMAN PRESCRIPTION DRUG'])\n\none_hot_encoder = OneHotEncoder(categories=\"auto\", sparse=False)\n# Pre-fit on the integer labels\none_hot_encoder.fit([[0], [1]])\n\n\ndef preprocess(df: pd.DataFrame) -> Tuple[pd.DataFrame, np.array]:\n    df = df.loc[df['PRODUCTTYPENAME'].isin(\n        ['HUMAN OTC DRUG', 'HUMAN PRESCRIPTION DRUG'])]\n\n    df = df[['NONPROPRIETARYNAME', 'DOSAGEFORMNAME',\n             'ROUTENAME', 'PRODUCTTYPENAME']]\n    df = df.dropna()\n\n    X = df[['NONPROPRIETARYNAME', 'DOSAGEFORMNAME', 'ROUTENAME']]\n    y = df[['PRODUCTTYPENAME']].values\n\n    y_int = label_encoder.transform(np.squeeze(y))\n\n    return X, y_int\n\n\ndef get_X_y(**kwargs) -> Tuple[pd.DataFrame, np.array]:\n    \"\"\"Simple wrapper around pd.read_csv that extracts features and labels.\n\n    Some systematic preprocessing is also carried out to avoid doing this\n    transformation repeatedly in the code.\n    \"\"\"\n    df = pd.read_csv(drug_directory.path, names=columns_names,\n                     **drug_directory.read_csv_kwargs, **kwargs)\n    return preprocess(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-danger\"><h4>Warning</h4><p>In the following steps, we assume the dataset to be shuffled prior to its\n   loading. Be careful as this is not the case for all datasets!\n   This is important here because we will take the $n$ first\n   observations for the training set and the next $m$ observations for\n   the test set repeatably.</p></div>\n\n\nFinally, :code:`X` and :code:`y` are loaded.\n\n\n.. topic:: Note: offsetting the test set\n\n   For the online-learning procedures of this example, we would like to\n   compare the accuracy at each iteration. In order to do that, we need to\n   keep the same test set. As such, we \"reserve\" the first 100k rows for\n   the training phase, and use the rest as the test set.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_set_size = 5000\ntest_set_size = 10000\noffset = 100000\n\nX_train, y_train = get_X_y(skiprows=1, nrows=train_set_size)\n\nX_test, y_test = get_X_y(skiprows=offset, nrows=test_set_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluating time and sample complexity\n\nLet's get an idea of model precision and performance depending on the number\nof the samples used in the train set.\nThe |Pipeline| is trained over different training set sizes. For this,\n:code:`X_train` and :code:`y_train` get sliced into subsets of increasing\nsize, while :code:`X_test` and :code:`y_test` do not change.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\nfrom sklearn.metrics import average_precision_score\n\n# Define the different train set sizes\ntrain_set_sizes = [train_set_size // 10, train_set_size // 3, train_set_size]\n\ntrain_times_svc, test_scores_svc = [], []\n\nfor n in train_set_sizes:\n\n    t0 = time.perf_counter()\n    model.fit(X_train[:n], y_train[:n])\n    train_time = time.perf_counter() - t0\n\n    y_pred = model.predict(X_test)\n\n    y_pred_onehot = one_hot_encoder.transform(y_pred.reshape(-1, 1))\n    y_test_onehot = one_hot_encoder.transform(y_test.reshape(-1, 1))\n\n    test_score = average_precision_score(y_test_onehot, y_pred_onehot)\n\n    train_times_svc.append(train_time)\n    test_scores_svc.append(test_score)\n\n    print(\n        f\"Using {n:>5} samples: model fitting took {train_time:.1f}s, \"\n        f\"test accuracy of {test_score:.3f}. \"\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Increasing the training set size clearly improves model accuracy.\nHowever, the training time and the input size increase quadratically with it.\n\nIndeed, kernel methods need to process an entire $n \\times n$\nmatrix at once. In order for this matrix to be loaded into memory, $n$\nhas to remain low: If we used 32-bit floats, and with 30k observations, the\ntotal size of this 30k x 30k matrix would be around\n$30000^2 \\times 32 = 2.8 \\times 10^{10} \\text{bits} = 4\\text{GB}$\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reducing input dimension using kernel approximation methods\n\nThe main scalability issues with kernels methods is the processing of a large\nsquare matrix. To understand where this matrix comes from, we need to delve a\nbit deeper into these methods.\n\n.. topic:: Kernel methods\n\n   Kernel methods address non-linear problems by leveraging similarities\n   between each pair of inputs. Using a similarity matrix to solve a machine\n   learning problem allows to catch complex, non-linear relationships within\n   the data.  But it requires inverting this matrix, which can be a\n   computational burden when the sample size increases.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Kernel approximation methods\n\nFrom what we saw above, two criterion are limiting kernel algorithms from\nscaling:\n\n* It processes a matrix, whose size increases quadratically with the number\n  of samples.\n* During training, this matrix is **inverted**, meaning it has to be\n  loaded into main memory.\n\nKernel approximation methods such as |RBF| or |NYS| [#nys_ref]_ try to\napproximate this similarity matrix, without actually creating it. By allowing\nthe program to not compute the perfect similarity matrix, **the problem\ncomplexity becomes linear**! Furthermore, the samples don't need to be\nprocessed at once.\n\nWe are not bound to use a |SVC| anymore, and can instead use a |RBF| in an\nonline optimization setting to process the input by batch.\n\n.. topic:: Online algorithms\n\n   An online algorithm [#online_ref]_ is an algorithm that treats its input\n   piece by piece in a serial fashion.\n   A famous example is the stochastic gradient descent [#sgd_ref]_,\n   where an estimation of the objective function's gradient is computed\n   on a batch of the data at each step.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reducing the transformers dimensionality\n\nThere is one last scalability issue in our pipeline: the |SE| and the |RBF|\nboth implement the |fit| method. How to adapt those methods to an online\nsetting, where the data is never loaded as a whole?\n\nA simple solution is to partially fit the |SE| and the |RBF| on a subset of\nthe data, prior to the online fitting step.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.kernel_approximation import RBFSampler\nn_out_encoder = 1000\nn_out_rbf = 5000\nn_samples_encoder = 10000\n\nX_encoder, _ = get_X_y(nrows=n_samples_encoder)\n\n# Fit the rbf_sampler with the similarity matrix.\ncolumn_transformer = make_column_transformer(\n    (\n        SimilarityEncoder(categories='most_frequent',\n                          n_prototypes=n_out_encoder,\n                          random_state=42, ngram_range=(2, 4)),\n        ['NONPROPRIETARYNAME']\n    ), (\n        OneHotEncoder(handle_unknown='ignore'),\n        ['DOSAGEFORMNAME', 'ROUTENAME']\n    ),\n    sparse_threshold=1)\n\ntransformed_categories = column_transformer.fit_transform(X_encoder)\n\n# gamma is a parameter of the rbf function, that sets how fast the similarity\n# between two points should decrease as the distance between them rises. It\n# is data-specific, and needs to be chosen carefully, for example using\n# cross-validation.\nrbf_sampler = RBFSampler(\n    gamma=0.5, n_components=n_out_rbf, random_state=42)\nrbf_sampler.fit(transformed_categories)\n\n\ndef encode(X, y_int, one_hot_encoder, column_transformer, rbf_sampler):\n    X_sim_encoded = column_transformer.transform(X)\n\n    X_highdim = rbf_sampler.transform(X_sim_encoded.toarray())\n\n    y_onehot = one_hot_encoder.transform(y_int.reshape(-1, 1))\n\n    return X_highdim, y_onehot\n\n\n# The inputs and labels of the val and test sets have to be pre-processed the\n# same way the training set was processed:\nX_test_kernel_approx, y_true_test_onehot = encode(\n    X_test, y_test, one_hot_encoder, column_transformer, rbf_sampler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Online training for out-of-memory data\nWe now have all the elements to create a non-linear, online kernel method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import warnings\nfrom sklearn.linear_model import SGDClassifier\n\nonline_train_set_size = 100000\n# Filter warnings on max_iter and tol\nwarnings.filterwarnings('ignore', module='sklearn.linear_model')\nsgd_classifier = SGDClassifier(\n    max_iter=1, tol=None, random_state=42, average=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now start the training by looping over batches one by one.\nNote that only one pass over the whole dataset is done.\nIt may be worth doing several passes, but for very large sample sizes,\nthe increase in test accuracy is likely to be marginal.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "batchsize = 1000\ntest_scores_rbf = []\ntrain_times_rbf = []\nonline_train_set_sizes = []\nt0 = time.perf_counter()\n\niter_csv = pd.read_csv(\n    drug_directory.path, nrows=online_train_set_size, chunksize=batchsize,\n    skiprows=1, names=columns_names, **drug_directory.read_csv_kwargs)\n\nfor batch_no, batch in enumerate(iter_csv):\n    X_batch, y_batch = preprocess(batch)\n    # Skip iteration if batch is empty after preprocessing\n    if len(y_batch) == 0:\n        continue\n    X_batch_kernel_approx, y_batch_onehot = encode(\n        X_batch, y_batch, one_hot_encoder, column_transformer, rbf_sampler)\n\n    # Make one pass of stochastic gradient descent over the batch.\n    sgd_classifier.partial_fit(\n        X_batch_kernel_approx, y_batch, classes=[0, 1])\n\n    # Print train/test accuracy metrics every 5 batch\n    if (batch_no % 5) == 0:\n        message = f\"batch {batch_no:>4} \"\n        for origin, X, y_true_onehot in zip(\n                ('train', 'val'),\n                (X_batch_kernel_approx, X_test_kernel_approx),\n                (y_batch_onehot, y_true_test_onehot)):\n\n            y_pred = sgd_classifier.predict(X)\n\n            # Preprocess correctly the labels and prediction to match\n            # average_precision_score expectations\n            y_pred_onehot = one_hot_encoder.transform(\n                y_pred.reshape(-1, 1))\n\n            score = average_precision_score(y_true_onehot, y_pred_onehot)\n            message += f\"{origin} precision: {score:.4f}  \"\n            if origin == 'val':\n                test_scores_rbf.append(score)\n                train_times_rbf.append(time.perf_counter() - t0)\n                online_train_set_sizes.append((batch_no + 1) * batchsize)\n\n        print(message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So far, we fitted two kinds of models: an exact kernel algorithm, and an\napproximate, online one.\n\nLet's compare both the accuracies and the number of visited samples\nfor each model as we increase our time budget:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nf, axs = plt.subplots(2, 1, sharex=True, figsize=(10, 7))\nax_score, ax_capacity = axs\n\nax_score.set_ylabel('score')\nax_capacity.set_ylabel('training set size')\nax_capacity.set_xlabel('time')\n\nax_score.plot(train_times_svc, test_scores_svc, 'b-', label='exact')\nax_score.plot(train_times_rbf, test_scores_rbf, 'r-', label='online')\n\nax_capacity.plot(train_times_svc, train_set_sizes, 'b-', label='exact')\nax_capacity.plot(train_times_rbf, online_train_set_sizes, 'r-', label='online')\nax_capacity.set_yscale('log')\n\nax_score.legend(bbox_to_anchor=(0., 1.02, 1., .102),\n                loc=3, ncol=2, mode='expand',\n                borderaxespad=0.)\n\n# Compare the two methods in the common time range\nax_score.set_xlim(0, min(train_times_svc[-1], train_times_rbf[-1]))\n\nf.suptitle(\"Test set accuracy and number of samples visited\"\n           \"samples seen by the SGDClassifier\")\n\nf.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This plot shows us that for the time budget, the online model will eventually\nprocess more samples, be faster and reach a far higher test accuracy that the\nnon-online, exact kernel method.\n\nOur online model also outperforms online **linear** models (for instance,\n|SE| + |SGDClassifier|).\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>We did not fit two online models here for the sake of simplicity, but to\n   train an online linear model, simply comment out the line\n   :code:`X_highdim = rbf_sampler.transform(X_sim_encoded.toarray())`\n   in the function :code:`encode` and change it with, for example,\n   :code:`X_highdim = X_sim_encoded`.</p></div>\n\nIn particular, this hierarchy between the linear and the non-linear models\nshows that there were some significant non-linear relationships\nbetween the input and the output. By scaling a kernel method, we successfully\ntook this non-linearity into account in our model, which was far from a\ntrivial task at the beginning of this example!\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. rubric:: Footnotes\n.. [#xgboost] [Slides on gradient boosting by Tianqi Chen, the founder of XGBoost](https://web.njit.edu/~usman/courses/cs675_summer20/BoostedTree.pdf)\n.. [#online_ref] [Wikipedia article on online algorithms](https://en.wikipedia.org/wiki/Online_algorithm)\n.. [#sgd_ref] [Leon Bouttou's article on stochastic gradient descent](http://khalilghorbal.info/assets/spa/papers/ML_GradDescent.pdf)\n.. [#nys_ref] |NYS_EXAMPLE|\n.. [#dual_ref] [Introduction to duality](https://pdfs.semanticscholar.org/0373/e7289a1978108d6455218160a529c85842c0.pdf)\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}