
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/08_join_aggregation.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_08_join_aggregation.py>`
        to download the full example code or to run this example in your browser via JupyterLite or Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_08_join_aggregation.py:


Self-aggregation on MovieLens
=============================

MovieLens is a famous movie dataset used for both explicit
and implicit recommender systems. It provides a main table,
"ratings", that can be viewed as logs or transactions, comprised
of only 4 columns: ``userId``, ``movieId``, ``rating`` and ``timestamp``.
MovieLens also gives a contextual table "movies", including
``movieId``, ``title`` and ``types``, to enable content-based feature extraction.

From the perspective of machine-learning pipelines, one challenge is to
transform the transaction log into features that can be fed to supervised learning.

In this notebook, we only deal with the main table "ratings".
Our objective is **not to achieve state-of-the-art performance** on
the explicit regression task, but rather to illustrate how to perform
feature engineering in a simple way using |AggJoiner| and |AggTarget|.
Note that our performance is higher than the baseline of using the mean
rating per movies.

The benefit of using  |AggJoiner| and |AggTarget| is that they readily
provide a full pipeline, from the original tables to the prediction, that can
be cross-validated or applied to new data to serve prediction. At the end of
this example, we showcase hyper-parameter optimization on the whole pipeline.


.. |AggJoiner| replace::
     :class:`~skrub.AggJoiner`

.. |AggTarget| replace::
     :class:`~skrub.AggTarget`

.. |TableVectorizer| replace::
     :class:`~skrub.TableVectorizer`

.. |DatetimeEncoder| replace::
     :class:`~skrub.DatetimeEncoder`

.. |TargetEncoder| replace::
     :class:`~sklearn.preprocessing.TargetEncoder`

.. |make_pipeline| replace::
     :class:`~sklearn.pipeline.make_pipeline`

.. |Pipeline| replace::
     :class:`~sklearn.pipeline.Pipeline`

.. |GridSearchCV| replace::
     :class:`~sklearn.model_selection.GridSearchCV`

.. |TimeSeriesSplit| replace::
     :class:`~sklearn.model_selection.TimeSeriesSplit`

.. |HGBR| replace::
     :class:`~sklearn.ensemble.HistGradientBoostingRegressor`

.. GENERATED FROM PYTHON SOURCE LINES 60-65

The data
--------

We begin with loading the ratings table from MovieLens.
Note that we use the light version (100k rows).

.. GENERATED FROM PYTHON SOURCE LINES 65-77

.. code-block:: Python

    import pandas as pd

    from skrub.datasets import fetch_movielens


    ratings = fetch_movielens(dataset_id="ratings")
    ratings = ratings.X.sort_values("timestamp").reset_index(drop=True)
    ratings["timestamp"] = pd.to_datetime(ratings["timestamp"], unit="s")

    X = ratings[["userId", "movieId", "timestamp"]]
    y = ratings["rating"]
    X.shape, y.shape




.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    ((100836, 3), (100836,))



.. GENERATED FROM PYTHON SOURCE LINES 78-80

.. code-block:: Python

    X.head()






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>userId</th>
          <th>movieId</th>
          <th>timestamp</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>429</td>
          <td>22</td>
          <td>1996-03-29 18:36:55</td>
        </tr>
        <tr>
          <th>1</th>
          <td>429</td>
          <td>150</td>
          <td>1996-03-29 18:36:55</td>
        </tr>
        <tr>
          <th>2</th>
          <td>429</td>
          <td>161</td>
          <td>1996-03-29 18:36:55</td>
        </tr>
        <tr>
          <th>3</th>
          <td>429</td>
          <td>165</td>
          <td>1996-03-29 18:36:55</td>
        </tr>
        <tr>
          <th>4</th>
          <td>429</td>
          <td>218</td>
          <td>1996-03-29 18:36:55</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 81-87

Encoding the timestamp with a TableVectorizer
---------------------------------------------

Our first step is to extract features from the timestamp, using the
|TableVectorizer|. Natively, it uses the |DatetimeEncoder| on datetime
columns, and doesn't interact with numerical columns.

.. GENERATED FROM PYTHON SOURCE LINES 87-97

.. code-block:: Python

    from skrub import TableVectorizer, DatetimeEncoder


    table_vectorizer = TableVectorizer(
        datetime_transformer=DatetimeEncoder(add_day_of_the_week=True)
    )
    table_vectorizer.set_output(transform="pandas")
    X_date_encoded = table_vectorizer.fit_transform(X)
    X_date_encoded.head()






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>userId</th>
          <th>movieId</th>
          <th>timestamp_year</th>
          <th>timestamp_month</th>
          <th>timestamp_day</th>
          <th>timestamp_hour</th>
          <th>timestamp_total_seconds</th>
          <th>timestamp_day_of_week</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>429.0</td>
          <td>22.0</td>
          <td>1996.0</td>
          <td>3.0</td>
          <td>29.0</td>
          <td>18.0</td>
          <td>828124615.0</td>
          <td>4.0</td>
        </tr>
        <tr>
          <th>1</th>
          <td>429.0</td>
          <td>150.0</td>
          <td>1996.0</td>
          <td>3.0</td>
          <td>29.0</td>
          <td>18.0</td>
          <td>828124615.0</td>
          <td>4.0</td>
        </tr>
        <tr>
          <th>2</th>
          <td>429.0</td>
          <td>161.0</td>
          <td>1996.0</td>
          <td>3.0</td>
          <td>29.0</td>
          <td>18.0</td>
          <td>828124615.0</td>
          <td>4.0</td>
        </tr>
        <tr>
          <th>3</th>
          <td>429.0</td>
          <td>165.0</td>
          <td>1996.0</td>
          <td>3.0</td>
          <td>29.0</td>
          <td>18.0</td>
          <td>828124615.0</td>
          <td>4.0</td>
        </tr>
        <tr>
          <th>4</th>
          <td>429.0</td>
          <td>218.0</td>
          <td>1996.0</td>
          <td>3.0</td>
          <td>29.0</td>
          <td>18.0</td>
          <td>828124615.0</td>
          <td>4.0</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 98-99

We can now make a couple of plots and gain some insight on our dataset.

.. GENERATED FROM PYTHON SOURCE LINES 99-126

.. code-block:: Python

    from matplotlib import pyplot as plt
    import seaborn as sns

    sns.set_style("darkgrid")


    def make_barplot(x, y, title):
        norm = plt.Normalize(y.min(), y.max())
        cmap = plt.get_cmap("magma")

        sns.barplot(x=x, y=y, palette=cmap(norm(y)))
        plt.title(title)
        plt.xticks(rotation=30)
        plt.ylabel(None)
        plt.tight_layout()


    # O is Monday, 6 is Sunday

    daily_volume = X_date_encoded["timestamp_day_of_week"].value_counts().sort_index()

    make_barplot(
        x=daily_volume.index,
        y=daily_volume.values,
        title="Daily volume of ratings",
    )




.. image-sg:: /auto_examples/images/sphx_glr_08_join_aggregation_001.png
   :alt: Daily volume of ratings
   :srcset: /auto_examples/images/sphx_glr_08_join_aggregation_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /home/circleci/project/examples/08_join_aggregation.py:109: FutureWarning: 

    Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

      sns.barplot(x=x, y=y, palette=cmap(norm(y)))
    /home/circleci/project/examples/08_join_aggregation.py:109: UserWarning: Numpy array is not a supported type for `palette`. Please convert your palette to a list. This will become an error in v0.14
      sns.barplot(x=x, y=y, palette=cmap(norm(y)))




.. GENERATED FROM PYTHON SOURCE LINES 127-128

We also display the distribution of our target ``y``.

.. GENERATED FROM PYTHON SOURCE LINES 128-137

.. code-block:: Python

    rating_count = y.value_counts().sort_index()

    make_barplot(
        x=rating_count.index,
        y=rating_count.values,
        title="Distribution of ratings given to movies",
    )





.. image-sg:: /auto_examples/images/sphx_glr_08_join_aggregation_002.png
   :alt: Distribution of ratings given to movies
   :srcset: /auto_examples/images/sphx_glr_08_join_aggregation_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /home/circleci/project/examples/08_join_aggregation.py:109: FutureWarning: 

    Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

      sns.barplot(x=x, y=y, palette=cmap(norm(y)))
    /home/circleci/project/examples/08_join_aggregation.py:109: UserWarning: Numpy array is not a supported type for `palette`. Please convert your palette to a list. This will become an error in v0.14
      sns.barplot(x=x, y=y, palette=cmap(norm(y)))




.. GENERATED FROM PYTHON SOURCE LINES 138-161

AggTarget: aggregate y, then join
---------------------------------

We have just extracted datetime features from timestamps.

Let's now perform an expansion for the target ``y``, by aggregating it before
joining it back on the main table. The biggest risk of doing target expansion
with multiple dataframe operations yourself is to end up leaking the target.

To solve this, the |AggTarget| transformer allows you to
aggregate the target ``y`` before joining it on the main table, without
risk of leaking. Note that to perform aggregation then joining on the features
``X``, you need to use |AggJoiner| instead.

You can also think of it as a generalization of the |TargetEncoder|, which
encodes categorical features based on the target.

We only focus on aggregating the target by **users**, but later we will
also consider aggregating by **movies**. Here, we compute the histogram of the
target with 3 bins, before joining it back on the initial table.

This feature answer questions like
*"How many times has this user given a bad, medium or good rate to movies?"*.

.. GENERATED FROM PYTHON SOURCE LINES 161-172

.. code-block:: Python

    from skrub import AggTarget


    agg_target_user = AggTarget(
        main_key="userId",
        suffix="_user",
        operation="hist(3)",
    )
    X_transformed = agg_target_user.fit_transform(X, y)

    X_transformed.shape




.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    (100836, 6)



.. GENERATED FROM PYTHON SOURCE LINES 173-175

.. code-block:: Python

    X_transformed.head()






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>userId</th>
          <th>movieId</th>
          <th>timestamp</th>
          <th>rating_(0.499, 2.0]_user</th>
          <th>rating_(2.0, 3.5]_user</th>
          <th>rating_(3.5, 5.0]_user</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>429</td>
          <td>22</td>
          <td>1996-03-29 18:36:55</td>
          <td>2</td>
          <td>14</td>
          <td>42</td>
        </tr>
        <tr>
          <th>1</th>
          <td>429</td>
          <td>150</td>
          <td>1996-03-29 18:36:55</td>
          <td>2</td>
          <td>14</td>
          <td>42</td>
        </tr>
        <tr>
          <th>2</th>
          <td>429</td>
          <td>161</td>
          <td>1996-03-29 18:36:55</td>
          <td>2</td>
          <td>14</td>
          <td>42</td>
        </tr>
        <tr>
          <th>3</th>
          <td>429</td>
          <td>165</td>
          <td>1996-03-29 18:36:55</td>
          <td>2</td>
          <td>14</td>
          <td>42</td>
        </tr>
        <tr>
          <th>4</th>
          <td>429</td>
          <td>218</td>
          <td>1996-03-29 18:36:55</td>
          <td>2</td>
          <td>14</td>
          <td>42</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 176-180

Similarly, we join on ``movieId`` instead of ``userId``.

This feature answer questions like
*"How many times has this movie received a bad, medium or good rate from users?"*.

.. GENERATED FROM PYTHON SOURCE LINES 180-187

.. code-block:: Python

    agg_target_movie = AggTarget(
        main_key="movieId",
        suffix="_movie",
        operation="hist(3)",
    )
    X_transformed = agg_target_movie.fit_transform(X, y)
    X_transformed.shape




.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    (100836, 6)



.. GENERATED FROM PYTHON SOURCE LINES 188-190

.. code-block:: Python

    X_transformed.head()






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>userId</th>
          <th>movieId</th>
          <th>timestamp</th>
          <th>rating_(0.499, 2.0]_movie</th>
          <th>rating_(2.0, 3.5]_movie</th>
          <th>rating_(3.5, 5.0]_movie</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>429</td>
          <td>22</td>
          <td>1996-03-29 18:36:55</td>
          <td>4</td>
          <td>24</td>
          <td>8</td>
        </tr>
        <tr>
          <th>1</th>
          <td>429</td>
          <td>150</td>
          <td>1996-03-29 18:36:55</td>
          <td>13</td>
          <td>61</td>
          <td>127</td>
        </tr>
        <tr>
          <th>2</th>
          <td>429</td>
          <td>161</td>
          <td>1996-03-29 18:36:55</td>
          <td>8</td>
          <td>38</td>
          <td>57</td>
        </tr>
        <tr>
          <th>3</th>
          <td>429</td>
          <td>165</td>
          <td>1996-03-29 18:36:55</td>
          <td>14</td>
          <td>64</td>
          <td>66</td>
        </tr>
        <tr>
          <th>4</th>
          <td>429</td>
          <td>218</td>
          <td>1996-03-29 18:36:55</td>
          <td>3</td>
          <td>4</td>
          <td>7</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 191-197

Chaining everything together in a pipeline
------------------------------------------

To perform cross-validation and enable hyper-parameter tuning, we gather
all elements into a scikit-learn |Pipeline| by using |make_pipeline|,
and define a scikit-learn |HGBR|.

.. GENERATED FROM PYTHON SOURCE LINES 197-209

.. code-block:: Python

    from sklearn.ensemble import HistGradientBoostingRegressor
    from sklearn.pipeline import make_pipeline

    pipeline = make_pipeline(
        table_vectorizer,
        agg_target_user,
        agg_target_movie,
        HistGradientBoostingRegressor(learning_rate=0.1, max_depth=4, max_iter=40),
    )

    pipeline






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[(&#x27;tablevectorizer&#x27;,
                     TableVectorizer(datetime_transformer=DatetimeEncoder(add_day_of_the_week=True))),
                    (&#x27;aggtarget-1&#x27;,
                     AggTarget(main_key=&#x27;userId&#x27;, operation=&#x27;hist(3)&#x27;,
                               suffix=&#x27;_user&#x27;)),
                    (&#x27;aggtarget-2&#x27;,
                     AggTarget(main_key=&#x27;movieId&#x27;, operation=&#x27;hist(3)&#x27;,
                               suffix=&#x27;_movie&#x27;)),
                    (&#x27;histgradientboostingregressor&#x27;,
                     HistGradientBoostingRegressor(max_depth=4, max_iter=40))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-19" type="checkbox" ><label for="sk-estimator-id-19" class="sk-toggleable__label sk-toggleable__label-arrow">Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[(&#x27;tablevectorizer&#x27;,
                     TableVectorizer(datetime_transformer=DatetimeEncoder(add_day_of_the_week=True))),
                    (&#x27;aggtarget-1&#x27;,
                     AggTarget(main_key=&#x27;userId&#x27;, operation=&#x27;hist(3)&#x27;,
                               suffix=&#x27;_user&#x27;)),
                    (&#x27;aggtarget-2&#x27;,
                     AggTarget(main_key=&#x27;movieId&#x27;, operation=&#x27;hist(3)&#x27;,
                               suffix=&#x27;_movie&#x27;)),
                    (&#x27;histgradientboostingregressor&#x27;,
                     HistGradientBoostingRegressor(max_depth=4, max_iter=40))])</pre></div></div></div><div class="sk-serial"><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-20" type="checkbox" ><label for="sk-estimator-id-20" class="sk-toggleable__label sk-toggleable__label-arrow">tablevectorizer: TableVectorizer</label><div class="sk-toggleable__content"><pre>TableVectorizer(datetime_transformer=DatetimeEncoder(add_day_of_the_week=True))</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-21" type="checkbox" ><label for="sk-estimator-id-21" class="sk-toggleable__label sk-toggleable__label-arrow">datetime_transformer: DatetimeEncoder</label><div class="sk-toggleable__content"><pre>DatetimeEncoder(add_day_of_the_week=True)</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-22" type="checkbox" ><label for="sk-estimator-id-22" class="sk-toggleable__label sk-toggleable__label-arrow">DatetimeEncoder</label><div class="sk-toggleable__content"><pre>DatetimeEncoder(add_day_of_the_week=True)</pre></div></div></div></div></div></div><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-23" type="checkbox" ><label for="sk-estimator-id-23" class="sk-toggleable__label sk-toggleable__label-arrow">high_cardinality_transformer: GapEncoder</label><div class="sk-toggleable__content"><pre>GapEncoder(n_components=30)</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-24" type="checkbox" ><label for="sk-estimator-id-24" class="sk-toggleable__label sk-toggleable__label-arrow">GapEncoder</label><div class="sk-toggleable__content"><pre>GapEncoder(n_components=30)</pre></div></div></div></div></div></div><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-25" type="checkbox" ><label for="sk-estimator-id-25" class="sk-toggleable__label sk-toggleable__label-arrow">low_cardinality_transformer: OneHotEncoder</label><div class="sk-toggleable__content"><pre>OneHotEncoder(drop=&#x27;if_binary&#x27;, handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-26" type="checkbox" ><label for="sk-estimator-id-26" class="sk-toggleable__label sk-toggleable__label-arrow">OneHotEncoder</label><div class="sk-toggleable__content"><pre>OneHotEncoder(drop=&#x27;if_binary&#x27;, handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-27" type="checkbox" ><label for="sk-estimator-id-27" class="sk-toggleable__label sk-toggleable__label-arrow">AggTarget</label><div class="sk-toggleable__content"><pre>AggTarget(main_key=&#x27;userId&#x27;, operation=&#x27;hist(3)&#x27;, suffix=&#x27;_user&#x27;)</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-28" type="checkbox" ><label for="sk-estimator-id-28" class="sk-toggleable__label sk-toggleable__label-arrow">AggTarget</label><div class="sk-toggleable__content"><pre>AggTarget(main_key=&#x27;movieId&#x27;, operation=&#x27;hist(3)&#x27;, suffix=&#x27;_movie&#x27;)</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-29" type="checkbox" ><label for="sk-estimator-id-29" class="sk-toggleable__label sk-toggleable__label-arrow">HistGradientBoostingRegressor</label><div class="sk-toggleable__content"><pre>HistGradientBoostingRegressor(max_depth=4, max_iter=40)</pre></div></div></div></div></div></div></div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 210-222

Hyper-parameters tuning and cross validation
--------------------------------------------

We can finally create our hyper-parameter search space, and use a
|GridSearchCV|. We select the cross validation splitter to be
the |TimeSeriesSplit| to prevent leakage, since our data are timestamped
logs.

Note that you need the name of the pipeline elements to assign them
hyper-parameters search.

You can lookup the name of the pipeline elements by doing:

.. GENERATED FROM PYTHON SOURCE LINES 222-224

.. code-block:: Python

    list(pipeline.named_steps)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    ['tablevectorizer', 'aggtarget-1', 'aggtarget-2', 'histgradientboostingregressor']



.. GENERATED FROM PYTHON SOURCE LINES 225-230

Alternatively, you can use scikit-learn |Pipeline| to name your transformers:
``Pipeline([("agg_target_user", agg_target_user), ...])``

We now perform the grid search over the ``AggTarget`` transformers to find the
operation maximizing our validation score.

.. GENERATED FROM PYTHON SOURCE LINES 230-249

.. code-block:: Python

    from sklearn.model_selection import GridSearchCV, TimeSeriesSplit

    operations = ["mean", "hist(3)", "hist(5)", "hist(7)", "value_counts"]
    param_grid = [
        {
            f"aggtarget-2__operation": [op],
        }
        for op in operations
    ]

    cv = GridSearchCV(pipeline, param_grid, cv=TimeSeriesSplit(n_splits=10))
    cv.fit(X, y)

    results = pd.DataFrame(cv.cv_results_)

    cols = [f"split{idx}_test_score" for idx in range(10)]
    results = results.set_index("param_aggtarget-2__operation")[cols].T
    results






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th>param_aggtarget-2__operation</th>
          <th>mean</th>
          <th>hist(3)</th>
          <th>hist(5)</th>
          <th>hist(7)</th>
          <th>value_counts</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>split0_test_score</th>
          <td>0.017906</td>
          <td>0.023572</td>
          <td>0.007540</td>
          <td>0.007540</td>
          <td>0.007540</td>
        </tr>
        <tr>
          <th>split1_test_score</th>
          <td>0.047968</td>
          <td>0.034920</td>
          <td>0.059455</td>
          <td>0.070215</td>
          <td>0.078351</td>
        </tr>
        <tr>
          <th>split2_test_score</th>
          <td>0.068097</td>
          <td>0.083264</td>
          <td>0.088838</td>
          <td>0.087972</td>
          <td>0.095634</td>
        </tr>
        <tr>
          <th>split3_test_score</th>
          <td>0.035797</td>
          <td>0.053966</td>
          <td>0.056003</td>
          <td>0.061367</td>
          <td>0.062436</td>
        </tr>
        <tr>
          <th>split4_test_score</th>
          <td>0.133327</td>
          <td>0.121540</td>
          <td>0.158436</td>
          <td>0.154274</td>
          <td>0.150200</td>
        </tr>
        <tr>
          <th>split5_test_score</th>
          <td>0.105519</td>
          <td>0.111000</td>
          <td>0.109453</td>
          <td>0.112274</td>
          <td>0.118223</td>
        </tr>
        <tr>
          <th>split6_test_score</th>
          <td>0.079701</td>
          <td>0.105084</td>
          <td>0.104736</td>
          <td>0.111211</td>
          <td>0.104890</td>
        </tr>
        <tr>
          <th>split7_test_score</th>
          <td>0.065811</td>
          <td>0.060532</td>
          <td>0.068918</td>
          <td>0.061500</td>
          <td>0.081844</td>
        </tr>
        <tr>
          <th>split8_test_score</th>
          <td>0.102426</td>
          <td>0.115744</td>
          <td>0.124244</td>
          <td>0.131354</td>
          <td>0.125673</td>
        </tr>
        <tr>
          <th>split9_test_score</th>
          <td>0.115310</td>
          <td>0.156327</td>
          <td>0.155995</td>
          <td>0.164067</td>
          <td>0.176232</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 250-259

The score used in this regression task is the R2. Remember that the R2
evaluates the relative performance compared to the naive baseline consisting
in always predicting the mean value of ``y_test``.
Therefore, the R2 is 0 when ``y_pred = y_true.mean()`` and is upper bounded
to 1 when ``y_pred = y_true``.

To get a better sense of the learning performances of our simple pipeline,
we also compute the average rating of each movie in the training set,
and uses this average to predict the ratings in the test set.

.. GENERATED FROM PYTHON SOURCE LINES 259-295

.. code-block:: Python

    from sklearn.metrics import r2_score


    def baseline_r2(X, y, train_idx, test_idx):
        """Compute the average rating for all movies in the train set,
        and map these averages to the test set as a prediction.

        If a movie in the test set is not present in the training set,
        we simply predict the global average rating of the training set.
        """
        X_train, y_train = X.iloc[train_idx].copy(), y.iloc[train_idx]
        X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]

        X_train["y"] = y_train

        movie_avg_rating = X_train.groupby("movieId")["y"].mean().to_frame().reset_index()

        y_pred = X_test.merge(movie_avg_rating, on="movieId", how="left")["y"]
        y_pred = y_pred.fillna(y_pred.mean())

        return r2_score(y_true=y_test, y_pred=y_pred)


    all_baseline_r2 = []
    for train_idx, test_idx in TimeSeriesSplit(n_splits=10).split(X, y):
        all_baseline_r2.append(baseline_r2(X, y, train_idx, test_idx))

    results.insert(0, "naive mean estimator", all_baseline_r2)

    # we only keep the 5 out of 10 last results
    # because the initial size of the train set is rather small
    sns.boxplot(results.tail(5), palette="magma")
    plt.ylabel("R2 score")
    plt.title("Hyper parameters grid-search results")
    plt.tight_layout()




.. image-sg:: /auto_examples/images/sphx_glr_08_join_aggregation_003.png
   :alt: Hyper parameters grid-search results
   :srcset: /auto_examples/images/sphx_glr_08_join_aggregation_003.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 296-308

The naive estimator has a lower performance than our pipeline, which means
that our extracted features brought some predictive power.

It seems that using the ``"value_counts"`` as an aggregation operator for
|AggTarget| yields better performances than using the mean (which is
equivalent to using the |TargetEncoder|).

Here, the number of bins encoding the target is proportional to the
performance: computing the mean yields a single statistic, whereas histograms
yield a density over a reduced set of bins, and ``"value_counts"`` yields an
exhaustive histogram over all the possible values of ratings
(here 10 different values, from 0.5 to 5).


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 18.256 seconds)


.. _sphx_glr_download_auto_examples_08_join_aggregation.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/skrub-data/skrub/0.1.0?urlpath=lab/tree/notebooks/auto_examples/08_join_aggregation.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: lite-badge

      .. image:: images/jupyterlite_badge_logo.svg
        :target: ../lite/lab/?path=auto_examples/08_join_aggregation.ipynb
        :alt: Launch JupyterLite
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: 08_join_aggregation.ipynb <08_join_aggregation.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: 08_join_aggregation.py <08_join_aggregation.py>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
